{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.sql(\"select 'spark' as hello \")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|    _1|   _2|\n",
      "+------+-----+\n",
      "|  Java|10000|\n",
      "|Python|10000|\n",
      "| Scala| 5000|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([(\"Java\",\"10000\"),(\"Python\",\"10000\"),(\"Scala\",\"5000\")]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = spark.sparkContext.textFile(\"/path/textFile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = spark.sparkContext.wholeTextFiles(\"/path/textFile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transRDD = spark.sparkContext.textFile(\"trans.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000000,06-26-2011,4000001,040.33,Exercise & Fitness,Cardio Machine Accessories,Clarksville,Tennessee,credit',\n",
       " '00000001,05-26-2011,4000002,198.44,Exercise & Fitness,Weightlifting Gloves,Long Beach,California,credit',\n",
       " '00000002,06-01-2011,4000002,005.58,Exercise & Fitness,Weightlifting Machine Accessories,Anaheim,California,credit',\n",
       " '00000003,06-05-2011,4000003,198.19,Gymnastics,Gymnastics Rings,Milwaukee,Wisconsin,credit',\n",
       " '00000004,12-17-2011,4000002,098.81,Team Sports,Field Hockey,Nashville  ,Tennessee,credit',\n",
       " '00000005,02-14-2011,4000004,193.63,Outdoor Recreation,Camping & Backpacking & Hiking,Chicago,Illinois,credit',\n",
       " '00000006,10-28-2011,4000005,027.89,Puzzles,Jigsaw Puzzles,Charleston,South Carolina,credit',\n",
       " '00000007,07-14-2011,4000006,096.01,Outdoor Play Equipment,Sandboxes,Columbus,Ohio,credit',\n",
       " '00000008,01-17-2011,4000006,010.44,Winter Sports,Snowmobiling,Des Moines,Iowa,credit',\n",
       " '00000009,05-17-2011,4000006,152.46,Jumping,Bungee Jumping,St. Petersburg,Florida,credit',\n",
       " '00000010,05-29-2011,4000007,180.28,Outdoor Recreation,Archery,Reno,Nevada,credit',\n",
       " '00000011,06-18-2011,4000009,121.39,Outdoor Play Equipment,Swing Sets,Columbus,Ohio,credit',\n",
       " '00000012,02-08-2011,4000009,041.52,Indoor Games,Bowling,San Francisco,California,credit',\n",
       " '00000013,03-13-2011,4000010,107.80,Team Sports,Field Hockey,Honolulu  ,Hawaii,credit',\n",
       " '00000014,02-25-2011,4000010,036.81,Gymnastics,Vaulting Horses,Los Angeles,California,credit',\n",
       " '00000015,10-20-2011,4000001,137.64,Combat Sports,Fencing,Honolulu  ,Hawaii,credit',\n",
       " '00000016,05-28-2011,4000010,035.56,Exercise & Fitness,Free Weight Bars,Columbia,South Carolina,credit',\n",
       " '00000017,10-18-2011,4000008,075.55,Water Sports,Scuba Diving & Snorkeling,Omaha,Nebraska,credit',\n",
       " '00000018,11-18-2011,4000008,088.65,Team Sports,Baseball,Salt Lake City,Utah,credit',\n",
       " '00000019,08-28-2011,4000008,051.81,Water Sports,Life Jackets,Newark,New Jersey,credit',\n",
       " '00000020,06-29-2011,4000005,041.55,Exercise & Fitness,Weightlifting Belts,New Orleans,Louisiana,credit',\n",
       " '00000021,02-14-2011,4000005,045.79,Air Sports,Parachutes,New York,New York,credit',\n",
       " '00000022,10-10-2011,4000009,019.64,Water Sports,Kitesurfing,Saint Paul,Minnesota,credit',\n",
       " '00000023,05-02-2011,4000009,099.50,Gymnastics,Gymnastics Rings,Springfield,Illinois,credit',\n",
       " '00000024,06-10-2011,4000003,151.20,Water Sports,Surfing,Plano,Texas,credit',\n",
       " '00000025,10-14-2011,4000009,144.20,Indoor Games,Darts,Phoenix,Arizona,credit',\n",
       " '00000026,10-11-2011,4000009,031.58,Combat Sports,Wrestling,Orange,California,credit',\n",
       " '00000027,09-29-2011,4000010,066.40,Games,Mahjong,Fremont,California,credit',\n",
       " '00000028,05-12-2011,4000008,079.78,Team Sports,Cricket,Lexington,Kentucky,credit',\n",
       " '00000029,06-03-2011,4000001,126.90,Outdoor Recreation,Hunting,Phoenix,Arizona,credit',\n",
       " '00000030,03-14-2011,4000001,047.05,Water Sports,Swimming,Lincoln,Nebraska,credit',\n",
       " '00000031,11-28-2011,4000008,005.03,Games,Dice & Dice Sets,Los Angeles,California,credit',\n",
       " '00000032,01-29-2011,4000008,020.13,Team Sports,Soccer,Springfield,Illinois,credit',\n",
       " '00000033,06-15-2011,4000008,154.15,Outdoor Recreation,Lawn Games,Nashville  ,Tennessee,credit',\n",
       " '00000034,05-06-2011,4000008,098.96,Team Sports,Indoor Volleyball,Atlanta,Georgia,credit',\n",
       " '00000035,04-12-2011,4000008,185.26,Games,Board Games,Centennial,Colorado,credit',\n",
       " '00000036,10-13-2011,4000007,035.66,Team Sports,Football,Saint Paul,Minnesota,credit',\n",
       " '00000037,04-19-2011,4000007,020.20,Outdoor Recreation,Shooting Games,San Diego,California,credit',\n",
       " '00000038,08-05-2011,4000007,150.60,Outdoor Recreation,Camping & Backpacking & Hiking,Hampton  ,Virginia,credit',\n",
       " '00000039,03-12-2011,4000006,174.36,Outdoor Play Equipment,Swing Sets,Pittsburgh,Pennsylvania,credit',\n",
       " '00000040,11-07-2011,4000005,165.10,Team Sports,Cheerleading,Reno,Nevada,credit',\n",
       " '00000041,04-16-2011,4000004,028.11,Indoor Games,Bowling,Westminster,Colorado,cash',\n",
       " '00000042,09-10-2011,4000004,038.52,Outdoor Recreation,Tetherball,Denton,Texas,cash',\n",
       " '00000043,04-22-2011,4000004,032.34,Water Sports,Water Polo,Las Vegas,Nevada,cash',\n",
       " '00000044,09-11-2011,4000001,135.37,Water Sports,Surfing,Seattle,Washington,credit',\n",
       " '00000045,11-27-2011,4000001,090.04,Exercise & Fitness,Abdominal Equipment,Honolulu  ,Hawaii,credit',\n",
       " '00000046,05-27-2011,4000001,052.29,Gymnastics,Vaulting Horses,Cleveland,Ohio,credit',\n",
       " '00000047,10-23-2011,4000008,100.10,Outdoor Play Equipment,Swing Sets,Everett,Washington,credit',\n",
       " '00000048,09-27-2011,4000007,157.94,Exercise & Fitness,Exercise Bands,Philadelphia,Pennsylvania,credit',\n",
       " '00000049,07-12-2011,4000010,144.59,Jumping,Jumping Stilts,Cambridge,Massachusetts,credit',\n",
       " '00000050,10-20-2011,4000010,055.93,Jumping,Pogo Sticks,Everett,Washington,credit',\n",
       " '00000051,02-17-2011,4000002,032.65,Water Sports,Life Jackets,Columbus,Georgia,cash',\n",
       " '00000052,02-04-2011,4000005,044.82,Outdoor Play Equipment,Lawn Water Slides,Hampton  ,Virginia,cash',\n",
       " '00000053,06-12-2011,4000004,044.46,Water Sports,Scuba Diving & Snorkeling,Charleston,South Carolina,cash',\n",
       " '00000054,10-03-2011,4000007,154.87,Outdoor Recreation,Running,Long Beach,California,credit',\n",
       " '00000055,12-16-2011,4000006,106.11,Water Sports,Swimming,New York,New York,credit',\n",
       " '00000056,06-21-2011,4000002,176.63,Outdoor Recreation,Geocaching,Boston,Massachusetts,credit',\n",
       " '00000057,12-20-2011,4000003,178.20,Outdoor Recreation,Skating,San Jose,California,credit',\n",
       " '00000058,12-29-2011,4000002,194.86,Water Sports,Windsurfing,Oklahoma City,Oklahoma,credit',\n",
       " '00000059,11-07-2011,4000001,021.43,Winter Sports,Snowboarding,Philadelphia,Pennsylvania,cash']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000000',\n",
       " '06-26-2011',\n",
       " '4000001',\n",
       " '040.33',\n",
       " 'Exercise & Fitness',\n",
       " 'Cardio Machine Accessories',\n",
       " 'Clarksville',\n",
       " 'Tennessee',\n",
       " 'credit',\n",
       " '00000001',\n",
       " '05-26-2011',\n",
       " '4000002',\n",
       " '198.44',\n",
       " 'Exercise & Fitness',\n",
       " 'Weightlifting Gloves',\n",
       " 'Long Beach',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000002',\n",
       " '06-01-2011',\n",
       " '4000002',\n",
       " '005.58',\n",
       " 'Exercise & Fitness',\n",
       " 'Weightlifting Machine Accessories',\n",
       " 'Anaheim',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000003',\n",
       " '06-05-2011',\n",
       " '4000003',\n",
       " '198.19',\n",
       " 'Gymnastics',\n",
       " 'Gymnastics Rings',\n",
       " 'Milwaukee',\n",
       " 'Wisconsin',\n",
       " 'credit',\n",
       " '00000004',\n",
       " '12-17-2011',\n",
       " '4000002',\n",
       " '098.81',\n",
       " 'Team Sports',\n",
       " 'Field Hockey',\n",
       " 'Nashville  ',\n",
       " 'Tennessee',\n",
       " 'credit',\n",
       " '00000005',\n",
       " '02-14-2011',\n",
       " '4000004',\n",
       " '193.63',\n",
       " 'Outdoor Recreation',\n",
       " 'Camping & Backpacking & Hiking',\n",
       " 'Chicago',\n",
       " 'Illinois',\n",
       " 'credit',\n",
       " '00000006',\n",
       " '10-28-2011',\n",
       " '4000005',\n",
       " '027.89',\n",
       " 'Puzzles',\n",
       " 'Jigsaw Puzzles',\n",
       " 'Charleston',\n",
       " 'South Carolina',\n",
       " 'credit',\n",
       " '00000007',\n",
       " '07-14-2011',\n",
       " '4000006',\n",
       " '096.01',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Sandboxes',\n",
       " 'Columbus',\n",
       " 'Ohio',\n",
       " 'credit',\n",
       " '00000008',\n",
       " '01-17-2011',\n",
       " '4000006',\n",
       " '010.44',\n",
       " 'Winter Sports',\n",
       " 'Snowmobiling',\n",
       " 'Des Moines',\n",
       " 'Iowa',\n",
       " 'credit',\n",
       " '00000009',\n",
       " '05-17-2011',\n",
       " '4000006',\n",
       " '152.46',\n",
       " 'Jumping',\n",
       " 'Bungee Jumping',\n",
       " 'St. Petersburg',\n",
       " 'Florida',\n",
       " 'credit',\n",
       " '00000010',\n",
       " '05-29-2011',\n",
       " '4000007',\n",
       " '180.28',\n",
       " 'Outdoor Recreation',\n",
       " 'Archery',\n",
       " 'Reno',\n",
       " 'Nevada',\n",
       " 'credit',\n",
       " '00000011',\n",
       " '06-18-2011',\n",
       " '4000009',\n",
       " '121.39',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Swing Sets',\n",
       " 'Columbus',\n",
       " 'Ohio',\n",
       " 'credit',\n",
       " '00000012',\n",
       " '02-08-2011',\n",
       " '4000009',\n",
       " '041.52',\n",
       " 'Indoor Games',\n",
       " 'Bowling',\n",
       " 'San Francisco',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000013',\n",
       " '03-13-2011',\n",
       " '4000010',\n",
       " '107.80',\n",
       " 'Team Sports',\n",
       " 'Field Hockey',\n",
       " 'Honolulu  ',\n",
       " 'Hawaii',\n",
       " 'credit',\n",
       " '00000014',\n",
       " '02-25-2011',\n",
       " '4000010',\n",
       " '036.81',\n",
       " 'Gymnastics',\n",
       " 'Vaulting Horses',\n",
       " 'Los Angeles',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000015',\n",
       " '10-20-2011',\n",
       " '4000001',\n",
       " '137.64',\n",
       " 'Combat Sports',\n",
       " 'Fencing',\n",
       " 'Honolulu  ',\n",
       " 'Hawaii',\n",
       " 'credit',\n",
       " '00000016',\n",
       " '05-28-2011',\n",
       " '4000010',\n",
       " '035.56',\n",
       " 'Exercise & Fitness',\n",
       " 'Free Weight Bars',\n",
       " 'Columbia',\n",
       " 'South Carolina',\n",
       " 'credit',\n",
       " '00000017',\n",
       " '10-18-2011',\n",
       " '4000008',\n",
       " '075.55',\n",
       " 'Water Sports',\n",
       " 'Scuba Diving & Snorkeling',\n",
       " 'Omaha',\n",
       " 'Nebraska',\n",
       " 'credit',\n",
       " '00000018',\n",
       " '11-18-2011',\n",
       " '4000008',\n",
       " '088.65',\n",
       " 'Team Sports',\n",
       " 'Baseball',\n",
       " 'Salt Lake City',\n",
       " 'Utah',\n",
       " 'credit',\n",
       " '00000019',\n",
       " '08-28-2011',\n",
       " '4000008',\n",
       " '051.81',\n",
       " 'Water Sports',\n",
       " 'Life Jackets',\n",
       " 'Newark',\n",
       " 'New Jersey',\n",
       " 'credit',\n",
       " '00000020',\n",
       " '06-29-2011',\n",
       " '4000005',\n",
       " '041.55',\n",
       " 'Exercise & Fitness',\n",
       " 'Weightlifting Belts',\n",
       " 'New Orleans',\n",
       " 'Louisiana',\n",
       " 'credit',\n",
       " '00000021',\n",
       " '02-14-2011',\n",
       " '4000005',\n",
       " '045.79',\n",
       " 'Air Sports',\n",
       " 'Parachutes',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'credit',\n",
       " '00000022',\n",
       " '10-10-2011',\n",
       " '4000009',\n",
       " '019.64',\n",
       " 'Water Sports',\n",
       " 'Kitesurfing',\n",
       " 'Saint Paul',\n",
       " 'Minnesota',\n",
       " 'credit',\n",
       " '00000023',\n",
       " '05-02-2011',\n",
       " '4000009',\n",
       " '099.50',\n",
       " 'Gymnastics',\n",
       " 'Gymnastics Rings',\n",
       " 'Springfield',\n",
       " 'Illinois',\n",
       " 'credit',\n",
       " '00000024',\n",
       " '06-10-2011',\n",
       " '4000003',\n",
       " '151.20',\n",
       " 'Water Sports',\n",
       " 'Surfing',\n",
       " 'Plano',\n",
       " 'Texas',\n",
       " 'credit',\n",
       " '00000025',\n",
       " '10-14-2011',\n",
       " '4000009',\n",
       " '144.20',\n",
       " 'Indoor Games',\n",
       " 'Darts',\n",
       " 'Phoenix',\n",
       " 'Arizona',\n",
       " 'credit',\n",
       " '00000026',\n",
       " '10-11-2011',\n",
       " '4000009',\n",
       " '031.58',\n",
       " 'Combat Sports',\n",
       " 'Wrestling',\n",
       " 'Orange',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000027',\n",
       " '09-29-2011',\n",
       " '4000010',\n",
       " '066.40',\n",
       " 'Games',\n",
       " 'Mahjong',\n",
       " 'Fremont',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000028',\n",
       " '05-12-2011',\n",
       " '4000008',\n",
       " '079.78',\n",
       " 'Team Sports',\n",
       " 'Cricket',\n",
       " 'Lexington',\n",
       " 'Kentucky',\n",
       " 'credit',\n",
       " '00000029',\n",
       " '06-03-2011',\n",
       " '4000001',\n",
       " '126.90',\n",
       " 'Outdoor Recreation',\n",
       " 'Hunting',\n",
       " 'Phoenix',\n",
       " 'Arizona',\n",
       " 'credit',\n",
       " '00000030',\n",
       " '03-14-2011',\n",
       " '4000001',\n",
       " '047.05',\n",
       " 'Water Sports',\n",
       " 'Swimming',\n",
       " 'Lincoln',\n",
       " 'Nebraska',\n",
       " 'credit',\n",
       " '00000031',\n",
       " '11-28-2011',\n",
       " '4000008',\n",
       " '005.03',\n",
       " 'Games',\n",
       " 'Dice & Dice Sets',\n",
       " 'Los Angeles',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000032',\n",
       " '01-29-2011',\n",
       " '4000008',\n",
       " '020.13',\n",
       " 'Team Sports',\n",
       " 'Soccer',\n",
       " 'Springfield',\n",
       " 'Illinois',\n",
       " 'credit',\n",
       " '00000033',\n",
       " '06-15-2011',\n",
       " '4000008',\n",
       " '154.15',\n",
       " 'Outdoor Recreation',\n",
       " 'Lawn Games',\n",
       " 'Nashville  ',\n",
       " 'Tennessee',\n",
       " 'credit',\n",
       " '00000034',\n",
       " '05-06-2011',\n",
       " '4000008',\n",
       " '098.96',\n",
       " 'Team Sports',\n",
       " 'Indoor Volleyball',\n",
       " 'Atlanta',\n",
       " 'Georgia',\n",
       " 'credit',\n",
       " '00000035',\n",
       " '04-12-2011',\n",
       " '4000008',\n",
       " '185.26',\n",
       " 'Games',\n",
       " 'Board Games',\n",
       " 'Centennial',\n",
       " 'Colorado',\n",
       " 'credit',\n",
       " '00000036',\n",
       " '10-13-2011',\n",
       " '4000007',\n",
       " '035.66',\n",
       " 'Team Sports',\n",
       " 'Football',\n",
       " 'Saint Paul',\n",
       " 'Minnesota',\n",
       " 'credit',\n",
       " '00000037',\n",
       " '04-19-2011',\n",
       " '4000007',\n",
       " '020.20',\n",
       " 'Outdoor Recreation',\n",
       " 'Shooting Games',\n",
       " 'San Diego',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000038',\n",
       " '08-05-2011',\n",
       " '4000007',\n",
       " '150.60',\n",
       " 'Outdoor Recreation',\n",
       " 'Camping & Backpacking & Hiking',\n",
       " 'Hampton  ',\n",
       " 'Virginia',\n",
       " 'credit',\n",
       " '00000039',\n",
       " '03-12-2011',\n",
       " '4000006',\n",
       " '174.36',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Swing Sets',\n",
       " 'Pittsburgh',\n",
       " 'Pennsylvania',\n",
       " 'credit',\n",
       " '00000040',\n",
       " '11-07-2011',\n",
       " '4000005',\n",
       " '165.10',\n",
       " 'Team Sports',\n",
       " 'Cheerleading',\n",
       " 'Reno',\n",
       " 'Nevada',\n",
       " 'credit',\n",
       " '00000041',\n",
       " '04-16-2011',\n",
       " '4000004',\n",
       " '028.11',\n",
       " 'Indoor Games',\n",
       " 'Bowling',\n",
       " 'Westminster',\n",
       " 'Colorado',\n",
       " 'cash',\n",
       " '00000042',\n",
       " '09-10-2011',\n",
       " '4000004',\n",
       " '038.52',\n",
       " 'Outdoor Recreation',\n",
       " 'Tetherball',\n",
       " 'Denton',\n",
       " 'Texas',\n",
       " 'cash',\n",
       " '00000043',\n",
       " '04-22-2011',\n",
       " '4000004',\n",
       " '032.34',\n",
       " 'Water Sports',\n",
       " 'Water Polo',\n",
       " 'Las Vegas',\n",
       " 'Nevada',\n",
       " 'cash',\n",
       " '00000044',\n",
       " '09-11-2011',\n",
       " '4000001',\n",
       " '135.37',\n",
       " 'Water Sports',\n",
       " 'Surfing',\n",
       " 'Seattle',\n",
       " 'Washington',\n",
       " 'credit',\n",
       " '00000045',\n",
       " '11-27-2011',\n",
       " '4000001',\n",
       " '090.04',\n",
       " 'Exercise & Fitness',\n",
       " 'Abdominal Equipment',\n",
       " 'Honolulu  ',\n",
       " 'Hawaii',\n",
       " 'credit',\n",
       " '00000046',\n",
       " '05-27-2011',\n",
       " '4000001',\n",
       " '052.29',\n",
       " 'Gymnastics',\n",
       " 'Vaulting Horses',\n",
       " 'Cleveland',\n",
       " 'Ohio',\n",
       " 'credit',\n",
       " '00000047',\n",
       " '10-23-2011',\n",
       " '4000008',\n",
       " '100.10',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Swing Sets',\n",
       " 'Everett',\n",
       " 'Washington',\n",
       " 'credit',\n",
       " '00000048',\n",
       " '09-27-2011',\n",
       " '4000007',\n",
       " '157.94',\n",
       " 'Exercise & Fitness',\n",
       " 'Exercise Bands',\n",
       " 'Philadelphia',\n",
       " 'Pennsylvania',\n",
       " 'credit',\n",
       " '00000049',\n",
       " '07-12-2011',\n",
       " '4000010',\n",
       " '144.59',\n",
       " 'Jumping',\n",
       " 'Jumping Stilts',\n",
       " 'Cambridge',\n",
       " 'Massachusetts',\n",
       " 'credit',\n",
       " '00000050',\n",
       " '10-20-2011',\n",
       " '4000010',\n",
       " '055.93',\n",
       " 'Jumping',\n",
       " 'Pogo Sticks',\n",
       " 'Everett',\n",
       " 'Washington',\n",
       " 'credit',\n",
       " '00000051',\n",
       " '02-17-2011',\n",
       " '4000002',\n",
       " '032.65',\n",
       " 'Water Sports',\n",
       " 'Life Jackets',\n",
       " 'Columbus',\n",
       " 'Georgia',\n",
       " 'cash',\n",
       " '00000052',\n",
       " '02-04-2011',\n",
       " '4000005',\n",
       " '044.82',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Lawn Water Slides',\n",
       " 'Hampton  ',\n",
       " 'Virginia',\n",
       " 'cash',\n",
       " '00000053',\n",
       " '06-12-2011',\n",
       " '4000004',\n",
       " '044.46',\n",
       " 'Water Sports',\n",
       " 'Scuba Diving & Snorkeling',\n",
       " 'Charleston',\n",
       " 'South Carolina',\n",
       " 'cash',\n",
       " '00000054',\n",
       " '10-03-2011',\n",
       " '4000007',\n",
       " '154.87',\n",
       " 'Outdoor Recreation',\n",
       " 'Running',\n",
       " 'Long Beach',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000055',\n",
       " '12-16-2011',\n",
       " '4000006',\n",
       " '106.11',\n",
       " 'Water Sports',\n",
       " 'Swimming',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'credit',\n",
       " '00000056',\n",
       " '06-21-2011',\n",
       " '4000002',\n",
       " '176.63',\n",
       " 'Outdoor Recreation',\n",
       " 'Geocaching',\n",
       " 'Boston',\n",
       " 'Massachusetts',\n",
       " 'credit',\n",
       " '00000057',\n",
       " '12-20-2011',\n",
       " '4000003',\n",
       " '178.20',\n",
       " 'Outdoor Recreation',\n",
       " 'Skating',\n",
       " 'San Jose',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000058',\n",
       " '12-29-2011',\n",
       " '4000002',\n",
       " '194.86',\n",
       " 'Water Sports',\n",
       " 'Windsurfing',\n",
       " 'Oklahoma City',\n",
       " 'Oklahoma',\n",
       " 'credit',\n",
       " '00000059',\n",
       " '11-07-2011',\n",
       " '4000001',\n",
       " '021.43',\n",
       " 'Winter Sports',\n",
       " 'Snowboarding',\n",
       " 'Philadelphia',\n",
       " 'Pennsylvania',\n",
       " 'cash']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.flatMap(lambda y: y.split(\",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00000000',\n",
       "  '06-26-2011',\n",
       "  '4000001',\n",
       "  '040.33',\n",
       "  'Exercise & Fitness',\n",
       "  'Cardio Machine Accessories',\n",
       "  'Clarksville',\n",
       "  'Tennessee',\n",
       "  'credit'],\n",
       " ['00000001',\n",
       "  '05-26-2011',\n",
       "  '4000002',\n",
       "  '198.44',\n",
       "  'Exercise & Fitness',\n",
       "  'Weightlifting Gloves',\n",
       "  'Long Beach',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000002',\n",
       "  '06-01-2011',\n",
       "  '4000002',\n",
       "  '005.58',\n",
       "  'Exercise & Fitness',\n",
       "  'Weightlifting Machine Accessories',\n",
       "  'Anaheim',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000003',\n",
       "  '06-05-2011',\n",
       "  '4000003',\n",
       "  '198.19',\n",
       "  'Gymnastics',\n",
       "  'Gymnastics Rings',\n",
       "  'Milwaukee',\n",
       "  'Wisconsin',\n",
       "  'credit'],\n",
       " ['00000004',\n",
       "  '12-17-2011',\n",
       "  '4000002',\n",
       "  '098.81',\n",
       "  'Team Sports',\n",
       "  'Field Hockey',\n",
       "  'Nashville  ',\n",
       "  'Tennessee',\n",
       "  'credit'],\n",
       " ['00000005',\n",
       "  '02-14-2011',\n",
       "  '4000004',\n",
       "  '193.63',\n",
       "  'Outdoor Recreation',\n",
       "  'Camping & Backpacking & Hiking',\n",
       "  'Chicago',\n",
       "  'Illinois',\n",
       "  'credit'],\n",
       " ['00000006',\n",
       "  '10-28-2011',\n",
       "  '4000005',\n",
       "  '027.89',\n",
       "  'Puzzles',\n",
       "  'Jigsaw Puzzles',\n",
       "  'Charleston',\n",
       "  'South Carolina',\n",
       "  'credit'],\n",
       " ['00000007',\n",
       "  '07-14-2011',\n",
       "  '4000006',\n",
       "  '096.01',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Sandboxes',\n",
       "  'Columbus',\n",
       "  'Ohio',\n",
       "  'credit'],\n",
       " ['00000008',\n",
       "  '01-17-2011',\n",
       "  '4000006',\n",
       "  '010.44',\n",
       "  'Winter Sports',\n",
       "  'Snowmobiling',\n",
       "  'Des Moines',\n",
       "  'Iowa',\n",
       "  'credit'],\n",
       " ['00000009',\n",
       "  '05-17-2011',\n",
       "  '4000006',\n",
       "  '152.46',\n",
       "  'Jumping',\n",
       "  'Bungee Jumping',\n",
       "  'St. Petersburg',\n",
       "  'Florida',\n",
       "  'credit'],\n",
       " ['00000010',\n",
       "  '05-29-2011',\n",
       "  '4000007',\n",
       "  '180.28',\n",
       "  'Outdoor Recreation',\n",
       "  'Archery',\n",
       "  'Reno',\n",
       "  'Nevada',\n",
       "  'credit'],\n",
       " ['00000011',\n",
       "  '06-18-2011',\n",
       "  '4000009',\n",
       "  '121.39',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Swing Sets',\n",
       "  'Columbus',\n",
       "  'Ohio',\n",
       "  'credit'],\n",
       " ['00000012',\n",
       "  '02-08-2011',\n",
       "  '4000009',\n",
       "  '041.52',\n",
       "  'Indoor Games',\n",
       "  'Bowling',\n",
       "  'San Francisco',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000013',\n",
       "  '03-13-2011',\n",
       "  '4000010',\n",
       "  '107.80',\n",
       "  'Team Sports',\n",
       "  'Field Hockey',\n",
       "  'Honolulu  ',\n",
       "  'Hawaii',\n",
       "  'credit'],\n",
       " ['00000014',\n",
       "  '02-25-2011',\n",
       "  '4000010',\n",
       "  '036.81',\n",
       "  'Gymnastics',\n",
       "  'Vaulting Horses',\n",
       "  'Los Angeles',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000015',\n",
       "  '10-20-2011',\n",
       "  '4000001',\n",
       "  '137.64',\n",
       "  'Combat Sports',\n",
       "  'Fencing',\n",
       "  'Honolulu  ',\n",
       "  'Hawaii',\n",
       "  'credit'],\n",
       " ['00000016',\n",
       "  '05-28-2011',\n",
       "  '4000010',\n",
       "  '035.56',\n",
       "  'Exercise & Fitness',\n",
       "  'Free Weight Bars',\n",
       "  'Columbia',\n",
       "  'South Carolina',\n",
       "  'credit'],\n",
       " ['00000017',\n",
       "  '10-18-2011',\n",
       "  '4000008',\n",
       "  '075.55',\n",
       "  'Water Sports',\n",
       "  'Scuba Diving & Snorkeling',\n",
       "  'Omaha',\n",
       "  'Nebraska',\n",
       "  'credit'],\n",
       " ['00000018',\n",
       "  '11-18-2011',\n",
       "  '4000008',\n",
       "  '088.65',\n",
       "  'Team Sports',\n",
       "  'Baseball',\n",
       "  'Salt Lake City',\n",
       "  'Utah',\n",
       "  'credit'],\n",
       " ['00000019',\n",
       "  '08-28-2011',\n",
       "  '4000008',\n",
       "  '051.81',\n",
       "  'Water Sports',\n",
       "  'Life Jackets',\n",
       "  'Newark',\n",
       "  'New Jersey',\n",
       "  'credit'],\n",
       " ['00000020',\n",
       "  '06-29-2011',\n",
       "  '4000005',\n",
       "  '041.55',\n",
       "  'Exercise & Fitness',\n",
       "  'Weightlifting Belts',\n",
       "  'New Orleans',\n",
       "  'Louisiana',\n",
       "  'credit'],\n",
       " ['00000021',\n",
       "  '02-14-2011',\n",
       "  '4000005',\n",
       "  '045.79',\n",
       "  'Air Sports',\n",
       "  'Parachutes',\n",
       "  'New York',\n",
       "  'New York',\n",
       "  'credit'],\n",
       " ['00000022',\n",
       "  '10-10-2011',\n",
       "  '4000009',\n",
       "  '019.64',\n",
       "  'Water Sports',\n",
       "  'Kitesurfing',\n",
       "  'Saint Paul',\n",
       "  'Minnesota',\n",
       "  'credit'],\n",
       " ['00000023',\n",
       "  '05-02-2011',\n",
       "  '4000009',\n",
       "  '099.50',\n",
       "  'Gymnastics',\n",
       "  'Gymnastics Rings',\n",
       "  'Springfield',\n",
       "  'Illinois',\n",
       "  'credit'],\n",
       " ['00000024',\n",
       "  '06-10-2011',\n",
       "  '4000003',\n",
       "  '151.20',\n",
       "  'Water Sports',\n",
       "  'Surfing',\n",
       "  'Plano',\n",
       "  'Texas',\n",
       "  'credit'],\n",
       " ['00000025',\n",
       "  '10-14-2011',\n",
       "  '4000009',\n",
       "  '144.20',\n",
       "  'Indoor Games',\n",
       "  'Darts',\n",
       "  'Phoenix',\n",
       "  'Arizona',\n",
       "  'credit'],\n",
       " ['00000026',\n",
       "  '10-11-2011',\n",
       "  '4000009',\n",
       "  '031.58',\n",
       "  'Combat Sports',\n",
       "  'Wrestling',\n",
       "  'Orange',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000027',\n",
       "  '09-29-2011',\n",
       "  '4000010',\n",
       "  '066.40',\n",
       "  'Games',\n",
       "  'Mahjong',\n",
       "  'Fremont',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000028',\n",
       "  '05-12-2011',\n",
       "  '4000008',\n",
       "  '079.78',\n",
       "  'Team Sports',\n",
       "  'Cricket',\n",
       "  'Lexington',\n",
       "  'Kentucky',\n",
       "  'credit'],\n",
       " ['00000029',\n",
       "  '06-03-2011',\n",
       "  '4000001',\n",
       "  '126.90',\n",
       "  'Outdoor Recreation',\n",
       "  'Hunting',\n",
       "  'Phoenix',\n",
       "  'Arizona',\n",
       "  'credit'],\n",
       " ['00000030',\n",
       "  '03-14-2011',\n",
       "  '4000001',\n",
       "  '047.05',\n",
       "  'Water Sports',\n",
       "  'Swimming',\n",
       "  'Lincoln',\n",
       "  'Nebraska',\n",
       "  'credit'],\n",
       " ['00000031',\n",
       "  '11-28-2011',\n",
       "  '4000008',\n",
       "  '005.03',\n",
       "  'Games',\n",
       "  'Dice & Dice Sets',\n",
       "  'Los Angeles',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000032',\n",
       "  '01-29-2011',\n",
       "  '4000008',\n",
       "  '020.13',\n",
       "  'Team Sports',\n",
       "  'Soccer',\n",
       "  'Springfield',\n",
       "  'Illinois',\n",
       "  'credit'],\n",
       " ['00000033',\n",
       "  '06-15-2011',\n",
       "  '4000008',\n",
       "  '154.15',\n",
       "  'Outdoor Recreation',\n",
       "  'Lawn Games',\n",
       "  'Nashville  ',\n",
       "  'Tennessee',\n",
       "  'credit'],\n",
       " ['00000034',\n",
       "  '05-06-2011',\n",
       "  '4000008',\n",
       "  '098.96',\n",
       "  'Team Sports',\n",
       "  'Indoor Volleyball',\n",
       "  'Atlanta',\n",
       "  'Georgia',\n",
       "  'credit'],\n",
       " ['00000035',\n",
       "  '04-12-2011',\n",
       "  '4000008',\n",
       "  '185.26',\n",
       "  'Games',\n",
       "  'Board Games',\n",
       "  'Centennial',\n",
       "  'Colorado',\n",
       "  'credit'],\n",
       " ['00000036',\n",
       "  '10-13-2011',\n",
       "  '4000007',\n",
       "  '035.66',\n",
       "  'Team Sports',\n",
       "  'Football',\n",
       "  'Saint Paul',\n",
       "  'Minnesota',\n",
       "  'credit'],\n",
       " ['00000037',\n",
       "  '04-19-2011',\n",
       "  '4000007',\n",
       "  '020.20',\n",
       "  'Outdoor Recreation',\n",
       "  'Shooting Games',\n",
       "  'San Diego',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000038',\n",
       "  '08-05-2011',\n",
       "  '4000007',\n",
       "  '150.60',\n",
       "  'Outdoor Recreation',\n",
       "  'Camping & Backpacking & Hiking',\n",
       "  'Hampton  ',\n",
       "  'Virginia',\n",
       "  'credit'],\n",
       " ['00000039',\n",
       "  '03-12-2011',\n",
       "  '4000006',\n",
       "  '174.36',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Swing Sets',\n",
       "  'Pittsburgh',\n",
       "  'Pennsylvania',\n",
       "  'credit'],\n",
       " ['00000040',\n",
       "  '11-07-2011',\n",
       "  '4000005',\n",
       "  '165.10',\n",
       "  'Team Sports',\n",
       "  'Cheerleading',\n",
       "  'Reno',\n",
       "  'Nevada',\n",
       "  'credit'],\n",
       " ['00000041',\n",
       "  '04-16-2011',\n",
       "  '4000004',\n",
       "  '028.11',\n",
       "  'Indoor Games',\n",
       "  'Bowling',\n",
       "  'Westminster',\n",
       "  'Colorado',\n",
       "  'cash'],\n",
       " ['00000042',\n",
       "  '09-10-2011',\n",
       "  '4000004',\n",
       "  '038.52',\n",
       "  'Outdoor Recreation',\n",
       "  'Tetherball',\n",
       "  'Denton',\n",
       "  'Texas',\n",
       "  'cash'],\n",
       " ['00000043',\n",
       "  '04-22-2011',\n",
       "  '4000004',\n",
       "  '032.34',\n",
       "  'Water Sports',\n",
       "  'Water Polo',\n",
       "  'Las Vegas',\n",
       "  'Nevada',\n",
       "  'cash'],\n",
       " ['00000044',\n",
       "  '09-11-2011',\n",
       "  '4000001',\n",
       "  '135.37',\n",
       "  'Water Sports',\n",
       "  'Surfing',\n",
       "  'Seattle',\n",
       "  'Washington',\n",
       "  'credit'],\n",
       " ['00000045',\n",
       "  '11-27-2011',\n",
       "  '4000001',\n",
       "  '090.04',\n",
       "  'Exercise & Fitness',\n",
       "  'Abdominal Equipment',\n",
       "  'Honolulu  ',\n",
       "  'Hawaii',\n",
       "  'credit'],\n",
       " ['00000046',\n",
       "  '05-27-2011',\n",
       "  '4000001',\n",
       "  '052.29',\n",
       "  'Gymnastics',\n",
       "  'Vaulting Horses',\n",
       "  'Cleveland',\n",
       "  'Ohio',\n",
       "  'credit'],\n",
       " ['00000047',\n",
       "  '10-23-2011',\n",
       "  '4000008',\n",
       "  '100.10',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Swing Sets',\n",
       "  'Everett',\n",
       "  'Washington',\n",
       "  'credit'],\n",
       " ['00000048',\n",
       "  '09-27-2011',\n",
       "  '4000007',\n",
       "  '157.94',\n",
       "  'Exercise & Fitness',\n",
       "  'Exercise Bands',\n",
       "  'Philadelphia',\n",
       "  'Pennsylvania',\n",
       "  'credit'],\n",
       " ['00000049',\n",
       "  '07-12-2011',\n",
       "  '4000010',\n",
       "  '144.59',\n",
       "  'Jumping',\n",
       "  'Jumping Stilts',\n",
       "  'Cambridge',\n",
       "  'Massachusetts',\n",
       "  'credit'],\n",
       " ['00000050',\n",
       "  '10-20-2011',\n",
       "  '4000010',\n",
       "  '055.93',\n",
       "  'Jumping',\n",
       "  'Pogo Sticks',\n",
       "  'Everett',\n",
       "  'Washington',\n",
       "  'credit'],\n",
       " ['00000051',\n",
       "  '02-17-2011',\n",
       "  '4000002',\n",
       "  '032.65',\n",
       "  'Water Sports',\n",
       "  'Life Jackets',\n",
       "  'Columbus',\n",
       "  'Georgia',\n",
       "  'cash'],\n",
       " ['00000052',\n",
       "  '02-04-2011',\n",
       "  '4000005',\n",
       "  '044.82',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Lawn Water Slides',\n",
       "  'Hampton  ',\n",
       "  'Virginia',\n",
       "  'cash'],\n",
       " ['00000053',\n",
       "  '06-12-2011',\n",
       "  '4000004',\n",
       "  '044.46',\n",
       "  'Water Sports',\n",
       "  'Scuba Diving & Snorkeling',\n",
       "  'Charleston',\n",
       "  'South Carolina',\n",
       "  'cash'],\n",
       " ['00000054',\n",
       "  '10-03-2011',\n",
       "  '4000007',\n",
       "  '154.87',\n",
       "  'Outdoor Recreation',\n",
       "  'Running',\n",
       "  'Long Beach',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000055',\n",
       "  '12-16-2011',\n",
       "  '4000006',\n",
       "  '106.11',\n",
       "  'Water Sports',\n",
       "  'Swimming',\n",
       "  'New York',\n",
       "  'New York',\n",
       "  'credit'],\n",
       " ['00000056',\n",
       "  '06-21-2011',\n",
       "  '4000002',\n",
       "  '176.63',\n",
       "  'Outdoor Recreation',\n",
       "  'Geocaching',\n",
       "  'Boston',\n",
       "  'Massachusetts',\n",
       "  'credit'],\n",
       " ['00000057',\n",
       "  '12-20-2011',\n",
       "  '4000003',\n",
       "  '178.20',\n",
       "  'Outdoor Recreation',\n",
       "  'Skating',\n",
       "  'San Jose',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000058',\n",
       "  '12-29-2011',\n",
       "  '4000002',\n",
       "  '194.86',\n",
       "  'Water Sports',\n",
       "  'Windsurfing',\n",
       "  'Oklahoma City',\n",
       "  'Oklahoma',\n",
       "  'credit'],\n",
       " ['00000059',\n",
       "  '11-07-2011',\n",
       "  '4000001',\n",
       "  '021.43',\n",
       "  'Winter Sports',\n",
       "  'Snowboarding',\n",
       "  'Philadelphia',\n",
       "  'Pennsylvania',\n",
       "  'cash']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.flatMap(lambda x: x.split(\",\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000001', '040.33'),\n",
       " ('4000002', '198.44'),\n",
       " ('4000002', '005.58'),\n",
       " ('4000003', '198.19'),\n",
       " ('4000002', '098.81'),\n",
       " ('4000004', '193.63'),\n",
       " ('4000005', '027.89'),\n",
       " ('4000006', '096.01'),\n",
       " ('4000006', '010.44'),\n",
       " ('4000006', '152.46'),\n",
       " ('4000007', '180.28'),\n",
       " ('4000009', '121.39'),\n",
       " ('4000009', '041.52'),\n",
       " ('4000010', '107.80'),\n",
       " ('4000010', '036.81'),\n",
       " ('4000001', '137.64'),\n",
       " ('4000010', '035.56'),\n",
       " ('4000008', '075.55'),\n",
       " ('4000008', '088.65'),\n",
       " ('4000008', '051.81'),\n",
       " ('4000005', '041.55'),\n",
       " ('4000005', '045.79'),\n",
       " ('4000009', '019.64'),\n",
       " ('4000009', '099.50'),\n",
       " ('4000003', '151.20'),\n",
       " ('4000009', '144.20'),\n",
       " ('4000009', '031.58'),\n",
       " ('4000010', '066.40'),\n",
       " ('4000008', '079.78'),\n",
       " ('4000001', '126.90'),\n",
       " ('4000001', '047.05'),\n",
       " ('4000008', '005.03'),\n",
       " ('4000008', '020.13'),\n",
       " ('4000008', '154.15'),\n",
       " ('4000008', '098.96'),\n",
       " ('4000008', '185.26'),\n",
       " ('4000007', '035.66'),\n",
       " ('4000007', '020.20'),\n",
       " ('4000007', '150.60'),\n",
       " ('4000006', '174.36'),\n",
       " ('4000005', '165.10'),\n",
       " ('4000004', '028.11'),\n",
       " ('4000004', '038.52'),\n",
       " ('4000004', '032.34'),\n",
       " ('4000001', '135.37'),\n",
       " ('4000001', '090.04'),\n",
       " ('4000001', '052.29'),\n",
       " ('4000008', '100.10'),\n",
       " ('4000007', '157.94'),\n",
       " ('4000010', '144.59'),\n",
       " ('4000010', '055.93'),\n",
       " ('4000002', '032.65'),\n",
       " ('4000005', '044.82'),\n",
       " ('4000004', '044.46'),\n",
       " ('4000007', '154.87'),\n",
       " ('4000006', '106.11'),\n",
       " ('4000002', '176.63'),\n",
       " ('4000003', '178.20'),\n",
       " ('4000002', '194.86'),\n",
       " ('4000001', '021.43')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000004', 337.06),\n",
       " ('4000007', 699.55),\n",
       " ('4000008', 859.42),\n",
       " ('4000001', 651.0500000000001),\n",
       " ('4000002', 706.97),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000005', 325.15),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000009', 457.83),\n",
       " ('4000010', 447.09000000000003)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000008', 859.42),\n",
       " ('4000002', 706.97),\n",
       " ('4000007', 699.55),\n",
       " ('4000001', 651.0500000000001),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000009', 457.83),\n",
       " ('4000010', 447.09000000000003),\n",
       " ('4000004', 337.06),\n",
       " ('4000005', 325.15)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).sortBy(lambda x: x[1], False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000001', 651.0500000000001),\n",
       " ('4000002', 706.97),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000004', 337.06),\n",
       " ('4000005', 325.15),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000007', 699.55),\n",
       " ('4000008', 859.42),\n",
       " ('4000009', 457.83),\n",
       " ('4000010', 447.09000000000003)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000002', 'Team Sports'),\n",
       " ('4000006', 'Winter Sports'),\n",
       " ('4000010', 'Team Sports'),\n",
       " ('4000001', 'Combat Sports'),\n",
       " ('4000008', 'Water Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000008', 'Water Sports'),\n",
       " ('4000005', 'Air Sports'),\n",
       " ('4000009', 'Water Sports'),\n",
       " ('4000003', 'Water Sports'),\n",
       " ('4000009', 'Combat Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000001', 'Water Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000007', 'Team Sports'),\n",
       " ('4000005', 'Team Sports'),\n",
       " ('4000004', 'Water Sports'),\n",
       " ('4000001', 'Water Sports'),\n",
       " ('4000002', 'Water Sports'),\n",
       " ('4000004', 'Water Sports'),\n",
       " ('4000006', 'Water Sports'),\n",
       " ('4000002', 'Water Sports'),\n",
       " ('4000001', 'Winter Sports')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).filter(lambda x: (\"Sport\" in x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000008',\n",
       "  'Water Sports;Team Sports;Games;Outdoor Play Equipment;Outdoor Recreation'),\n",
       " ('4000004', 'Indoor Games;Water Sports;Outdoor Recreation'),\n",
       " ('4000003', 'Gymnastics;Outdoor Recreation;Water Sports'),\n",
       " ('4000006', 'Jumping;Outdoor Play Equipment;Winter Sports;Water Sports'),\n",
       " ('4000001',\n",
       "  'Combat Sports;Outdoor Recreation;Gymnastics;Exercise & Fitness;Water Sports;Winter Sports'),\n",
       " ('4000009',\n",
       "  'Gymnastics;Combat Sports;Outdoor Play Equipment;Indoor Games;Water Sports'),\n",
       " ('4000002', 'Outdoor Recreation;Exercise & Fitness;Team Sports;Water Sports')]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).distinct().reduceByKey(lambda x1,x2: x1 + (';') + x2).filter(lambda x: (\"Water Sports\" in x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'4000001': 8,\n",
       "             '4000002': 6,\n",
       "             '4000003': 3,\n",
       "             '4000004': 5,\n",
       "             '4000005': 5,\n",
       "             '4000006': 5,\n",
       "             '4000007': 6,\n",
       "             '4000009': 6,\n",
       "             '4000010': 6,\n",
       "             '4000008': 10})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'4000001': 8,\n",
       "             '4000002': 6,\n",
       "             '4000003': 3,\n",
       "             '4000004': 5,\n",
       "             '4000005': 5,\n",
       "             '4000006': 5,\n",
       "             '4000007': 6,\n",
       "             '4000008': 10,\n",
       "             '4000009': 6,\n",
       "             '4000010': 6})"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).sortByKey().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000005', 325.15),\n",
       " ('4000004', 337.06),\n",
       " ('4000010', 447.09000000000003),\n",
       " ('4000009', 457.83),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000001', 651.0500000000001),\n",
       " ('4000007', 699.55),\n",
       " ('4000002', 706.97),\n",
       " ('4000008', 859.42)]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).sortBy(lambda x: x[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\", \"users_Count\"]\n",
    "data = [(\"Java\",\"20000\"),(\"Python\",\"100000\"),(\"Scala\",\"3000\")]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Java', '20000'), ('Python', '100000'), ('Scala', '3000')]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1 = rdd.toDF()\n",
    "dfFromRDD1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1 = rdd.toDF(columns)\n",
    "dfFromRDD1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD2 = spark.createDataFrame(data).toDF(*columns)\n",
    "dfFromRDD2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Java\",\"20000\"),(\"Python\",\"100000\"),(\"Scala\",\"3000\")]\n",
    "dfFromRDD2 = spark.createDataFrame(data).toDF(*columns)\n",
    "dfFromRDD2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "rowData = map(lambda x: Row(*x), data)\n",
    "dfFromRDD3 = spark.createDataFrame(rowData, columns)\n",
    "dfFromRDD3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|   id|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|    James|          |   Smith|36636|     M|  3000|\n",
      "|    Maria|      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "         (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "         (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "        ]\n",
    "schema1 = StructType([\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\",StringType(),True), \\\n",
    "    StructField(\"gender\",StringType(),True), \\\n",
    "    StructField(\"salary\",IntegerType(),True), \\\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data = data2, schema= schema1)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"zipcodes.csv\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").load(\"zipcodes.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: string (nullable = true)\n",
      " |-- Long: string (nullable = true)\n",
      " |-- Xaxis: string (nullable = true)\n",
      " |-- Yaxis: string (nullable = true)\n",
      " |-- Zaxis: string (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: string (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: string (nullable = true)\n",
      " |-- TotalWages: string (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "|       76512|  27203|   STANDARD|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| 0.14|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        FALSE|           8355|              15228| 215474318|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.option(\"header\",True).csv(\"zipcodes.csv\")\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|   _c0|    _c1|   _c2|      _c3|\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dftest1 = spark.read.csv(\"/E:/spark/spark-3.0.3-bin-hadoop2.7/BTGK/\")\n",
    "dftest1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(delimiter=',').csv(\"zipcodes.csv\")\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.options(inferSchema='True',delimiter=',').csv(\"zipcodes.csv\")\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: boolean (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(inferSchema='True',delimiter=',').csv(\"zipcodesNoHeader.csv\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: string (nullable = true)\n",
      " |-- Long: string (nullable = true)\n",
      " |-- Xaxis: string (nullable = true)\n",
      " |-- Yaxis: string (nullable = true)\n",
      " |-- Zaxis: string (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: string (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: string (nullable = true)\n",
      " |-- TotalWages: string (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(header = 'true', inferSchema = 'false', delimiter = ',').csv(\"zipcodes.csv\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType() \\\n",
    ".add (\"RecordNumber\", IntegerType(), True)\\\n",
    ".add (\"Zipcode\" ,IntegerType() ,True)\\\n",
    ".add (\"ZipCodeType\" ,StringType(), True)\\\n",
    ".add (\"City\" ,StringType(), True)\\\n",
    ".add (\"State\", StringType(), True)\\\n",
    ".add (\"LocationType\", StringType(), True)\\\n",
    ".add (\"Lat\" ,DoubleType(), True)\\\n",
    ".add (\"Long\" ,DoubleType(), True)\\\n",
    ".add (\"Xaxis\", IntegerType(), True)\\\n",
    ".add (\"Yaxis\", DoubleType(), True)\\\n",
    ".add (\"Zaxis\", DoubleType(), True)\\\n",
    ".add (\"WorldRegion\", StringType(), True)\\\n",
    ".add (\"Country\" ,StringType(), True)\\\n",
    ".add (\"LocationText\" ,StringType(), True)\\\n",
    ".add (\"Location\" ,StringType() ,True)\\\n",
    ".add (\"Decommisioned\" ,BooleanType(), True)\\\n",
    ".add (\"TaxReturnsFiled\", StringType(), True)\\\n",
    ".add (\"EstimatedPopulation\" ,IntegerType(), True)\\\n",
    ".add (\"TotalWages\", IntegerType(), True)\\\n",
    ".add (\"Notes\" ,StringType(), True)\n",
    "      \n",
    "df_with_schema = spark.read.format(\"csv\").option(\"header\",True).schema(schema).load(\"zipcodes.csv\")\n",
    "df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_ID: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF = spark.read.options(delimiter=',').schema('trans_id INT, date STRING, cust_ID INT, amount DOUBLE, game STRING, equipment STRING, city STRING, state STRING, mode STRING').csv(\"trans.txt\")\n",
    "transDF.printSchema()\n",
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o6574.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 502.0 failed 1 times, most recent failure: Lost task 0.0 in stage 502.0 (TID 1327, vannhinh-ng02.ea.corp.samsungelectronics.net, executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745225243685078389409585_0502_m_000000_1327\\part-00000-9db24d75-3ff9-40fb-85f6-794cd2b3ccfe-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\r\n\t... 33 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745225243685078389409585_0502_m_000000_1327\\part-00000-9db24d75-3ff9-40fb-85f6-794cd2b3ccfe-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-313-d6f2186680ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"header\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"newzipcodes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o6574.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 502.0 failed 1 times, most recent failure: Lost task 0.0 in stage 502.0 (TID 1327, vannhinh-ng02.ea.corp.samsungelectronics.net, executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745225243685078389409585_0502_m_000000_1327\\part-00000-9db24d75-3ff9-40fb-85f6-794cd2b3ccfe-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\r\n\t... 33 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745225243685078389409585_0502_m_000000_1327\\part-00000-9db24d75-3ff9-40fb-85f6-794cd2b3ccfe-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True).csv(\"newzipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o6587.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 503.0 failed 1 times, most recent failure: Lost task 0.0 in stage 503.0 (TID 1328, vannhinh-ng02.ea.corp.samsungelectronics.net, executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745556102435554786885995_0503_m_000000_1328\\part-00000-de885931-4703-4e9f-9cfa-8f0ba9b85708-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\r\n\t... 33 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745556102435554786885995_0503_m_000000_1328\\part-00000-de885931-4703-4e9f-9cfa-8f0ba9b85708-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-315-8375c7083598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"newzipcodes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o6587.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 503.0 failed 1 times, most recent failure: Lost task 0.0 in stage 503.0 (TID 1328, vannhinh-ng02.ea.corp.samsungelectronics.net, executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745556102435554786885995_0503_m_000000_1328\\part-00000-de885931-4703-4e9f-9cfa-8f0ba9b85708-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\r\n\t... 33 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112081745556102435554786885995_0503_m_000000_1328\\part-00000-de885931-4703-4e9f-9cfa-8f0ba9b85708-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "df2.write.options(header='True', delimiter=',').csv(\"newzipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9ed8f365029d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'overwrite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"newzipcodes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2.write.mode('overwrite').csv(\"newzipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(value='RecordNumber\\tZipcode\\tZipCodeType\\tCity\\tState\\tLocationType'),\n",
       " Row(value='1\\t704\\tSTANDARD\\tPARC PARQUE\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='2\\t704\\tSTANDARD\\tPASEO COSTA DEL SUR\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='10\\t709\\tSTANDARD\\tBDA SAN LUIS\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='61391\\t76166\\tUNIQUE\\tCINGULAR WIRELESS\\tTX\\tNOT ACCEPTABLE'),\n",
       " Row(value='61392\\t76177\\tSTANDARD\\tFORT WORTH\\tTX\\tPRIMARY'),\n",
       " Row(value='61393\\t76177\\tSTANDARD\\tFT WORTH\\tTX\\tACCEPTABLE'),\n",
       " Row(value='4\\t704\\tSTANDARD\\tURB EUGENE RICE\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='39827\\t85209\\tSTANDARD\\tMESA\\tAZ\\tPRIMARY'),\n",
       " Row(value='39828\\t85210\\tSTANDARD\\tMESA\\tAZ\\tPRIMARY'),\n",
       " Row(value='49345\\t32046\\tSTANDARD\\tHILLIARD\\tFL\\tPRIMARY'),\n",
       " Row(value='49346\\t34445\\tPO BOX\\tHOLDER\\tFL\\tPRIMARY'),\n",
       " Row(value='49347\\t32564\\tSTANDARD\\tHOLT\\tFL\\tPRIMARY'),\n",
       " Row(value='49348\\t34487\\tPO BOX\\tHOMOSASSA\\tFL\\tPRIMARY'),\n",
       " Row(value='10\\t708\\tSTANDARD\\tBDA SAN LUIS\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='3\\t704\\tSTANDARD\\tSECT LANAUSSE\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='54354\\t36275\\tPO BOX\\tSPRING GARDEN\\tAL\\tPRIMARY'),\n",
       " Row(value='54355\\t35146\\tSTANDARD\\tSPRINGVILLE\\tAL\\tPRIMARY'),\n",
       " Row(value='54356\\t35585\\tSTANDARD\\tSPRUCE PINE\\tAL\\tPRIMARY'),\n",
       " Row(value='76511\\t27007\\tSTANDARD\\tASH HILL\\tNC\\tNOT ACCEPTABLE'),\n",
       " Row(value='76512\\t27203\\tSTANDARD\\tASHEBORO\\tNC\\tPRIMARY'),\n",
       " Row(value='76513\\t27204\\tPO BOX\\tASHEBORO\\tNC\\tPRIMARY')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.text(\"zipcodes.txt\")\n",
    "df.printSchema()\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header='True',inferSchema='True', delimiter='\\t').csv(\"zipcodes.txt\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transDF = spark.read.options(delimiter=',').schema('trans_id INT, date STRING, cust_id INT, amount DOUBLE, game STRING, equipment STRING, city STRING, state STRING, mode STRING').csv(\"trans.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select('cust_id','amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select(transDF.cust_id,transDF.amount).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select(transDF['cust_id'],transDF['amount']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twocolumns=['cust_id','amount']\n",
    "transDF.select(twocolumns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select([col for col in transDF.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "transDF.withColumn('trans_id',col('trans_id').cast('String')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.withColumn('trans_id',col('date').cast('integer')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 80.66|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|396.88|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002| 11.16|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|396.38|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002|197.62|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|387.26|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 55.78|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006|192.02|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 20.88|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|304.92|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|360.56|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|242.78|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 83.04|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 215.6|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 73.62|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|275.28|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 71.12|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 151.1|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 177.3|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008|103.62|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "transDF.withColumn('amount',col('amount')*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+----------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|new amount|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+----------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|     80.66|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|    396.88|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|     11.16|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|    396.38|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|    197.62|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|    387.26|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|     55.78|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|    192.02|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|     20.88|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|    304.92|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|    360.56|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|    242.78|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|     83.04|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|     215.6|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|     73.62|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|    275.28|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|     71.12|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|     151.1|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|     177.3|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|    103.62|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "transDF.withColumn('new amount',col('amount')*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+-------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|Country|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+-------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|    USA|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|    USA|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|    USA|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|    USA|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|    USA|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|    USA|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|    USA|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|    USA|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|    USA|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|    USA|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|    USA|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|    USA|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|    USA|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|    USA|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|    USA|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|    USA|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|    USA|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|    USA|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|    USA|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|    USA|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "transDF.withColumn(\"Country\", lit(\"USA\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|  cost|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "transDF.withColumnRenamed('amount','cost').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Anna, Rose, ]        |[Spark, Java, C++]|NY   |F     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Maria, Anne, Jones]  |[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]    |[CSharp, VB]      |NY   |M     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "data = [\n",
    "((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    "]\n",
    "schema = StructType([\n",
    "StructField('name', StructType([\n",
    "StructField('firstname', StringType(), True),\n",
    "StructField('middlename', StringType(), True),\n",
    "StructField('lastname', StringType(), True)\n",
    "])),\n",
    "StructField('languages', ArrayType(StringType()), True),\n",
    "StructField('state', StringType(), True),\n",
    "StructField('gender', StringType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|name                |languages         |state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|[Anna, Rose, ]      |[Spark, Java, C++]|NY   |F     |\n",
      "|[Maria, Anne, Jones]|[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]  |[CSharp, VB]      |NY   |M     |\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state != \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|name                |languages         |state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|[Anna, Rose, ]      |[Spark, Java, C++]|NY   |F     |\n",
      "|[Maria, Anne, Jones]|[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]  |[CSharp, VB]      |NY   |M     |\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~(df.state == \"OH\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(col(\"state\") == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender == 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----+------+\n",
      "|               name|         languages|state|gender|\n",
      "+-------------------+------------------+-----+------+\n",
      "|     [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "+-------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender != 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----+------+\n",
      "|               name|         languages|state|gender|\n",
      "+-------------------+------------------+-----+------+\n",
      "|     [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "+-------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.state == 'OH') & (df.gender =='M')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li=[\"OH\",\"CA\",\"DE\"]\n",
    "df.filter(df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.isin(li) == False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.startswith(\"N\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.endswith(\"H\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.contains(\"Y\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),(4,\"Rames Rose\"),(5,\"Rames rose\")]\n",
    "df2 = spark.createDataFrame(data = data2, schema=[\"id\",\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|      name|\n",
      "+---+----------+\n",
      "|  5|Rames rose|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(df2.name.like(\"%rose%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|        name|\n",
      "+---+------------+\n",
      "|  2|Michael Rose|\n",
      "|  4|  Rames Rose|\n",
      "|  5|  Rames rose|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----+------+\n",
      "|            name|         languages|state|gender|\n",
      "+----------------+------------------+-----+------+\n",
      "|[James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|  [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "+----------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.filter(array_contains(df.languages,\"Java\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+-----+------+\n",
      "|name                  |languages   |state|gender|\n",
      "+----------------------+------------+-----+------+\n",
      "|[Julia, , Williams]   |[CSharp, VB]|OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]|OH   |M     |\n",
      "+----------------------+------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.name.lastname ==\"Williams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+-----+------+\n",
      "|name                  |languages   |state|gender|\n",
      "+----------------------+------------+-----+------+\n",
      "|[Julia, , Williams]   |[CSharp, VB]|OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]|OH   |M     |\n",
      "+----------------------+------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.name.lastname ==\"Williams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transDF.select('cust_id','game').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transDF.select('cust_id','game').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count of customer ID & game : 43\n",
      "+--------+----------+-------+------+----------------------+-------------------+-------------+--------------+------+\n",
      "|trans_id|date      |cust_id|amount|game                  |equipment          |city         |state         |mode  |\n",
      "+--------+----------+-------+------+----------------------+-------------------+-------------+--------------+------+\n",
      "|13      |03-13-2011|4000010|107.8 |Team Sports           |Field Hockey       |Honolulu     |Hawaii        |credit|\n",
      "|48      |09-27-2011|4000007|157.94|Exercise & Fitness    |Exercise Bands     |Philadelphia |Pennsylvania  |credit|\n",
      "|20      |06-29-2011|4000005|41.55 |Exercise & Fitness    |Weightlifting Belts|New Orleans  |Louisiana     |credit|\n",
      "|33      |06-15-2011|4000008|154.15|Outdoor Recreation    |Lawn Games         |Nashville    |Tennessee     |credit|\n",
      "|49      |07-12-2011|4000010|144.59|Jumping               |Jumping Stilts     |Cambridge    |Massachusetts |credit|\n",
      "|46      |05-27-2011|4000001|52.29 |Gymnastics            |Vaulting Horses    |Cleveland    |Ohio          |credit|\n",
      "|55      |12-16-2011|4000006|106.11|Water Sports          |Swimming           |New York     |New York      |credit|\n",
      "|3       |06-05-2011|4000003|198.19|Gymnastics            |Gymnastics Rings   |Milwaukee    |Wisconsin     |credit|\n",
      "|6       |10-28-2011|4000005|27.89 |Puzzles               |Jigsaw Puzzles     |Charleston   |South Carolina|credit|\n",
      "|12      |02-08-2011|4000009|41.52 |Indoor Games          |Bowling            |San Francisco|California    |credit|\n",
      "|10      |05-29-2011|4000007|180.28|Outdoor Recreation    |Archery            |Reno         |Nevada        |credit|\n",
      "|47      |10-23-2011|4000008|100.1 |Outdoor Play Equipment|Swing Sets         |Everett      |Washington    |credit|\n",
      "|24      |06-10-2011|4000003|151.2 |Water Sports          |Surfing            |Plano        |Texas         |credit|\n",
      "|52      |02-04-2011|4000005|44.82 |Outdoor Play Equipment|Lawn Water Slides  |Hampton      |Virginia      |cash  |\n",
      "|15      |10-20-2011|4000001|137.64|Combat Sports         |Fencing            |Honolulu     |Hawaii        |credit|\n",
      "|43      |04-22-2011|4000004|32.34 |Water Sports          |Water Polo         |Las Vegas    |Nevada        |cash  |\n",
      "|16      |05-28-2011|4000010|35.56 |Exercise & Fitness    |Free Weight Bars   |Columbia     |South Carolina|credit|\n",
      "|14      |02-25-2011|4000010|36.81 |Gymnastics            |Vaulting Horses    |Los Angeles  |California    |credit|\n",
      "|22      |10-10-2011|4000009|19.64 |Water Sports          |Kitesurfing        |Saint Paul   |Minnesota     |credit|\n",
      "|7       |07-14-2011|4000006|96.01 |Outdoor Play Equipment|Sandboxes          |Columbus     |Ohio          |credit|\n",
      "+--------+----------+-------+------+----------------------+-------------------+-------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropDisDF = transDF.dropDuplicates(['cust_id','game'])\n",
    "print(\"Distinct count of customer ID & game : \" + str(dropDisDF.count()))\n",
    "dropDisDF.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------------+--------------------------+-----------+----------+------+\n",
      "|trans_id|date      |cust_ID|amount|game              |equipment                 |city       |state     |mode  |\n",
      "+--------+----------+-------+------+------------------+--------------------------+-----------+----------+------+\n",
      "|0       |06-26-2011|4000001|40.33 |Exercise & Fitness|Cardio Machine Accessories|Clarksville|Tennessee |credit|\n",
      "|1       |05-26-2011|4000002|198.44|Exercise & Fitness|Weightlifting Gloves      |Long Beach |California|credit|\n",
      "+--------+----------+-------+------+------------------+--------------------------+-----------+----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF = spark.read.options(delimiter=',')\\\n",
    ".schema('trans_id INT, date STRING, cust_ID INT, amount DOUBLE, game STRING, equipment STRING, city STRING, state STRING, mode STRING')\\\n",
    ".csv(\"trans.txt\")\n",
    "\n",
    "transDF.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+----------------------+------------------------------+-------------+-------------+------+\n",
      "|trans_id|date      |cust_ID|amount|game                  |equipment                     |city         |state        |mode  |\n",
      "+--------+----------+-------+------+----------------------+------------------------------+-------------+-------------+------+\n",
      "|1       |05-26-2011|4000002|198.44|Exercise & Fitness    |Weightlifting Gloves          |Long Beach   |California   |credit|\n",
      "|3       |06-05-2011|4000003|198.19|Gymnastics            |Gymnastics Rings              |Milwaukee    |Wisconsin    |credit|\n",
      "|58      |12-29-2011|4000002|194.86|Water Sports          |Windsurfing                   |Oklahoma City|Oklahoma     |credit|\n",
      "|5       |02-14-2011|4000004|193.63|Outdoor Recreation    |Camping & Backpacking & Hiking|Chicago      |Illinois     |credit|\n",
      "|35      |04-12-2011|4000008|185.26|Games                 |Board Games                   |Centennial   |Colorado     |credit|\n",
      "|10      |05-29-2011|4000007|180.28|Outdoor Recreation    |Archery                       |Reno         |Nevada       |credit|\n",
      "|57      |12-20-2011|4000003|178.2 |Outdoor Recreation    |Skating                       |San Jose     |California   |credit|\n",
      "|56      |06-21-2011|4000002|176.63|Outdoor Recreation    |Geocaching                    |Boston       |Massachusetts|credit|\n",
      "|39      |03-12-2011|4000006|174.36|Outdoor Play Equipment|Swing Sets                    |Pittsburgh   |Pennsylvania |credit|\n",
      "|40      |11-07-2011|4000005|165.1 |Team Sports           |Cheerleading                  |Reno         |Nevada       |credit|\n",
      "+--------+----------+-------+------+----------------------+------------------------------+-------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.sort('amount',ascending = False).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|cust_ID|count|\n",
      "+-------+-----+\n",
      "|4000001|    8|\n",
      "|4000002|    6|\n",
      "|4000003|    3|\n",
      "|4000004|    5|\n",
      "|4000005|    5|\n",
      "|4000006|    5|\n",
      "|4000007|    6|\n",
      "|4000008|   10|\n",
      "|4000009|    6|\n",
      "|4000010|    6|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').count().sort('cust_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+-----------+\n",
      "|cust_id|min(trans_id)|min(cust_ID)|min(amount)|\n",
      "+-------+-------------+------------+-----------+\n",
      "|4000009|           11|     4000009|      19.64|\n",
      "|4000001|            0|     4000001|      21.43|\n",
      "|4000006|            7|     4000006|      10.44|\n",
      "|4000005|            6|     4000005|      27.89|\n",
      "|4000008|           17|     4000008|       5.03|\n",
      "+-------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').min().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_id|min(amount)|\n",
      "+-------+-----------+\n",
      "|4000009|      19.64|\n",
      "|4000001|      21.43|\n",
      "|4000006|      10.44|\n",
      "|4000005|      27.89|\n",
      "|4000008|       5.03|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').min('amount').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|cust_ID|min_transaction_amount|\n",
      "+-------+----------------------+\n",
      "|4000009|                 19.64|\n",
      "|4000001|                 21.43|\n",
      "|4000006|                 10.44|\n",
      "|4000005|                 27.89|\n",
      "|4000008|                  5.03|\n",
      "+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "transDF.groupBy('cust_ID').agg(f.min('amount').alias('min_transaction_amount')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|cust_id|min_trans|\n",
      "+-------+---------+\n",
      "|4000009|    19.64|\n",
      "|4000001|    21.43|\n",
      "|4000006|    10.44|\n",
      "|4000005|    27.89|\n",
      "|4000008|     5.03|\n",
      "|4000004|    28.11|\n",
      "|4000003|    151.2|\n",
      "|4000010|    35.56|\n",
      "|4000007|     20.2|\n",
      "|4000002|     5.58|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').agg(f.min('amount').alias('min_trans')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_id|min(amount)|\n",
      "+-------+-----------+\n",
      "|4000001|      21.43|\n",
      "|4000002|       5.58|\n",
      "|4000003|      151.2|\n",
      "|4000004|      28.11|\n",
      "|4000005|      27.89|\n",
      "|4000006|      10.44|\n",
      "|4000007|       20.2|\n",
      "|4000008|       5.03|\n",
      "|4000009|      19.64|\n",
      "|4000010|      35.56|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').agg(f.min('amount')).sort('cust_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|cust_id|       sum(amount)|\n",
      "+-------+------------------+\n",
      "|4000009|            457.83|\n",
      "|4000001|            651.05|\n",
      "|4000006|            539.38|\n",
      "|4000005|            325.15|\n",
      "|4000008|            859.42|\n",
      "|4000004|            337.06|\n",
      "|4000003| 527.5899999999999|\n",
      "|4000010|447.09000000000003|\n",
      "|4000007| 699.5500000000001|\n",
      "|4000002|            706.97|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').sum('amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|cust_id|      total_amount|\n",
      "+-------+------------------+\n",
      "|4000009|            457.83|\n",
      "|4000001|            651.05|\n",
      "|4000006|            539.38|\n",
      "|4000005|            325.15|\n",
      "|4000008|            859.42|\n",
      "|4000004|            337.06|\n",
      "|4000003| 527.5899999999999|\n",
      "|4000010|447.09000000000003|\n",
      "|4000007| 699.5500000000001|\n",
      "|4000002|            706.97|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').agg(f.sum('amount').alias('total_amount')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|cust_ID|         first(game)|\n",
      "+-------+--------------------+\n",
      "|4000009|Outdoor Play Equi...|\n",
      "|4000001|  Exercise & Fitness|\n",
      "|4000006|Outdoor Play Equi...|\n",
      "|4000005|             Puzzles|\n",
      "|4000008|        Water Sports|\n",
      "|4000004|  Outdoor Recreation|\n",
      "|4000003|          Gymnastics|\n",
      "|4000010|         Team Sports|\n",
      "|4000007|  Outdoor Recreation|\n",
      "|4000002|  Exercise & Fitness|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.first('game')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------------+--------------------+-------------+-------------+------+\n",
      "|trans_id|      date|cust_ID|amount|              game|           equipment|         city|        state|  mode|\n",
      "+--------+----------+-------+------+------------------+--------------------+-------------+-------------+------+\n",
      "|       1|05-26-2011|4000002|198.44|Exercise & Fitness|Weightlifting Gloves|   Long Beach|   California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|Exercise & Fitness|Weightlifting Mac...|      Anaheim|   California|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|       Team Sports|        Field Hockey|  Nashville  |    Tennessee|credit|\n",
      "|      51|02-17-2011|4000002| 32.65|      Water Sports|        Life Jackets|     Columbus|      Georgia|  cash|\n",
      "|      56|06-21-2011|4000002|176.63|Outdoor Recreation|          Geocaching|       Boston|Massachusetts|credit|\n",
      "|      58|12-29-2011|4000002|194.86|      Water Sports|         Windsurfing|Oklahoma City|     Oklahoma|credit|\n",
      "+--------+----------+-------+------+------------------+--------------------+-------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.filter(transDF.cust_ID == 4000002).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_ID|count(game)|\n",
      "+-------+-----------+\n",
      "|4000009|          5|\n",
      "|4000001|          6|\n",
      "|4000006|          4|\n",
      "|4000005|          5|\n",
      "|4000008|          5|\n",
      "|4000004|          3|\n",
      "|4000003|          3|\n",
      "|4000010|          5|\n",
      "|4000007|          3|\n",
      "|4000002|          4|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.countDistinct('game')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|cust_ID|collect_list(game)                                                                                                                        |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|4000009|[Outdoor Play Equipment, Indoor Games, Water Sports, Gymnastics, Indoor Games, Combat Sports]                                             |\n",
      "|4000001|[Exercise & Fitness, Combat Sports, Outdoor Recreation, Water Sports, Water Sports, Exercise & Fitness, Gymnastics, Winter Sports]        |\n",
      "|4000006|[Outdoor Play Equipment, Winter Sports, Jumping, Outdoor Play Equipment, Water Sports]                                                    |\n",
      "|4000005|[Puzzles, Exercise & Fitness, Air Sports, Team Sports, Outdoor Play Equipment]                                                            |\n",
      "|4000008|[Water Sports, Team Sports, Water Sports, Team Sports, Games, Team Sports, Outdoor Recreation, Team Sports, Games, Outdoor Play Equipment]|\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_list('game')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------+\n",
      "|cust_ID|collect_set(game)                                                                               |\n",
      "+-------+------------------------------------------------------------------------------------------------+\n",
      "|4000009|[Combat Sports, Water Sports, Indoor Games, Gymnastics, Outdoor Play Equipment]                 |\n",
      "|4000001|[Combat Sports, Water Sports, Outdoor Recreation, Gymnastics, Winter Sports, Exercise & Fitness]|\n",
      "|4000006|[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]                                  |\n",
      "|4000005|[Puzzles, Team Sports, Air Sports, Exercise & Fitness, Outdoor Play Equipment]                  |\n",
      "|4000008|[Team Sports, Water Sports, Outdoor Recreation, Games, Outdoor Play Equipment]                  |\n",
      "+-------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_set('game')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------------+\n",
      "|cust_ID|collect_set(game)                                             |\n",
      "+-------+--------------------------------------------------------------+\n",
      "|4000006|[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]|\n",
      "|4000010|[Team Sports, Jumping, Gymnastics, Games, Exercise & Fitness] |\n",
      "+-------+--------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_set('game')).filter(f.array_contains(f.col('collect_set(game)'),'Jumping')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
      "|cust_ID|collect_set(game)                                                                               |game_list_string                                                                         |\n",
      "+-------+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
      "|4000009|[Combat Sports, Water Sports, Indoor Games, Gymnastics, Outdoor Play Equipment]                 |Combat Sports,Water Sports,Indoor Games,Gymnastics,Outdoor Play Equipment                |\n",
      "|4000001|[Combat Sports, Water Sports, Outdoor Recreation, Gymnastics, Winter Sports, Exercise & Fitness]|Combat Sports,Water Sports,Outdoor Recreation,Gymnastics,Winter Sports,Exercise & Fitness|\n",
      "|4000006|[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]                                  |Water Sports,Jumping,Winter Sports,Outdoor Play Equipment                                |\n",
      "|4000005|[Puzzles, Team Sports, Air Sports, Exercise & Fitness, Outdoor Play Equipment]                  |Puzzles,Team Sports,Air Sports,Exercise & Fitness,Outdoor Play Equipment                 |\n",
      "|4000008|[Team Sports, Water Sports, Outdoor Recreation, Games, Outdoor Play Equipment]                  |Team Sports,Water Sports,Outdoor Recreation,Games,Outdoor Play Equipment                 |\n",
      "+-------+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_set('game')).withColumn('game_list_string',f.concat_ws(',',f.col('collect_set(game)'))).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "transGameStringDF =  transDF.groupBy('cust_id').agg(f.collect_set('game')).withColumn('game_string',f.concat_ws(',',f.col('collect_set(game)'))).select('cust_ID','game_string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------------------------------------+\n",
      "|cust_ID|game_string                                                                              |\n",
      "+-------+-----------------------------------------------------------------------------------------+\n",
      "|4000009|Combat Sports,Water Sports,Indoor Games,Gymnastics,Outdoor Play Equipment                |\n",
      "|4000001|Combat Sports,Water Sports,Outdoor Recreation,Gymnastics,Winter Sports,Exercise & Fitness|\n",
      "|4000006|Water Sports,Jumping,Winter Sports,Outdoor Play Equipment                                |\n",
      "|4000005|Puzzles,Team Sports,Air Sports,Exercise & Fitness,Outdoor Play Equipment                 |\n",
      "|4000008|Team Sports,Water Sports,Outdoor Recreation,Games,Outdoor Play Equipment                 |\n",
      "+-------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
      "|cust_ID|game_string                                                                              |game_array                                                                                      |\n",
      "+-------+-----------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
      "|4000009|Combat Sports,Water Sports,Indoor Games,Gymnastics,Outdoor Play Equipment                |[Combat Sports, Water Sports, Indoor Games, Gymnastics, Outdoor Play Equipment]                 |\n",
      "|4000001|Combat Sports,Water Sports,Outdoor Recreation,Gymnastics,Winter Sports,Exercise & Fitness|[Combat Sports, Water Sports, Outdoor Recreation, Gymnastics, Winter Sports, Exercise & Fitness]|\n",
      "|4000006|Water Sports,Jumping,Winter Sports,Outdoor Play Equipment                                |[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]                                  |\n",
      "|4000005|Puzzles,Team Sports,Air Sports,Exercise & Fitness,Outdoor Play Equipment                 |[Puzzles, Team Sports, Air Sports, Exercise & Fitness, Outdoor Play Equipment]                  |\n",
      "|4000008|Team Sports,Water Sports,Outdoor Recreation,Games,Outdoor Play Equipment                 |[Team Sports, Water Sports, Outdoor Recreation, Games, Outdoor Play Equipment]                  |\n",
      "+-------+-----------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array',f.split('game_string',',')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------+\n",
      "|cust_ID|         game_string|          game_array|num_game|\n",
      "+-------+--------------------+--------------------+--------+\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|       5|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|       6|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|       4|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|       5|\n",
      "|4000008|Team Sports,Water...|[Team Sports, Wat...|       5|\n",
      "+-------+--------------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array', f.split('game_string',',')).withColumn('num_game',f.size('game_array')).show(5,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------+--------------------+\n",
      "|cust_ID|         game_string|          game_array|   first_game|           last_game|\n",
      "+-------+--------------------+--------------------+-------------+--------------------+\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|Combat Sports|Outdoor Play Equi...|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|Combat Sports|  Exercise & Fitness|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...| Water Sports|Outdoor Play Equi...|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|      Puzzles|Outdoor Play Equi...|\n",
      "|4000008|Team Sports,Water...|[Team Sports, Wat...|  Team Sports|Outdoor Play Equi...|\n",
      "+-------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array',f.split('game_string',',')) \\\n",
    ".withColumn('first_game',f.element_at('game_array',1)) \\\n",
    ".withColumn('last_game',f.element_at('game_array',-1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|cust_ID|         game_string|          game_array|         single_game|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|       Combat Sports|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|        Water Sports|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|        Indoor Games|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|          Gymnastics|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|Outdoor Play Equi...|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|       Combat Sports|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|        Water Sports|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|  Outdoor Recreation|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|          Gymnastics|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|       Winter Sports|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|  Exercise & Fitness|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|        Water Sports|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|             Jumping|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|       Winter Sports|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|Outdoor Play Equi...|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|             Puzzles|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|         Team Sports|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|          Air Sports|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|  Exercise & Fitness|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|Outdoor Play Equi...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array',f.split('game_string',',')).withColumn('single_game',f.explode('game_array')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+---------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|day_month|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+---------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|    06-26|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|    05-26|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|    06-01|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|    06-05|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|    12-17|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|    02-14|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|    10-28|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|    07-14|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|    01-17|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|    05-17|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|    05-29|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|    06-18|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|    02-08|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|    03-13|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|    02-25|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|    10-20|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|    05-28|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|    10-18|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|    11-18|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|    08-28|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.show()\n",
    "transDF.withColumn('day_month',f.substring('date',1,5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|06-26-2011|\n",
      "|05-26-2011|\n",
      "|06-01-2011|\n",
      "|06-05-2011|\n",
      "|12-17-2011|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+\n",
      "|day_month_year|\n",
      "+--------------+\n",
      "|    06-26-2011|\n",
      "|    05-26-2011|\n",
      "|    06-01-2011|\n",
      "|    06-05-2011|\n",
      "|    12-17-2011|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select(f.col('date')).show(5)\n",
    "transDF.select(f.col('date').alias('day_month_year')).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------------+--------------------+-----------+----------+------+--------------+\n",
      "|trans_id|      date|cust_ID|amount|              game|           equipment|       city|     state|  mode|month_in_05_06|\n",
      "+--------+----------+-------+------+------------------+--------------------+-----------+----------+------+--------------+\n",
      "|       0|06-26-2011|4000001| 40.33|Exercise & Fitness|Cardio Machine Ac...|Clarksville| Tennessee|credit|         false|\n",
      "|       1|05-26-2011|4000002|198.44|Exercise & Fitness|Weightlifting Gloves| Long Beach|California|credit|          true|\n",
      "|       2|06-01-2011|4000002|  5.58|Exercise & Fitness|Weightlifting Mac...|    Anaheim|California|credit|         false|\n",
      "|       3|06-05-2011|4000003|198.19|        Gymnastics|    Gymnastics Rings|  Milwaukee| Wisconsin|credit|         false|\n",
      "|       4|12-17-2011|4000002| 98.81|       Team Sports|        Field Hockey|Nashville  | Tennessee|credit|          true|\n",
      "+--------+----------+-------+------+------------------+--------------------+-----------+----------+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.withColumn('month_in_05_06',f.substring('date',1,2).isin(['05','12'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+-----------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|       city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+-----------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|Clarksville|     Tennessee|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|    Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|  Milwaukee|     Wisconsin|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|   Columbus|          Ohio|credit|\n",
      "|      20|06-29-2011|4000005| 41.55|  Exercise & Fitness| Weightlifting Belts|New Orleans|     Louisiana|credit|\n",
      "|      24|06-10-2011|4000003| 151.2|        Water Sports|             Surfing|      Plano|         Texas|credit|\n",
      "|      29|06-03-2011|4000001| 126.9|  Outdoor Recreation|             Hunting|    Phoenix|       Arizona|credit|\n",
      "|      33|06-15-2011|4000008|154.15|  Outdoor Recreation|          Lawn Games|Nashville  |     Tennessee|credit|\n",
      "|      53|06-12-2011|4000004| 44.46|        Water Sports|Scuba Diving & Sn...| Charleston|South Carolina|  cash|\n",
      "|      56|06-21-2011|4000002|176.63|  Outdoor Recreation|          Geocaching|     Boston| Massachusetts|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+-----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.filter(f.substring('date',0,2).isin(['06'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_ID: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_ID: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.withColumn('month',f.substring('date',0,2)).printSchema()\n",
    "transDF.withColumn('month',f.substring('date',0,2).cast('INT')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-225-4cbbffdfdb64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_inner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Roll_No'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_inner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df_inner = df1.join(df2, on=['Roll_No'], how='inner')\n",
    "df_inner.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.sql(\"select 'spark' as hello \")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|    _1|   _2|\n",
      "+------+-----+\n",
      "|  Java|10000|\n",
      "|Python|10000|\n",
      "| Scala| 5000|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([(\"Java\",\"10000\"),(\"Python\",\"10000\"),(\"Scala\",\"5000\")]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = spark.sparkContext.textFile(\"/path/textFile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = spark.sparkContext.wholeTextFiles(\"/path/textFile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transRDD = spark.sparkContext.textFile(\"trans.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000000,06-26-2011,4000001,040.33,Exercise & Fitness,Cardio Machine Accessories,Clarksville,Tennessee,credit',\n",
       " '00000001,05-26-2011,4000002,198.44,Exercise & Fitness,Weightlifting Gloves,Long Beach,California,credit',\n",
       " '00000002,06-01-2011,4000002,005.58,Exercise & Fitness,Weightlifting Machine Accessories,Anaheim,California,credit',\n",
       " '00000003,06-05-2011,4000003,198.19,Gymnastics,Gymnastics Rings,Milwaukee,Wisconsin,credit',\n",
       " '00000004,12-17-2011,4000002,098.81,Team Sports,Field Hockey,Nashville  ,Tennessee,credit',\n",
       " '00000005,02-14-2011,4000004,193.63,Outdoor Recreation,Camping & Backpacking & Hiking,Chicago,Illinois,credit',\n",
       " '00000006,10-28-2011,4000005,027.89,Puzzles,Jigsaw Puzzles,Charleston,South Carolina,credit',\n",
       " '00000007,07-14-2011,4000006,096.01,Outdoor Play Equipment,Sandboxes,Columbus,Ohio,credit',\n",
       " '00000008,01-17-2011,4000006,010.44,Winter Sports,Snowmobiling,Des Moines,Iowa,credit',\n",
       " '00000009,05-17-2011,4000006,152.46,Jumping,Bungee Jumping,St. Petersburg,Florida,credit',\n",
       " '00000010,05-29-2011,4000007,180.28,Outdoor Recreation,Archery,Reno,Nevada,credit',\n",
       " '00000011,06-18-2011,4000009,121.39,Outdoor Play Equipment,Swing Sets,Columbus,Ohio,credit',\n",
       " '00000012,02-08-2011,4000009,041.52,Indoor Games,Bowling,San Francisco,California,credit',\n",
       " '00000013,03-13-2011,4000010,107.80,Team Sports,Field Hockey,Honolulu  ,Hawaii,credit',\n",
       " '00000014,02-25-2011,4000010,036.81,Gymnastics,Vaulting Horses,Los Angeles,California,credit',\n",
       " '00000015,10-20-2011,4000001,137.64,Combat Sports,Fencing,Honolulu  ,Hawaii,credit',\n",
       " '00000016,05-28-2011,4000010,035.56,Exercise & Fitness,Free Weight Bars,Columbia,South Carolina,credit',\n",
       " '00000017,10-18-2011,4000008,075.55,Water Sports,Scuba Diving & Snorkeling,Omaha,Nebraska,credit',\n",
       " '00000018,11-18-2011,4000008,088.65,Team Sports,Baseball,Salt Lake City,Utah,credit',\n",
       " '00000019,08-28-2011,4000008,051.81,Water Sports,Life Jackets,Newark,New Jersey,credit',\n",
       " '00000020,06-29-2011,4000005,041.55,Exercise & Fitness,Weightlifting Belts,New Orleans,Louisiana,credit',\n",
       " '00000021,02-14-2011,4000005,045.79,Air Sports,Parachutes,New York,New York,credit',\n",
       " '00000022,10-10-2011,4000009,019.64,Water Sports,Kitesurfing,Saint Paul,Minnesota,credit',\n",
       " '00000023,05-02-2011,4000009,099.50,Gymnastics,Gymnastics Rings,Springfield,Illinois,credit',\n",
       " '00000024,06-10-2011,4000003,151.20,Water Sports,Surfing,Plano,Texas,credit',\n",
       " '00000025,10-14-2011,4000009,144.20,Indoor Games,Darts,Phoenix,Arizona,credit',\n",
       " '00000026,10-11-2011,4000009,031.58,Combat Sports,Wrestling,Orange,California,credit',\n",
       " '00000027,09-29-2011,4000010,066.40,Games,Mahjong,Fremont,California,credit',\n",
       " '00000028,05-12-2011,4000008,079.78,Team Sports,Cricket,Lexington,Kentucky,credit',\n",
       " '00000029,06-03-2011,4000001,126.90,Outdoor Recreation,Hunting,Phoenix,Arizona,credit',\n",
       " '00000030,03-14-2011,4000001,047.05,Water Sports,Swimming,Lincoln,Nebraska,credit',\n",
       " '00000031,11-28-2011,4000008,005.03,Games,Dice & Dice Sets,Los Angeles,California,credit',\n",
       " '00000032,01-29-2011,4000008,020.13,Team Sports,Soccer,Springfield,Illinois,credit',\n",
       " '00000033,06-15-2011,4000008,154.15,Outdoor Recreation,Lawn Games,Nashville  ,Tennessee,credit',\n",
       " '00000034,05-06-2011,4000008,098.96,Team Sports,Indoor Volleyball,Atlanta,Georgia,credit',\n",
       " '00000035,04-12-2011,4000008,185.26,Games,Board Games,Centennial,Colorado,credit',\n",
       " '00000036,10-13-2011,4000007,035.66,Team Sports,Football,Saint Paul,Minnesota,credit',\n",
       " '00000037,04-19-2011,4000007,020.20,Outdoor Recreation,Shooting Games,San Diego,California,credit',\n",
       " '00000038,08-05-2011,4000007,150.60,Outdoor Recreation,Camping & Backpacking & Hiking,Hampton  ,Virginia,credit',\n",
       " '00000039,03-12-2011,4000006,174.36,Outdoor Play Equipment,Swing Sets,Pittsburgh,Pennsylvania,credit',\n",
       " '00000040,11-07-2011,4000005,165.10,Team Sports,Cheerleading,Reno,Nevada,credit',\n",
       " '00000041,04-16-2011,4000004,028.11,Indoor Games,Bowling,Westminster,Colorado,cash',\n",
       " '00000042,09-10-2011,4000004,038.52,Outdoor Recreation,Tetherball,Denton,Texas,cash',\n",
       " '00000043,04-22-2011,4000004,032.34,Water Sports,Water Polo,Las Vegas,Nevada,cash',\n",
       " '00000044,09-11-2011,4000001,135.37,Water Sports,Surfing,Seattle,Washington,credit',\n",
       " '00000045,11-27-2011,4000001,090.04,Exercise & Fitness,Abdominal Equipment,Honolulu  ,Hawaii,credit',\n",
       " '00000046,05-27-2011,4000001,052.29,Gymnastics,Vaulting Horses,Cleveland,Ohio,credit',\n",
       " '00000047,10-23-2011,4000008,100.10,Outdoor Play Equipment,Swing Sets,Everett,Washington,credit',\n",
       " '00000048,09-27-2011,4000007,157.94,Exercise & Fitness,Exercise Bands,Philadelphia,Pennsylvania,credit',\n",
       " '00000049,07-12-2011,4000010,144.59,Jumping,Jumping Stilts,Cambridge,Massachusetts,credit',\n",
       " '00000050,10-20-2011,4000010,055.93,Jumping,Pogo Sticks,Everett,Washington,credit',\n",
       " '00000051,02-17-2011,4000002,032.65,Water Sports,Life Jackets,Columbus,Georgia,cash',\n",
       " '00000052,02-04-2011,4000005,044.82,Outdoor Play Equipment,Lawn Water Slides,Hampton  ,Virginia,cash',\n",
       " '00000053,06-12-2011,4000004,044.46,Water Sports,Scuba Diving & Snorkeling,Charleston,South Carolina,cash',\n",
       " '00000054,10-03-2011,4000007,154.87,Outdoor Recreation,Running,Long Beach,California,credit',\n",
       " '00000055,12-16-2011,4000006,106.11,Water Sports,Swimming,New York,New York,credit',\n",
       " '00000056,06-21-2011,4000002,176.63,Outdoor Recreation,Geocaching,Boston,Massachusetts,credit',\n",
       " '00000057,12-20-2011,4000003,178.20,Outdoor Recreation,Skating,San Jose,California,credit',\n",
       " '00000058,12-29-2011,4000002,194.86,Water Sports,Windsurfing,Oklahoma City,Oklahoma,credit',\n",
       " '00000059,11-07-2011,4000001,021.43,Winter Sports,Snowboarding,Philadelphia,Pennsylvania,cash']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000000',\n",
       " '06-26-2011',\n",
       " '4000001',\n",
       " '040.33',\n",
       " 'Exercise & Fitness',\n",
       " 'Cardio Machine Accessories',\n",
       " 'Clarksville',\n",
       " 'Tennessee',\n",
       " 'credit',\n",
       " '00000001',\n",
       " '05-26-2011',\n",
       " '4000002',\n",
       " '198.44',\n",
       " 'Exercise & Fitness',\n",
       " 'Weightlifting Gloves',\n",
       " 'Long Beach',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000002',\n",
       " '06-01-2011',\n",
       " '4000002',\n",
       " '005.58',\n",
       " 'Exercise & Fitness',\n",
       " 'Weightlifting Machine Accessories',\n",
       " 'Anaheim',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000003',\n",
       " '06-05-2011',\n",
       " '4000003',\n",
       " '198.19',\n",
       " 'Gymnastics',\n",
       " 'Gymnastics Rings',\n",
       " 'Milwaukee',\n",
       " 'Wisconsin',\n",
       " 'credit',\n",
       " '00000004',\n",
       " '12-17-2011',\n",
       " '4000002',\n",
       " '098.81',\n",
       " 'Team Sports',\n",
       " 'Field Hockey',\n",
       " 'Nashville  ',\n",
       " 'Tennessee',\n",
       " 'credit',\n",
       " '00000005',\n",
       " '02-14-2011',\n",
       " '4000004',\n",
       " '193.63',\n",
       " 'Outdoor Recreation',\n",
       " 'Camping & Backpacking & Hiking',\n",
       " 'Chicago',\n",
       " 'Illinois',\n",
       " 'credit',\n",
       " '00000006',\n",
       " '10-28-2011',\n",
       " '4000005',\n",
       " '027.89',\n",
       " 'Puzzles',\n",
       " 'Jigsaw Puzzles',\n",
       " 'Charleston',\n",
       " 'South Carolina',\n",
       " 'credit',\n",
       " '00000007',\n",
       " '07-14-2011',\n",
       " '4000006',\n",
       " '096.01',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Sandboxes',\n",
       " 'Columbus',\n",
       " 'Ohio',\n",
       " 'credit',\n",
       " '00000008',\n",
       " '01-17-2011',\n",
       " '4000006',\n",
       " '010.44',\n",
       " 'Winter Sports',\n",
       " 'Snowmobiling',\n",
       " 'Des Moines',\n",
       " 'Iowa',\n",
       " 'credit',\n",
       " '00000009',\n",
       " '05-17-2011',\n",
       " '4000006',\n",
       " '152.46',\n",
       " 'Jumping',\n",
       " 'Bungee Jumping',\n",
       " 'St. Petersburg',\n",
       " 'Florida',\n",
       " 'credit',\n",
       " '00000010',\n",
       " '05-29-2011',\n",
       " '4000007',\n",
       " '180.28',\n",
       " 'Outdoor Recreation',\n",
       " 'Archery',\n",
       " 'Reno',\n",
       " 'Nevada',\n",
       " 'credit',\n",
       " '00000011',\n",
       " '06-18-2011',\n",
       " '4000009',\n",
       " '121.39',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Swing Sets',\n",
       " 'Columbus',\n",
       " 'Ohio',\n",
       " 'credit',\n",
       " '00000012',\n",
       " '02-08-2011',\n",
       " '4000009',\n",
       " '041.52',\n",
       " 'Indoor Games',\n",
       " 'Bowling',\n",
       " 'San Francisco',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000013',\n",
       " '03-13-2011',\n",
       " '4000010',\n",
       " '107.80',\n",
       " 'Team Sports',\n",
       " 'Field Hockey',\n",
       " 'Honolulu  ',\n",
       " 'Hawaii',\n",
       " 'credit',\n",
       " '00000014',\n",
       " '02-25-2011',\n",
       " '4000010',\n",
       " '036.81',\n",
       " 'Gymnastics',\n",
       " 'Vaulting Horses',\n",
       " 'Los Angeles',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000015',\n",
       " '10-20-2011',\n",
       " '4000001',\n",
       " '137.64',\n",
       " 'Combat Sports',\n",
       " 'Fencing',\n",
       " 'Honolulu  ',\n",
       " 'Hawaii',\n",
       " 'credit',\n",
       " '00000016',\n",
       " '05-28-2011',\n",
       " '4000010',\n",
       " '035.56',\n",
       " 'Exercise & Fitness',\n",
       " 'Free Weight Bars',\n",
       " 'Columbia',\n",
       " 'South Carolina',\n",
       " 'credit',\n",
       " '00000017',\n",
       " '10-18-2011',\n",
       " '4000008',\n",
       " '075.55',\n",
       " 'Water Sports',\n",
       " 'Scuba Diving & Snorkeling',\n",
       " 'Omaha',\n",
       " 'Nebraska',\n",
       " 'credit',\n",
       " '00000018',\n",
       " '11-18-2011',\n",
       " '4000008',\n",
       " '088.65',\n",
       " 'Team Sports',\n",
       " 'Baseball',\n",
       " 'Salt Lake City',\n",
       " 'Utah',\n",
       " 'credit',\n",
       " '00000019',\n",
       " '08-28-2011',\n",
       " '4000008',\n",
       " '051.81',\n",
       " 'Water Sports',\n",
       " 'Life Jackets',\n",
       " 'Newark',\n",
       " 'New Jersey',\n",
       " 'credit',\n",
       " '00000020',\n",
       " '06-29-2011',\n",
       " '4000005',\n",
       " '041.55',\n",
       " 'Exercise & Fitness',\n",
       " 'Weightlifting Belts',\n",
       " 'New Orleans',\n",
       " 'Louisiana',\n",
       " 'credit',\n",
       " '00000021',\n",
       " '02-14-2011',\n",
       " '4000005',\n",
       " '045.79',\n",
       " 'Air Sports',\n",
       " 'Parachutes',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'credit',\n",
       " '00000022',\n",
       " '10-10-2011',\n",
       " '4000009',\n",
       " '019.64',\n",
       " 'Water Sports',\n",
       " 'Kitesurfing',\n",
       " 'Saint Paul',\n",
       " 'Minnesota',\n",
       " 'credit',\n",
       " '00000023',\n",
       " '05-02-2011',\n",
       " '4000009',\n",
       " '099.50',\n",
       " 'Gymnastics',\n",
       " 'Gymnastics Rings',\n",
       " 'Springfield',\n",
       " 'Illinois',\n",
       " 'credit',\n",
       " '00000024',\n",
       " '06-10-2011',\n",
       " '4000003',\n",
       " '151.20',\n",
       " 'Water Sports',\n",
       " 'Surfing',\n",
       " 'Plano',\n",
       " 'Texas',\n",
       " 'credit',\n",
       " '00000025',\n",
       " '10-14-2011',\n",
       " '4000009',\n",
       " '144.20',\n",
       " 'Indoor Games',\n",
       " 'Darts',\n",
       " 'Phoenix',\n",
       " 'Arizona',\n",
       " 'credit',\n",
       " '00000026',\n",
       " '10-11-2011',\n",
       " '4000009',\n",
       " '031.58',\n",
       " 'Combat Sports',\n",
       " 'Wrestling',\n",
       " 'Orange',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000027',\n",
       " '09-29-2011',\n",
       " '4000010',\n",
       " '066.40',\n",
       " 'Games',\n",
       " 'Mahjong',\n",
       " 'Fremont',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000028',\n",
       " '05-12-2011',\n",
       " '4000008',\n",
       " '079.78',\n",
       " 'Team Sports',\n",
       " 'Cricket',\n",
       " 'Lexington',\n",
       " 'Kentucky',\n",
       " 'credit',\n",
       " '00000029',\n",
       " '06-03-2011',\n",
       " '4000001',\n",
       " '126.90',\n",
       " 'Outdoor Recreation',\n",
       " 'Hunting',\n",
       " 'Phoenix',\n",
       " 'Arizona',\n",
       " 'credit',\n",
       " '00000030',\n",
       " '03-14-2011',\n",
       " '4000001',\n",
       " '047.05',\n",
       " 'Water Sports',\n",
       " 'Swimming',\n",
       " 'Lincoln',\n",
       " 'Nebraska',\n",
       " 'credit',\n",
       " '00000031',\n",
       " '11-28-2011',\n",
       " '4000008',\n",
       " '005.03',\n",
       " 'Games',\n",
       " 'Dice & Dice Sets',\n",
       " 'Los Angeles',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000032',\n",
       " '01-29-2011',\n",
       " '4000008',\n",
       " '020.13',\n",
       " 'Team Sports',\n",
       " 'Soccer',\n",
       " 'Springfield',\n",
       " 'Illinois',\n",
       " 'credit',\n",
       " '00000033',\n",
       " '06-15-2011',\n",
       " '4000008',\n",
       " '154.15',\n",
       " 'Outdoor Recreation',\n",
       " 'Lawn Games',\n",
       " 'Nashville  ',\n",
       " 'Tennessee',\n",
       " 'credit',\n",
       " '00000034',\n",
       " '05-06-2011',\n",
       " '4000008',\n",
       " '098.96',\n",
       " 'Team Sports',\n",
       " 'Indoor Volleyball',\n",
       " 'Atlanta',\n",
       " 'Georgia',\n",
       " 'credit',\n",
       " '00000035',\n",
       " '04-12-2011',\n",
       " '4000008',\n",
       " '185.26',\n",
       " 'Games',\n",
       " 'Board Games',\n",
       " 'Centennial',\n",
       " 'Colorado',\n",
       " 'credit',\n",
       " '00000036',\n",
       " '10-13-2011',\n",
       " '4000007',\n",
       " '035.66',\n",
       " 'Team Sports',\n",
       " 'Football',\n",
       " 'Saint Paul',\n",
       " 'Minnesota',\n",
       " 'credit',\n",
       " '00000037',\n",
       " '04-19-2011',\n",
       " '4000007',\n",
       " '020.20',\n",
       " 'Outdoor Recreation',\n",
       " 'Shooting Games',\n",
       " 'San Diego',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000038',\n",
       " '08-05-2011',\n",
       " '4000007',\n",
       " '150.60',\n",
       " 'Outdoor Recreation',\n",
       " 'Camping & Backpacking & Hiking',\n",
       " 'Hampton  ',\n",
       " 'Virginia',\n",
       " 'credit',\n",
       " '00000039',\n",
       " '03-12-2011',\n",
       " '4000006',\n",
       " '174.36',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Swing Sets',\n",
       " 'Pittsburgh',\n",
       " 'Pennsylvania',\n",
       " 'credit',\n",
       " '00000040',\n",
       " '11-07-2011',\n",
       " '4000005',\n",
       " '165.10',\n",
       " 'Team Sports',\n",
       " 'Cheerleading',\n",
       " 'Reno',\n",
       " 'Nevada',\n",
       " 'credit',\n",
       " '00000041',\n",
       " '04-16-2011',\n",
       " '4000004',\n",
       " '028.11',\n",
       " 'Indoor Games',\n",
       " 'Bowling',\n",
       " 'Westminster',\n",
       " 'Colorado',\n",
       " 'cash',\n",
       " '00000042',\n",
       " '09-10-2011',\n",
       " '4000004',\n",
       " '038.52',\n",
       " 'Outdoor Recreation',\n",
       " 'Tetherball',\n",
       " 'Denton',\n",
       " 'Texas',\n",
       " 'cash',\n",
       " '00000043',\n",
       " '04-22-2011',\n",
       " '4000004',\n",
       " '032.34',\n",
       " 'Water Sports',\n",
       " 'Water Polo',\n",
       " 'Las Vegas',\n",
       " 'Nevada',\n",
       " 'cash',\n",
       " '00000044',\n",
       " '09-11-2011',\n",
       " '4000001',\n",
       " '135.37',\n",
       " 'Water Sports',\n",
       " 'Surfing',\n",
       " 'Seattle',\n",
       " 'Washington',\n",
       " 'credit',\n",
       " '00000045',\n",
       " '11-27-2011',\n",
       " '4000001',\n",
       " '090.04',\n",
       " 'Exercise & Fitness',\n",
       " 'Abdominal Equipment',\n",
       " 'Honolulu  ',\n",
       " 'Hawaii',\n",
       " 'credit',\n",
       " '00000046',\n",
       " '05-27-2011',\n",
       " '4000001',\n",
       " '052.29',\n",
       " 'Gymnastics',\n",
       " 'Vaulting Horses',\n",
       " 'Cleveland',\n",
       " 'Ohio',\n",
       " 'credit',\n",
       " '00000047',\n",
       " '10-23-2011',\n",
       " '4000008',\n",
       " '100.10',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Swing Sets',\n",
       " 'Everett',\n",
       " 'Washington',\n",
       " 'credit',\n",
       " '00000048',\n",
       " '09-27-2011',\n",
       " '4000007',\n",
       " '157.94',\n",
       " 'Exercise & Fitness',\n",
       " 'Exercise Bands',\n",
       " 'Philadelphia',\n",
       " 'Pennsylvania',\n",
       " 'credit',\n",
       " '00000049',\n",
       " '07-12-2011',\n",
       " '4000010',\n",
       " '144.59',\n",
       " 'Jumping',\n",
       " 'Jumping Stilts',\n",
       " 'Cambridge',\n",
       " 'Massachusetts',\n",
       " 'credit',\n",
       " '00000050',\n",
       " '10-20-2011',\n",
       " '4000010',\n",
       " '055.93',\n",
       " 'Jumping',\n",
       " 'Pogo Sticks',\n",
       " 'Everett',\n",
       " 'Washington',\n",
       " 'credit',\n",
       " '00000051',\n",
       " '02-17-2011',\n",
       " '4000002',\n",
       " '032.65',\n",
       " 'Water Sports',\n",
       " 'Life Jackets',\n",
       " 'Columbus',\n",
       " 'Georgia',\n",
       " 'cash',\n",
       " '00000052',\n",
       " '02-04-2011',\n",
       " '4000005',\n",
       " '044.82',\n",
       " 'Outdoor Play Equipment',\n",
       " 'Lawn Water Slides',\n",
       " 'Hampton  ',\n",
       " 'Virginia',\n",
       " 'cash',\n",
       " '00000053',\n",
       " '06-12-2011',\n",
       " '4000004',\n",
       " '044.46',\n",
       " 'Water Sports',\n",
       " 'Scuba Diving & Snorkeling',\n",
       " 'Charleston',\n",
       " 'South Carolina',\n",
       " 'cash',\n",
       " '00000054',\n",
       " '10-03-2011',\n",
       " '4000007',\n",
       " '154.87',\n",
       " 'Outdoor Recreation',\n",
       " 'Running',\n",
       " 'Long Beach',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000055',\n",
       " '12-16-2011',\n",
       " '4000006',\n",
       " '106.11',\n",
       " 'Water Sports',\n",
       " 'Swimming',\n",
       " 'New York',\n",
       " 'New York',\n",
       " 'credit',\n",
       " '00000056',\n",
       " '06-21-2011',\n",
       " '4000002',\n",
       " '176.63',\n",
       " 'Outdoor Recreation',\n",
       " 'Geocaching',\n",
       " 'Boston',\n",
       " 'Massachusetts',\n",
       " 'credit',\n",
       " '00000057',\n",
       " '12-20-2011',\n",
       " '4000003',\n",
       " '178.20',\n",
       " 'Outdoor Recreation',\n",
       " 'Skating',\n",
       " 'San Jose',\n",
       " 'California',\n",
       " 'credit',\n",
       " '00000058',\n",
       " '12-29-2011',\n",
       " '4000002',\n",
       " '194.86',\n",
       " 'Water Sports',\n",
       " 'Windsurfing',\n",
       " 'Oklahoma City',\n",
       " 'Oklahoma',\n",
       " 'credit',\n",
       " '00000059',\n",
       " '11-07-2011',\n",
       " '4000001',\n",
       " '021.43',\n",
       " 'Winter Sports',\n",
       " 'Snowboarding',\n",
       " 'Philadelphia',\n",
       " 'Pennsylvania',\n",
       " 'cash']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.flatMap(lambda y: y.split(\",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00000000',\n",
       "  '06-26-2011',\n",
       "  '4000001',\n",
       "  '040.33',\n",
       "  'Exercise & Fitness',\n",
       "  'Cardio Machine Accessories',\n",
       "  'Clarksville',\n",
       "  'Tennessee',\n",
       "  'credit'],\n",
       " ['00000001',\n",
       "  '05-26-2011',\n",
       "  '4000002',\n",
       "  '198.44',\n",
       "  'Exercise & Fitness',\n",
       "  'Weightlifting Gloves',\n",
       "  'Long Beach',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000002',\n",
       "  '06-01-2011',\n",
       "  '4000002',\n",
       "  '005.58',\n",
       "  'Exercise & Fitness',\n",
       "  'Weightlifting Machine Accessories',\n",
       "  'Anaheim',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000003',\n",
       "  '06-05-2011',\n",
       "  '4000003',\n",
       "  '198.19',\n",
       "  'Gymnastics',\n",
       "  'Gymnastics Rings',\n",
       "  'Milwaukee',\n",
       "  'Wisconsin',\n",
       "  'credit'],\n",
       " ['00000004',\n",
       "  '12-17-2011',\n",
       "  '4000002',\n",
       "  '098.81',\n",
       "  'Team Sports',\n",
       "  'Field Hockey',\n",
       "  'Nashville  ',\n",
       "  'Tennessee',\n",
       "  'credit'],\n",
       " ['00000005',\n",
       "  '02-14-2011',\n",
       "  '4000004',\n",
       "  '193.63',\n",
       "  'Outdoor Recreation',\n",
       "  'Camping & Backpacking & Hiking',\n",
       "  'Chicago',\n",
       "  'Illinois',\n",
       "  'credit'],\n",
       " ['00000006',\n",
       "  '10-28-2011',\n",
       "  '4000005',\n",
       "  '027.89',\n",
       "  'Puzzles',\n",
       "  'Jigsaw Puzzles',\n",
       "  'Charleston',\n",
       "  'South Carolina',\n",
       "  'credit'],\n",
       " ['00000007',\n",
       "  '07-14-2011',\n",
       "  '4000006',\n",
       "  '096.01',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Sandboxes',\n",
       "  'Columbus',\n",
       "  'Ohio',\n",
       "  'credit'],\n",
       " ['00000008',\n",
       "  '01-17-2011',\n",
       "  '4000006',\n",
       "  '010.44',\n",
       "  'Winter Sports',\n",
       "  'Snowmobiling',\n",
       "  'Des Moines',\n",
       "  'Iowa',\n",
       "  'credit'],\n",
       " ['00000009',\n",
       "  '05-17-2011',\n",
       "  '4000006',\n",
       "  '152.46',\n",
       "  'Jumping',\n",
       "  'Bungee Jumping',\n",
       "  'St. Petersburg',\n",
       "  'Florida',\n",
       "  'credit'],\n",
       " ['00000010',\n",
       "  '05-29-2011',\n",
       "  '4000007',\n",
       "  '180.28',\n",
       "  'Outdoor Recreation',\n",
       "  'Archery',\n",
       "  'Reno',\n",
       "  'Nevada',\n",
       "  'credit'],\n",
       " ['00000011',\n",
       "  '06-18-2011',\n",
       "  '4000009',\n",
       "  '121.39',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Swing Sets',\n",
       "  'Columbus',\n",
       "  'Ohio',\n",
       "  'credit'],\n",
       " ['00000012',\n",
       "  '02-08-2011',\n",
       "  '4000009',\n",
       "  '041.52',\n",
       "  'Indoor Games',\n",
       "  'Bowling',\n",
       "  'San Francisco',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000013',\n",
       "  '03-13-2011',\n",
       "  '4000010',\n",
       "  '107.80',\n",
       "  'Team Sports',\n",
       "  'Field Hockey',\n",
       "  'Honolulu  ',\n",
       "  'Hawaii',\n",
       "  'credit'],\n",
       " ['00000014',\n",
       "  '02-25-2011',\n",
       "  '4000010',\n",
       "  '036.81',\n",
       "  'Gymnastics',\n",
       "  'Vaulting Horses',\n",
       "  'Los Angeles',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000015',\n",
       "  '10-20-2011',\n",
       "  '4000001',\n",
       "  '137.64',\n",
       "  'Combat Sports',\n",
       "  'Fencing',\n",
       "  'Honolulu  ',\n",
       "  'Hawaii',\n",
       "  'credit'],\n",
       " ['00000016',\n",
       "  '05-28-2011',\n",
       "  '4000010',\n",
       "  '035.56',\n",
       "  'Exercise & Fitness',\n",
       "  'Free Weight Bars',\n",
       "  'Columbia',\n",
       "  'South Carolina',\n",
       "  'credit'],\n",
       " ['00000017',\n",
       "  '10-18-2011',\n",
       "  '4000008',\n",
       "  '075.55',\n",
       "  'Water Sports',\n",
       "  'Scuba Diving & Snorkeling',\n",
       "  'Omaha',\n",
       "  'Nebraska',\n",
       "  'credit'],\n",
       " ['00000018',\n",
       "  '11-18-2011',\n",
       "  '4000008',\n",
       "  '088.65',\n",
       "  'Team Sports',\n",
       "  'Baseball',\n",
       "  'Salt Lake City',\n",
       "  'Utah',\n",
       "  'credit'],\n",
       " ['00000019',\n",
       "  '08-28-2011',\n",
       "  '4000008',\n",
       "  '051.81',\n",
       "  'Water Sports',\n",
       "  'Life Jackets',\n",
       "  'Newark',\n",
       "  'New Jersey',\n",
       "  'credit'],\n",
       " ['00000020',\n",
       "  '06-29-2011',\n",
       "  '4000005',\n",
       "  '041.55',\n",
       "  'Exercise & Fitness',\n",
       "  'Weightlifting Belts',\n",
       "  'New Orleans',\n",
       "  'Louisiana',\n",
       "  'credit'],\n",
       " ['00000021',\n",
       "  '02-14-2011',\n",
       "  '4000005',\n",
       "  '045.79',\n",
       "  'Air Sports',\n",
       "  'Parachutes',\n",
       "  'New York',\n",
       "  'New York',\n",
       "  'credit'],\n",
       " ['00000022',\n",
       "  '10-10-2011',\n",
       "  '4000009',\n",
       "  '019.64',\n",
       "  'Water Sports',\n",
       "  'Kitesurfing',\n",
       "  'Saint Paul',\n",
       "  'Minnesota',\n",
       "  'credit'],\n",
       " ['00000023',\n",
       "  '05-02-2011',\n",
       "  '4000009',\n",
       "  '099.50',\n",
       "  'Gymnastics',\n",
       "  'Gymnastics Rings',\n",
       "  'Springfield',\n",
       "  'Illinois',\n",
       "  'credit'],\n",
       " ['00000024',\n",
       "  '06-10-2011',\n",
       "  '4000003',\n",
       "  '151.20',\n",
       "  'Water Sports',\n",
       "  'Surfing',\n",
       "  'Plano',\n",
       "  'Texas',\n",
       "  'credit'],\n",
       " ['00000025',\n",
       "  '10-14-2011',\n",
       "  '4000009',\n",
       "  '144.20',\n",
       "  'Indoor Games',\n",
       "  'Darts',\n",
       "  'Phoenix',\n",
       "  'Arizona',\n",
       "  'credit'],\n",
       " ['00000026',\n",
       "  '10-11-2011',\n",
       "  '4000009',\n",
       "  '031.58',\n",
       "  'Combat Sports',\n",
       "  'Wrestling',\n",
       "  'Orange',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000027',\n",
       "  '09-29-2011',\n",
       "  '4000010',\n",
       "  '066.40',\n",
       "  'Games',\n",
       "  'Mahjong',\n",
       "  'Fremont',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000028',\n",
       "  '05-12-2011',\n",
       "  '4000008',\n",
       "  '079.78',\n",
       "  'Team Sports',\n",
       "  'Cricket',\n",
       "  'Lexington',\n",
       "  'Kentucky',\n",
       "  'credit'],\n",
       " ['00000029',\n",
       "  '06-03-2011',\n",
       "  '4000001',\n",
       "  '126.90',\n",
       "  'Outdoor Recreation',\n",
       "  'Hunting',\n",
       "  'Phoenix',\n",
       "  'Arizona',\n",
       "  'credit'],\n",
       " ['00000030',\n",
       "  '03-14-2011',\n",
       "  '4000001',\n",
       "  '047.05',\n",
       "  'Water Sports',\n",
       "  'Swimming',\n",
       "  'Lincoln',\n",
       "  'Nebraska',\n",
       "  'credit'],\n",
       " ['00000031',\n",
       "  '11-28-2011',\n",
       "  '4000008',\n",
       "  '005.03',\n",
       "  'Games',\n",
       "  'Dice & Dice Sets',\n",
       "  'Los Angeles',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000032',\n",
       "  '01-29-2011',\n",
       "  '4000008',\n",
       "  '020.13',\n",
       "  'Team Sports',\n",
       "  'Soccer',\n",
       "  'Springfield',\n",
       "  'Illinois',\n",
       "  'credit'],\n",
       " ['00000033',\n",
       "  '06-15-2011',\n",
       "  '4000008',\n",
       "  '154.15',\n",
       "  'Outdoor Recreation',\n",
       "  'Lawn Games',\n",
       "  'Nashville  ',\n",
       "  'Tennessee',\n",
       "  'credit'],\n",
       " ['00000034',\n",
       "  '05-06-2011',\n",
       "  '4000008',\n",
       "  '098.96',\n",
       "  'Team Sports',\n",
       "  'Indoor Volleyball',\n",
       "  'Atlanta',\n",
       "  'Georgia',\n",
       "  'credit'],\n",
       " ['00000035',\n",
       "  '04-12-2011',\n",
       "  '4000008',\n",
       "  '185.26',\n",
       "  'Games',\n",
       "  'Board Games',\n",
       "  'Centennial',\n",
       "  'Colorado',\n",
       "  'credit'],\n",
       " ['00000036',\n",
       "  '10-13-2011',\n",
       "  '4000007',\n",
       "  '035.66',\n",
       "  'Team Sports',\n",
       "  'Football',\n",
       "  'Saint Paul',\n",
       "  'Minnesota',\n",
       "  'credit'],\n",
       " ['00000037',\n",
       "  '04-19-2011',\n",
       "  '4000007',\n",
       "  '020.20',\n",
       "  'Outdoor Recreation',\n",
       "  'Shooting Games',\n",
       "  'San Diego',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000038',\n",
       "  '08-05-2011',\n",
       "  '4000007',\n",
       "  '150.60',\n",
       "  'Outdoor Recreation',\n",
       "  'Camping & Backpacking & Hiking',\n",
       "  'Hampton  ',\n",
       "  'Virginia',\n",
       "  'credit'],\n",
       " ['00000039',\n",
       "  '03-12-2011',\n",
       "  '4000006',\n",
       "  '174.36',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Swing Sets',\n",
       "  'Pittsburgh',\n",
       "  'Pennsylvania',\n",
       "  'credit'],\n",
       " ['00000040',\n",
       "  '11-07-2011',\n",
       "  '4000005',\n",
       "  '165.10',\n",
       "  'Team Sports',\n",
       "  'Cheerleading',\n",
       "  'Reno',\n",
       "  'Nevada',\n",
       "  'credit'],\n",
       " ['00000041',\n",
       "  '04-16-2011',\n",
       "  '4000004',\n",
       "  '028.11',\n",
       "  'Indoor Games',\n",
       "  'Bowling',\n",
       "  'Westminster',\n",
       "  'Colorado',\n",
       "  'cash'],\n",
       " ['00000042',\n",
       "  '09-10-2011',\n",
       "  '4000004',\n",
       "  '038.52',\n",
       "  'Outdoor Recreation',\n",
       "  'Tetherball',\n",
       "  'Denton',\n",
       "  'Texas',\n",
       "  'cash'],\n",
       " ['00000043',\n",
       "  '04-22-2011',\n",
       "  '4000004',\n",
       "  '032.34',\n",
       "  'Water Sports',\n",
       "  'Water Polo',\n",
       "  'Las Vegas',\n",
       "  'Nevada',\n",
       "  'cash'],\n",
       " ['00000044',\n",
       "  '09-11-2011',\n",
       "  '4000001',\n",
       "  '135.37',\n",
       "  'Water Sports',\n",
       "  'Surfing',\n",
       "  'Seattle',\n",
       "  'Washington',\n",
       "  'credit'],\n",
       " ['00000045',\n",
       "  '11-27-2011',\n",
       "  '4000001',\n",
       "  '090.04',\n",
       "  'Exercise & Fitness',\n",
       "  'Abdominal Equipment',\n",
       "  'Honolulu  ',\n",
       "  'Hawaii',\n",
       "  'credit'],\n",
       " ['00000046',\n",
       "  '05-27-2011',\n",
       "  '4000001',\n",
       "  '052.29',\n",
       "  'Gymnastics',\n",
       "  'Vaulting Horses',\n",
       "  'Cleveland',\n",
       "  'Ohio',\n",
       "  'credit'],\n",
       " ['00000047',\n",
       "  '10-23-2011',\n",
       "  '4000008',\n",
       "  '100.10',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Swing Sets',\n",
       "  'Everett',\n",
       "  'Washington',\n",
       "  'credit'],\n",
       " ['00000048',\n",
       "  '09-27-2011',\n",
       "  '4000007',\n",
       "  '157.94',\n",
       "  'Exercise & Fitness',\n",
       "  'Exercise Bands',\n",
       "  'Philadelphia',\n",
       "  'Pennsylvania',\n",
       "  'credit'],\n",
       " ['00000049',\n",
       "  '07-12-2011',\n",
       "  '4000010',\n",
       "  '144.59',\n",
       "  'Jumping',\n",
       "  'Jumping Stilts',\n",
       "  'Cambridge',\n",
       "  'Massachusetts',\n",
       "  'credit'],\n",
       " ['00000050',\n",
       "  '10-20-2011',\n",
       "  '4000010',\n",
       "  '055.93',\n",
       "  'Jumping',\n",
       "  'Pogo Sticks',\n",
       "  'Everett',\n",
       "  'Washington',\n",
       "  'credit'],\n",
       " ['00000051',\n",
       "  '02-17-2011',\n",
       "  '4000002',\n",
       "  '032.65',\n",
       "  'Water Sports',\n",
       "  'Life Jackets',\n",
       "  'Columbus',\n",
       "  'Georgia',\n",
       "  'cash'],\n",
       " ['00000052',\n",
       "  '02-04-2011',\n",
       "  '4000005',\n",
       "  '044.82',\n",
       "  'Outdoor Play Equipment',\n",
       "  'Lawn Water Slides',\n",
       "  'Hampton  ',\n",
       "  'Virginia',\n",
       "  'cash'],\n",
       " ['00000053',\n",
       "  '06-12-2011',\n",
       "  '4000004',\n",
       "  '044.46',\n",
       "  'Water Sports',\n",
       "  'Scuba Diving & Snorkeling',\n",
       "  'Charleston',\n",
       "  'South Carolina',\n",
       "  'cash'],\n",
       " ['00000054',\n",
       "  '10-03-2011',\n",
       "  '4000007',\n",
       "  '154.87',\n",
       "  'Outdoor Recreation',\n",
       "  'Running',\n",
       "  'Long Beach',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000055',\n",
       "  '12-16-2011',\n",
       "  '4000006',\n",
       "  '106.11',\n",
       "  'Water Sports',\n",
       "  'Swimming',\n",
       "  'New York',\n",
       "  'New York',\n",
       "  'credit'],\n",
       " ['00000056',\n",
       "  '06-21-2011',\n",
       "  '4000002',\n",
       "  '176.63',\n",
       "  'Outdoor Recreation',\n",
       "  'Geocaching',\n",
       "  'Boston',\n",
       "  'Massachusetts',\n",
       "  'credit'],\n",
       " ['00000057',\n",
       "  '12-20-2011',\n",
       "  '4000003',\n",
       "  '178.20',\n",
       "  'Outdoor Recreation',\n",
       "  'Skating',\n",
       "  'San Jose',\n",
       "  'California',\n",
       "  'credit'],\n",
       " ['00000058',\n",
       "  '12-29-2011',\n",
       "  '4000002',\n",
       "  '194.86',\n",
       "  'Water Sports',\n",
       "  'Windsurfing',\n",
       "  'Oklahoma City',\n",
       "  'Oklahoma',\n",
       "  'credit'],\n",
       " ['00000059',\n",
       "  '11-07-2011',\n",
       "  '4000001',\n",
       "  '021.43',\n",
       "  'Winter Sports',\n",
       "  'Snowboarding',\n",
       "  'Philadelphia',\n",
       "  'Pennsylvania',\n",
       "  'cash']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.flatMap(lambda x: x.split(\",\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000001', '040.33'),\n",
       " ('4000002', '198.44'),\n",
       " ('4000002', '005.58'),\n",
       " ('4000003', '198.19'),\n",
       " ('4000002', '098.81'),\n",
       " ('4000004', '193.63'),\n",
       " ('4000005', '027.89'),\n",
       " ('4000006', '096.01'),\n",
       " ('4000006', '010.44'),\n",
       " ('4000006', '152.46'),\n",
       " ('4000007', '180.28'),\n",
       " ('4000009', '121.39'),\n",
       " ('4000009', '041.52'),\n",
       " ('4000010', '107.80'),\n",
       " ('4000010', '036.81'),\n",
       " ('4000001', '137.64'),\n",
       " ('4000010', '035.56'),\n",
       " ('4000008', '075.55'),\n",
       " ('4000008', '088.65'),\n",
       " ('4000008', '051.81'),\n",
       " ('4000005', '041.55'),\n",
       " ('4000005', '045.79'),\n",
       " ('4000009', '019.64'),\n",
       " ('4000009', '099.50'),\n",
       " ('4000003', '151.20'),\n",
       " ('4000009', '144.20'),\n",
       " ('4000009', '031.58'),\n",
       " ('4000010', '066.40'),\n",
       " ('4000008', '079.78'),\n",
       " ('4000001', '126.90'),\n",
       " ('4000001', '047.05'),\n",
       " ('4000008', '005.03'),\n",
       " ('4000008', '020.13'),\n",
       " ('4000008', '154.15'),\n",
       " ('4000008', '098.96'),\n",
       " ('4000008', '185.26'),\n",
       " ('4000007', '035.66'),\n",
       " ('4000007', '020.20'),\n",
       " ('4000007', '150.60'),\n",
       " ('4000006', '174.36'),\n",
       " ('4000005', '165.10'),\n",
       " ('4000004', '028.11'),\n",
       " ('4000004', '038.52'),\n",
       " ('4000004', '032.34'),\n",
       " ('4000001', '135.37'),\n",
       " ('4000001', '090.04'),\n",
       " ('4000001', '052.29'),\n",
       " ('4000008', '100.10'),\n",
       " ('4000007', '157.94'),\n",
       " ('4000010', '144.59'),\n",
       " ('4000010', '055.93'),\n",
       " ('4000002', '032.65'),\n",
       " ('4000005', '044.82'),\n",
       " ('4000004', '044.46'),\n",
       " ('4000007', '154.87'),\n",
       " ('4000006', '106.11'),\n",
       " ('4000002', '176.63'),\n",
       " ('4000003', '178.20'),\n",
       " ('4000002', '194.86'),\n",
       " ('4000001', '021.43')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000004', 337.06),\n",
       " ('4000007', 699.55),\n",
       " ('4000008', 859.42),\n",
       " ('4000001', 651.0500000000001),\n",
       " ('4000002', 706.97),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000005', 325.15),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000009', 457.83),\n",
       " ('4000010', 447.09000000000003)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000008', 859.42),\n",
       " ('4000002', 706.97),\n",
       " ('4000007', 699.55),\n",
       " ('4000001', 651.0500000000001),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000009', 457.83),\n",
       " ('4000010', 447.09000000000003),\n",
       " ('4000004', 337.06),\n",
       " ('4000005', 325.15)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).sortBy(lambda x: x[1], False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000001', 651.0500000000001),\n",
       " ('4000002', 706.97),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000004', 337.06),\n",
       " ('4000005', 325.15),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000007', 699.55),\n",
       " ('4000008', 859.42),\n",
       " ('4000009', 457.83),\n",
       " ('4000010', 447.09000000000003)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000002', 'Team Sports'),\n",
       " ('4000006', 'Winter Sports'),\n",
       " ('4000010', 'Team Sports'),\n",
       " ('4000001', 'Combat Sports'),\n",
       " ('4000008', 'Water Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000008', 'Water Sports'),\n",
       " ('4000005', 'Air Sports'),\n",
       " ('4000009', 'Water Sports'),\n",
       " ('4000003', 'Water Sports'),\n",
       " ('4000009', 'Combat Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000001', 'Water Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000008', 'Team Sports'),\n",
       " ('4000007', 'Team Sports'),\n",
       " ('4000005', 'Team Sports'),\n",
       " ('4000004', 'Water Sports'),\n",
       " ('4000001', 'Water Sports'),\n",
       " ('4000002', 'Water Sports'),\n",
       " ('4000004', 'Water Sports'),\n",
       " ('4000006', 'Water Sports'),\n",
       " ('4000002', 'Water Sports'),\n",
       " ('4000001', 'Winter Sports')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).filter(lambda x: (\"Sport\" in x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000008',\n",
       "  'Water Sports;Team Sports;Games;Outdoor Play Equipment;Outdoor Recreation'),\n",
       " ('4000004', 'Indoor Games;Water Sports;Outdoor Recreation'),\n",
       " ('4000003', 'Gymnastics;Outdoor Recreation;Water Sports'),\n",
       " ('4000006', 'Jumping;Outdoor Play Equipment;Winter Sports;Water Sports'),\n",
       " ('4000001',\n",
       "  'Combat Sports;Outdoor Recreation;Gymnastics;Exercise & Fitness;Water Sports;Winter Sports'),\n",
       " ('4000009',\n",
       "  'Gymnastics;Combat Sports;Outdoor Play Equipment;Indoor Games;Water Sports'),\n",
       " ('4000002', 'Outdoor Recreation;Exercise & Fitness;Team Sports;Water Sports')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).distinct().reduceByKey(lambda x1,x2: x1 + (';') + x2).filter(lambda x: (\"Water Sports\" in x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'4000001': 8,\n",
       "             '4000002': 6,\n",
       "             '4000003': 3,\n",
       "             '4000004': 5,\n",
       "             '4000005': 5,\n",
       "             '4000006': 5,\n",
       "             '4000007': 6,\n",
       "             '4000009': 6,\n",
       "             '4000010': 6,\n",
       "             '4000008': 10})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'4000001': 8,\n",
       "             '4000002': 6,\n",
       "             '4000003': 3,\n",
       "             '4000004': 5,\n",
       "             '4000005': 5,\n",
       "             '4000006': 5,\n",
       "             '4000007': 6,\n",
       "             '4000008': 10,\n",
       "             '4000009': 6,\n",
       "             '4000010': 6})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).sortByKey().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4000005', 325.15),\n",
       " ('4000004', 337.06),\n",
       " ('4000010', 447.09000000000003),\n",
       " ('4000009', 457.83),\n",
       " ('4000003', 527.5899999999999),\n",
       " ('4000006', 539.3800000000001),\n",
       " ('4000001', 651.0500000000001),\n",
       " ('4000007', 699.55),\n",
       " ('4000002', 706.97),\n",
       " ('4000008', 859.42)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: float(x1)+float(x2)).sortBy(lambda x: x[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.defaultdict' object has no attribute 'collect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d59c410145d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtransRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msortByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtransRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.defaultdict' object has no attribute 'collect'"
     ]
    }
   ],
   "source": [
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[4])).sortByKey().countByKey().collect()\n",
    "transRDD.map(lambda x: x.split(\",\")).map(lambda x: (x[2],x[3])).reduceByKey(lambda x1,x2: (float(x1)+float(x2))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[247] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "print(transRDDT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\", \"users_Count\"]\n",
    "data = [(\"Java\",\"20000\"),(\"Python\",\"100000\"),(\"Scala\",\"3000\")]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Java', '20000'), ('Python', '100000'), ('Scala', '3000')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1 = rdd.toDF()\n",
    "dfFromRDD1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1 = rdd.toDF(columns)\n",
    "dfFromRDD1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD2 = spark.createDataFrame(rdd).toDF(*columns)\n",
    "dfFromRDD2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Java\",\"20000\"),(\"Python\",\"100000\"),(\"Scala\",\"3000\")]\n",
    "dfFromRDD2 = spark.createDataFrame(data).toDF(*columns)\n",
    "dfFromRDD2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_Count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "rowData = map(lambda x: Row(*x), data)\n",
    "dfFromRDD3 = spark.createDataFrame(rowData, columns)\n",
    "dfFromRDD3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|   id|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|    James|          |   Smith|36636|     M|  3000|\n",
      "|    Maria|      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "         (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "         (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "        ]\n",
    "schema1 = StructType([\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\",StringType(),True), \\\n",
    "    StructField(\"gender\",StringType(),True), \\\n",
    "    StructField(\"salary\",IntegerType(),True), \\\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data = data2, schema= schema1)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"zipcodes.csv\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").load(\"zipcodes.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: string (nullable = true)\n",
      " |-- Long: string (nullable = true)\n",
      " |-- Xaxis: string (nullable = true)\n",
      " |-- Yaxis: string (nullable = true)\n",
      " |-- Zaxis: string (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: string (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: string (nullable = true)\n",
      " |-- TotalWages: string (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "|       76512|  27203|   STANDARD|           ASHEBORO|   NC|       PRIMARY|35.71| -79.81| 0.14|-0.79| 0.58|         NA|     US|        Asheboro, NC|   NA-US-NC-ASHEBORO|        FALSE|           8355|              15228| 215474318|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.option(\"header\",True).csv(\"zipcodes.csv\")\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|     _c0|       _c1|    _c2|   _c3|                 _c4|                 _c5|           _c6|           _c7|   _c8|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|00000000|06-26-2011|4000001|040.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|00000001|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|00000002|06-01-2011|4000002|005.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|00000003|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|00000004|12-17-2011|4000002|098.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|00000005|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|00000006|10-28-2011|4000005|027.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|00000007|07-14-2011|4000006|096.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|00000008|01-17-2011|4000006|010.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|00000009|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|00000010|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|00000011|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|00000012|02-08-2011|4000009|041.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|00000013|03-13-2011|4000010|107.80|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|00000014|02-25-2011|4000010|036.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|00000015|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|00000016|05-28-2011|4000010|035.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|00000017|10-18-2011|4000008|075.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|00000018|11-18-2011|4000008|088.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|00000019|08-28-2011|4000008|051.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "|00000020|06-29-2011|4000005|041.55|  Exercise & Fitness| Weightlifting Belts|   New Orleans|     Louisiana|credit|\n",
      "|00000021|02-14-2011|4000005|045.79|          Air Sports|          Parachutes|      New York|      New York|credit|\n",
      "|00000022|10-10-2011|4000009|019.64|        Water Sports|         Kitesurfing|    Saint Paul|     Minnesota|credit|\n",
      "|00000023|05-02-2011|4000009|099.50|          Gymnastics|    Gymnastics Rings|   Springfield|      Illinois|credit|\n",
      "|00000024|06-10-2011|4000003|151.20|        Water Sports|             Surfing|         Plano|         Texas|credit|\n",
      "|00000025|10-14-2011|4000009|144.20|        Indoor Games|               Darts|       Phoenix|       Arizona|credit|\n",
      "|00000026|10-11-2011|4000009|031.58|       Combat Sports|           Wrestling|        Orange|    California|credit|\n",
      "|00000027|09-29-2011|4000010|066.40|               Games|             Mahjong|       Fremont|    California|credit|\n",
      "|00000028|05-12-2011|4000008|079.78|         Team Sports|             Cricket|     Lexington|      Kentucky|credit|\n",
      "|00000029|06-03-2011|4000001|126.90|  Outdoor Recreation|             Hunting|       Phoenix|       Arizona|credit|\n",
      "|00000030|03-14-2011|4000001|047.05|        Water Sports|            Swimming|       Lincoln|      Nebraska|credit|\n",
      "|00000031|11-28-2011|4000008|005.03|               Games|    Dice & Dice Sets|   Los Angeles|    California|credit|\n",
      "|00000032|01-29-2011|4000008|020.13|         Team Sports|              Soccer|   Springfield|      Illinois|credit|\n",
      "|00000033|06-15-2011|4000008|154.15|  Outdoor Recreation|          Lawn Games|   Nashville  |     Tennessee|credit|\n",
      "|00000034|05-06-2011|4000008|098.96|         Team Sports|   Indoor Volleyball|       Atlanta|       Georgia|credit|\n",
      "|00000035|04-12-2011|4000008|185.26|               Games|         Board Games|    Centennial|      Colorado|credit|\n",
      "|00000036|10-13-2011|4000007|035.66|         Team Sports|            Football|    Saint Paul|     Minnesota|credit|\n",
      "|00000037|04-19-2011|4000007|020.20|  Outdoor Recreation|      Shooting Games|     San Diego|    California|credit|\n",
      "|00000038|08-05-2011|4000007|150.60|  Outdoor Recreation|Camping & Backpac...|     Hampton  |      Virginia|credit|\n",
      "|00000039|03-12-2011|4000006|174.36|Outdoor Play Equi...|          Swing Sets|    Pittsburgh|  Pennsylvania|credit|\n",
      "|00000040|11-07-2011|4000005|165.10|         Team Sports|        Cheerleading|          Reno|        Nevada|credit|\n",
      "|00000041|04-16-2011|4000004|028.11|        Indoor Games|             Bowling|   Westminster|      Colorado|  cash|\n",
      "|00000042|09-10-2011|4000004|038.52|  Outdoor Recreation|          Tetherball|        Denton|         Texas|  cash|\n",
      "|00000043|04-22-2011|4000004|032.34|        Water Sports|          Water Polo|     Las Vegas|        Nevada|  cash|\n",
      "|00000044|09-11-2011|4000001|135.37|        Water Sports|             Surfing|       Seattle|    Washington|credit|\n",
      "|00000045|11-27-2011|4000001|090.04|  Exercise & Fitness| Abdominal Equipment|    Honolulu  |        Hawaii|credit|\n",
      "|00000046|05-27-2011|4000001|052.29|          Gymnastics|     Vaulting Horses|     Cleveland|          Ohio|credit|\n",
      "|00000047|10-23-2011|4000008|100.10|Outdoor Play Equi...|          Swing Sets|       Everett|    Washington|credit|\n",
      "|00000048|09-27-2011|4000007|157.94|  Exercise & Fitness|      Exercise Bands|  Philadelphia|  Pennsylvania|credit|\n",
      "|00000049|07-12-2011|4000010|144.59|             Jumping|      Jumping Stilts|     Cambridge| Massachusetts|credit|\n",
      "|00000050|10-20-2011|4000010|055.93|             Jumping|         Pogo Sticks|       Everett|    Washington|credit|\n",
      "|00000051|02-17-2011|4000002|032.65|        Water Sports|        Life Jackets|      Columbus|       Georgia|  cash|\n",
      "|00000052|02-04-2011|4000005|044.82|Outdoor Play Equi...|   Lawn Water Slides|     Hampton  |      Virginia|  cash|\n",
      "|00000053|06-12-2011|4000004|044.46|        Water Sports|Scuba Diving & Sn...|    Charleston|South Carolina|  cash|\n",
      "|00000054|10-03-2011|4000007|154.87|  Outdoor Recreation|             Running|    Long Beach|    California|credit|\n",
      "|00000055|12-16-2011|4000006|106.11|        Water Sports|            Swimming|      New York|      New York|credit|\n",
      "|00000056|06-21-2011|4000002|176.63|  Outdoor Recreation|          Geocaching|        Boston| Massachusetts|credit|\n",
      "|00000057|12-20-2011|4000003|178.20|  Outdoor Recreation|             Skating|      San Jose|    California|credit|\n",
      "|00000058|12-29-2011|4000002|194.86|        Water Sports|         Windsurfing| Oklahoma City|      Oklahoma|credit|\n",
      "|00000059|11-07-2011|4000001|021.43|       Winter Sports|        Snowboarding|  Philadelphia|  Pennsylvania|  cash|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dftest1 = spark.read.csv('/E:/spark/spark-3.0.3-bin-hadoop2.7/BTGK/trans.txt')\n",
    "dftest1.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(delimiter=',').csv(\"zipcodes.csv\")\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.options(inferSchema='True',delimiter=',').csv(\"zipcodes.csv\")\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: boolean (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(inferSchema='True',delimiter=',').csv(\"zipcodesNoHeader.csv\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: string (nullable = true)\n",
      " |-- Long: string (nullable = true)\n",
      " |-- Xaxis: string (nullable = true)\n",
      " |-- Yaxis: string (nullable = true)\n",
      " |-- Zaxis: string (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: string (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: string (nullable = true)\n",
      " |-- TotalWages: string (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(header = 'true', inferSchema = 'false', delimiter = ',').csv(\"zipcodes.csv\")\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType() \\\n",
    ".add (\"RecordNumber\", IntegerType(), True)\\\n",
    ".add (\"Zipcode\" ,IntegerType() ,True)\\\n",
    ".add (\"ZipCodeType\" ,StringType(), True)\\\n",
    ".add (\"City\" ,StringType(), True)\\\n",
    ".add (\"State\", StringType(), True)\\\n",
    ".add (\"LocationType\", StringType(), True)\\\n",
    ".add (\"Lat\" ,DoubleType(), True)\\\n",
    ".add (\"Long\" ,DoubleType(), True)\\\n",
    ".add (\"Xaxis\", IntegerType(), True)\\\n",
    ".add (\"Yaxis\", DoubleType(), True)\\\n",
    ".add (\"Zaxis\", DoubleType(), True)\\\n",
    ".add (\"WorldRegion\", StringType(), True)\\\n",
    ".add (\"Country\" ,StringType(), True)\\\n",
    ".add (\"LocationText\" ,StringType(), True)\\\n",
    ".add (\"Location\" ,StringType() ,True)\\\n",
    ".add (\"Decommisioned\" ,BooleanType(), True)\\\n",
    ".add (\"TaxReturnsFiled\", StringType(), True)\\\n",
    ".add (\"EstimatedPopulation\" ,IntegerType(), True)\\\n",
    ".add (\"TotalWages\", IntegerType(), True)\\\n",
    ".add (\"Notes\" ,StringType(), True)\n",
    "      \n",
    "df_with_schema = spark.read.format(\"csv\").option(\"header\",True).schema(schema).load(\"zipcodes.csv\")\n",
    "df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_ID: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF = spark.read.options(delimiter=',').schema('trans_id INT, date STRING, cust_ID INT, amount DOUBLE, game STRING, equipment STRING, city STRING, state STRING, mode STRING').csv(\"trans.txt\")\n",
    "transDF.printSchema()\n",
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|         _c0|    _c1|        _c2|                _c3|  _c4|           _c5|  _c6|    _c7|  _c8|  _c9| _c10|       _c11|   _c12|                _c13|                _c14|         _c15|           _c16|               _c17|      _c18|         _c19|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|   Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|        Notes|\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        FALSE|           null|               null|      null|         null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72| -97.31| -0.1|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        FALSE|           null|               null|      null|         null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|32.75| -97.33| -0.1|-0.83| 0.54|         NA|     US|        Ft Worth, TX|   NA-US-TX-FT WORTH|        FALSE|           2126|               4053| 122396986|         null|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US| Urb Eugene Rice, PR|NA-US-PR-URB EUGE...|        FALSE|           null|               null|      null|         null|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|33.37|-111.64| -0.3|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14962|              26883| 563792730|no NWS data, |\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|33.38|-111.84|-0.31|-0.77| 0.55|         NA|     US|            Mesa, AZ|       NA-US-AZ-MESA|        FALSE|          14374|              25446| 471000465|         null|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|30.69| -81.92| 0.12|-0.85| 0.51|         NA|     US|        Hilliard, FL|   NA-US-FL-HILLIARD|        FALSE|           3922|               7443| 133112149|         null|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|28.96| -82.41| 0.11|-0.86| 0.48|         NA|     US|          Holder, FL|     NA-US-FL-HOLDER|        FALSE|           null|               null|      null|         null|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|30.72| -86.67| 0.04|-0.85| 0.51|         NA|     US|            Holt, FL|       NA-US-FL-HOLT|        FALSE|           1207|               2190|  36395913|         null|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|28.78| -82.61| 0.11|-0.86| 0.48|         NA|     US|       Homosassa, FL|  NA-US-FL-HOMOSASSA|        FALSE|           null|               null|      null|         null|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14| -66.26| 0.38|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        FALSE|           null|               null|      null|         null|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|17.96| -66.22| 0.38|-0.87|  0.3|         NA|     US|   Sect Lanausse, PR|NA-US-PR-SECT LAN...|        FALSE|           null|               null|      null|         null|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|33.97| -85.55| 0.06|-0.82| 0.55|         NA|     US|   Spring Garden, AL|NA-US-AL-SPRING G...|        FALSE|           null|               null|      null|         null|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|33.77| -86.47| 0.05|-0.82| 0.55|         NA|     US|     Springville, AL|NA-US-AL-SPRINGVILLE|        FALSE|           4046|               7845| 172127599|         null|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|34.37| -87.69| 0.03|-0.82| 0.56|         NA|     US|     Spruce Pine, AL|NA-US-AL-SPRUCE PINE|        FALSE|            610|               1209|  18525517|         null|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE| 36.4| -80.56| 0.13|-0.79| 0.59|         NA|     US|        Ash Hill, NC|   NA-US-NC-ASH HILL|        FALSE|            842|               1666|  28876493|         null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+-------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/E:/spark/spark-3.0.3-bin-hadoop2.7/BTGK/newzipcodes already exists.;",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-d6f2186680ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"header\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"newzipcodes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(e)\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: path file:/E:/spark/spark-3.0.3-bin-hadoop2.7/BTGK/newzipcodes already exists.;"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True).csv(\"newzipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/E:/spark/spark-3.0.3-bin-hadoop2.7/BTGK/newzipcodes already exists.;",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-8375c7083598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"newzipcodes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(e)\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: path file:/E:/spark/spark-3.0.3-bin-hadoop2.7/BTGK/newzipcodes already exists.;"
     ]
    }
   ],
   "source": [
    "df2.write.options(header='True', delimiter=',').csv(\"newzipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1606.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 155.0 failed 1 times, most recent failure: Lost task 0.0 in stage 155.0 (TID 307, vannhinh-ng02.ea.corp.samsungelectronics.net, executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112171247472039298821884897827_0155_m_000000_307\\part-00000-3460f4cc-8ecf-4edf-be1b-43553d088430-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\r\n\t... 33 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112171247472039298821884897827_0155_m_000000_307\\part-00000-3460f4cc-8ecf-4edf-be1b-43553d088430-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-9ed8f365029d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'overwrite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"newzipcodes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1606.csv.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:126)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:962)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:414)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:398)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:287)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:952)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 155.0 failed 1 times, most recent failure: Lost task 0.0 in stage 155.0 (TID 307, vannhinh-ng02.ea.corp.samsungelectronics.net, executor driver): java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112171247472039298821884897827_0155_m_000000_307\\part-00000-3460f4cc-8ecf-4edf-be1b-43553d088430-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\r\n\t... 33 more\r\nCaused by: java.io.IOException: (null) entry in command string: null chmod 0644 E:\\spark\\spark-3.0.3-bin-hadoop2.7\\BTGK\\newzipcodes\\_temporary\\0\\_temporary\\attempt_202112171247472039298821884897827_0155_m_000000_307\\part-00000-3460f4cc-8ecf-4edf-be1b-43553d088430-c000.csv\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\r\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\r\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "df2.write.mode('overwrite').csv(\"newzipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(value='RecordNumber\\tZipcode\\tZipCodeType\\tCity\\tState\\tLocationType'),\n",
       " Row(value='1\\t704\\tSTANDARD\\tPARC PARQUE\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='2\\t704\\tSTANDARD\\tPASEO COSTA DEL SUR\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='10\\t709\\tSTANDARD\\tBDA SAN LUIS\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='61391\\t76166\\tUNIQUE\\tCINGULAR WIRELESS\\tTX\\tNOT ACCEPTABLE'),\n",
       " Row(value='61392\\t76177\\tSTANDARD\\tFORT WORTH\\tTX\\tPRIMARY'),\n",
       " Row(value='61393\\t76177\\tSTANDARD\\tFT WORTH\\tTX\\tACCEPTABLE'),\n",
       " Row(value='4\\t704\\tSTANDARD\\tURB EUGENE RICE\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='39827\\t85209\\tSTANDARD\\tMESA\\tAZ\\tPRIMARY'),\n",
       " Row(value='39828\\t85210\\tSTANDARD\\tMESA\\tAZ\\tPRIMARY'),\n",
       " Row(value='49345\\t32046\\tSTANDARD\\tHILLIARD\\tFL\\tPRIMARY'),\n",
       " Row(value='49346\\t34445\\tPO BOX\\tHOLDER\\tFL\\tPRIMARY'),\n",
       " Row(value='49347\\t32564\\tSTANDARD\\tHOLT\\tFL\\tPRIMARY'),\n",
       " Row(value='49348\\t34487\\tPO BOX\\tHOMOSASSA\\tFL\\tPRIMARY'),\n",
       " Row(value='10\\t708\\tSTANDARD\\tBDA SAN LUIS\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='3\\t704\\tSTANDARD\\tSECT LANAUSSE\\tPR\\tNOT ACCEPTABLE'),\n",
       " Row(value='54354\\t36275\\tPO BOX\\tSPRING GARDEN\\tAL\\tPRIMARY'),\n",
       " Row(value='54355\\t35146\\tSTANDARD\\tSPRINGVILLE\\tAL\\tPRIMARY'),\n",
       " Row(value='54356\\t35585\\tSTANDARD\\tSPRUCE PINE\\tAL\\tPRIMARY'),\n",
       " Row(value='76511\\t27007\\tSTANDARD\\tASH HILL\\tNC\\tNOT ACCEPTABLE'),\n",
       " Row(value='76512\\t27203\\tSTANDARD\\tASHEBORO\\tNC\\tPRIMARY'),\n",
       " Row(value='76513\\t27204\\tPO BOX\\tASHEBORO\\tNC\\tPRIMARY')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.text(\"zipcodes.txt\")\n",
    "df.printSchema()\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|\n",
      "|       61393|  76177|   STANDARD|           FT WORTH|   TX|    ACCEPTABLE|\n",
      "|           4|    704|   STANDARD|    URB EUGENE RICE|   PR|NOT ACCEPTABLE|\n",
      "|       39827|  85209|   STANDARD|               MESA|   AZ|       PRIMARY|\n",
      "|       39828|  85210|   STANDARD|               MESA|   AZ|       PRIMARY|\n",
      "|       49345|  32046|   STANDARD|           HILLIARD|   FL|       PRIMARY|\n",
      "|       49346|  34445|     PO BOX|             HOLDER|   FL|       PRIMARY|\n",
      "|       49347|  32564|   STANDARD|               HOLT|   FL|       PRIMARY|\n",
      "|       49348|  34487|     PO BOX|          HOMOSASSA|   FL|       PRIMARY|\n",
      "|          10|    708|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|\n",
      "|           3|    704|   STANDARD|      SECT LANAUSSE|   PR|NOT ACCEPTABLE|\n",
      "|       54354|  36275|     PO BOX|      SPRING GARDEN|   AL|       PRIMARY|\n",
      "|       54355|  35146|   STANDARD|        SPRINGVILLE|   AL|       PRIMARY|\n",
      "|       54356|  35585|   STANDARD|        SPRUCE PINE|   AL|       PRIMARY|\n",
      "|       76511|  27007|   STANDARD|           ASH HILL|   NC|NOT ACCEPTABLE|\n",
      "|       76512|  27203|   STANDARD|           ASHEBORO|   NC|       PRIMARY|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header='True',inferSchema='True', delimiter='\\t').csv(\"zipcodes.txt\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "transDF = spark.read.options(delimiter=',').schema('trans_id INT, date STRING, cust_id INT, amount DOUBLE, game STRING, equipment STRING, city STRING, state STRING, mode STRING').csv(\"trans.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select('cust_id','amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select(transDF.cust_id,transDF.amount).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select(transDF['cust_id'],transDF['amount']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|cust_id|amount|\n",
      "+-------+------+\n",
      "|4000001| 40.33|\n",
      "|4000002|198.44|\n",
      "|4000002|  5.58|\n",
      "|4000003|198.19|\n",
      "|4000002| 98.81|\n",
      "|4000004|193.63|\n",
      "|4000005| 27.89|\n",
      "|4000006| 96.01|\n",
      "|4000006| 10.44|\n",
      "|4000006|152.46|\n",
      "|4000007|180.28|\n",
      "|4000009|121.39|\n",
      "|4000009| 41.52|\n",
      "|4000010| 107.8|\n",
      "|4000010| 36.81|\n",
      "|4000001|137.64|\n",
      "|4000010| 35.56|\n",
      "|4000008| 75.55|\n",
      "|4000008| 88.65|\n",
      "|4000008| 51.81|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twocolumns=['cust_id','amount']\n",
    "transDF.select(twocolumns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select([col for col in transDF.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "transDF.withColumn('trans_id',col('trans_id').cast('String')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_id: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.withColumn('trans_id',col('trans_id').cast('integer')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 80.66|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|396.88|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002| 11.16|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|396.38|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002|197.62|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|387.26|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 55.78|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006|192.02|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 20.88|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|304.92|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|360.56|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|242.78|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 83.04|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 215.6|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 73.62|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|275.28|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 71.12|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 151.1|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 177.3|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008|103.62|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "transDF.withColumn('amount',col('amount')*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+----------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|new amount|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+----------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|     80.66|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|    396.88|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|     11.16|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|    396.38|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|    197.62|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|    387.26|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|     55.78|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|    192.02|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|     20.88|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|    304.92|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|    360.56|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|    242.78|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|     83.04|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|     215.6|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|     73.62|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|    275.28|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|     71.12|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|     151.1|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|     177.3|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|    103.62|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "transDF.withColumn('new amount',col('amount')*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+-------+\n",
      "|trans_id|      date|cust_id|amount|                game|           equipment|          city|         state|  mode|Country|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+-------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|    USA|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|    USA|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|    USA|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|    USA|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|    USA|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|    USA|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|    USA|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|    USA|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|    USA|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|    USA|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|    USA|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|    USA|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|    USA|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|    USA|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|    USA|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|    USA|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|    USA|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|    USA|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|    USA|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|    USA|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "transDF.withColumn(\"Country\", lit(\"USA\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_id|  cost|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "transDF.withColumnRenamed('amount','cost').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Anna, Rose, ]        |[Spark, Java, C++]|NY   |F     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Maria, Anne, Jones]  |[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]    |[CSharp, VB]      |NY   |M     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "data = [\n",
    "((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    "]\n",
    "schema = StructType([\n",
    "StructField('name', StructType([\n",
    "StructField('firstname', StringType(), True),\n",
    "StructField('middlename', StringType(), True),\n",
    "StructField('lastname', StringType(), True)\n",
    "])),\n",
    "StructField('languages', ArrayType(StringType()), True),\n",
    "StructField('state', StringType(), True),\n",
    "StructField('gender', StringType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['state'] == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|name                |languages         |state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|[Anna, Rose, ]      |[Spark, Java, C++]|NY   |F     |\n",
      "|[Maria, Anne, Jones]|[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]  |[CSharp, VB]      |NY   |M     |\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state != \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|name                |languages         |state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|[Anna, Rose, ]      |[Spark, Java, C++]|NY   |F     |\n",
      "|[Maria, Anne, Jones]|[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]  |[CSharp, VB]      |NY   |M     |\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~(df.state == \"OH\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(col(\"state\") == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender == 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----+------+\n",
      "|               name|         languages|state|gender|\n",
      "+-------------------+------------------+-----+------+\n",
      "|     [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "+-------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender != 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----+------+\n",
      "|               name|         languages|state|gender|\n",
      "+-------------------+------------------+-----+------+\n",
      "|     [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "+-------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.state == 'OH') & (df.gender =='M')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "li=[\"OH\",\"CA\",\"DE\"]\n",
    "df.filter(df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.isin(li) == False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.startswith(\"N\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.endswith(\"H\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.contains(\"Y\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),(4,\"Rames Rose\"),(5,\"Rames rose\")]\n",
    "df2 = spark.createDataFrame(data = data2, schema=[\"id\",\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|      name|\n",
      "+---+----------+\n",
      "|  5|Rames rose|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(df2.name.like(\"%rose%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|        name|\n",
      "+---+------------+\n",
      "|  2|Michael Rose|\n",
      "|  4|  Rames Rose|\n",
      "|  5|  Rames rose|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----+------+\n",
      "|            name|         languages|state|gender|\n",
      "+----------------+------------------+-----+------+\n",
      "|[James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|  [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "+----------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.filter(array_contains(df.languages,\"Java\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+-----+------+\n",
      "|name                  |languages   |state|gender|\n",
      "+----------------------+------------+-----+------+\n",
      "|[Julia, , Williams]   |[CSharp, VB]|OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]|OH   |M     |\n",
      "+----------------------+------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.name.lastname ==\"Williams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+-----+------+\n",
      "|name                  |languages   |state|gender|\n",
      "+----------------------+------------+-----+------+\n",
      "|[Julia, , Williams]   |[CSharp, VB]|OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]|OH   |M     |\n",
      "+----------------------+------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.name.lastname ==\"Williams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transDF.select('cust_id','game').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transDF.select('cust_id','game').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count of customer ID & game : 43\n",
      "+--------+----------+-------+------+----------------------+-------------------+-------------+--------------+------+\n",
      "|trans_id|date      |cust_id|amount|game                  |equipment          |city         |state         |mode  |\n",
      "+--------+----------+-------+------+----------------------+-------------------+-------------+--------------+------+\n",
      "|13      |03-13-2011|4000010|107.8 |Team Sports           |Field Hockey       |Honolulu     |Hawaii        |credit|\n",
      "|48      |09-27-2011|4000007|157.94|Exercise & Fitness    |Exercise Bands     |Philadelphia |Pennsylvania  |credit|\n",
      "|20      |06-29-2011|4000005|41.55 |Exercise & Fitness    |Weightlifting Belts|New Orleans  |Louisiana     |credit|\n",
      "|33      |06-15-2011|4000008|154.15|Outdoor Recreation    |Lawn Games         |Nashville    |Tennessee     |credit|\n",
      "|49      |07-12-2011|4000010|144.59|Jumping               |Jumping Stilts     |Cambridge    |Massachusetts |credit|\n",
      "|46      |05-27-2011|4000001|52.29 |Gymnastics            |Vaulting Horses    |Cleveland    |Ohio          |credit|\n",
      "|55      |12-16-2011|4000006|106.11|Water Sports          |Swimming           |New York     |New York      |credit|\n",
      "|3       |06-05-2011|4000003|198.19|Gymnastics            |Gymnastics Rings   |Milwaukee    |Wisconsin     |credit|\n",
      "|6       |10-28-2011|4000005|27.89 |Puzzles               |Jigsaw Puzzles     |Charleston   |South Carolina|credit|\n",
      "|12      |02-08-2011|4000009|41.52 |Indoor Games          |Bowling            |San Francisco|California    |credit|\n",
      "|10      |05-29-2011|4000007|180.28|Outdoor Recreation    |Archery            |Reno         |Nevada        |credit|\n",
      "|47      |10-23-2011|4000008|100.1 |Outdoor Play Equipment|Swing Sets         |Everett      |Washington    |credit|\n",
      "|24      |06-10-2011|4000003|151.2 |Water Sports          |Surfing            |Plano        |Texas         |credit|\n",
      "|52      |02-04-2011|4000005|44.82 |Outdoor Play Equipment|Lawn Water Slides  |Hampton      |Virginia      |cash  |\n",
      "|15      |10-20-2011|4000001|137.64|Combat Sports         |Fencing            |Honolulu     |Hawaii        |credit|\n",
      "|43      |04-22-2011|4000004|32.34 |Water Sports          |Water Polo         |Las Vegas    |Nevada        |cash  |\n",
      "|16      |05-28-2011|4000010|35.56 |Exercise & Fitness    |Free Weight Bars   |Columbia     |South Carolina|credit|\n",
      "|14      |02-25-2011|4000010|36.81 |Gymnastics            |Vaulting Horses    |Los Angeles  |California    |credit|\n",
      "|22      |10-10-2011|4000009|19.64 |Water Sports          |Kitesurfing        |Saint Paul   |Minnesota     |credit|\n",
      "|7       |07-14-2011|4000006|96.01 |Outdoor Play Equipment|Sandboxes          |Columbus     |Ohio          |credit|\n",
      "+--------+----------+-------+------+----------------------+-------------------+-------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropDisDF = transDF.dropDuplicates(['cust_id','game'])\n",
    "print(\"Distinct count of customer ID & game : \" + str(dropDisDF.count()))\n",
    "dropDisDF.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------------+--------------------------+-----------+----------+------+\n",
      "|trans_id|date      |cust_ID|amount|game              |equipment                 |city       |state     |mode  |\n",
      "+--------+----------+-------+------+------------------+--------------------------+-----------+----------+------+\n",
      "|0       |06-26-2011|4000001|40.33 |Exercise & Fitness|Cardio Machine Accessories|Clarksville|Tennessee |credit|\n",
      "|1       |05-26-2011|4000002|198.44|Exercise & Fitness|Weightlifting Gloves      |Long Beach |California|credit|\n",
      "+--------+----------+-------+------+------------------+--------------------------+-----------+----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF = spark.read.options(delimiter=',')\\\n",
    ".schema('trans_id INT, date STRING, cust_ID INT, amount DOUBLE, game STRING, equipment STRING, city STRING, state STRING, mode STRING')\\\n",
    ".csv(\"trans.txt\")\n",
    "\n",
    "transDF.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+----------------------+------------------------------+-------------+-------------+------+\n",
      "|trans_id|date      |cust_ID|amount|game                  |equipment                     |city         |state        |mode  |\n",
      "+--------+----------+-------+------+----------------------+------------------------------+-------------+-------------+------+\n",
      "|1       |05-26-2011|4000002|198.44|Exercise & Fitness    |Weightlifting Gloves          |Long Beach   |California   |credit|\n",
      "|3       |06-05-2011|4000003|198.19|Gymnastics            |Gymnastics Rings              |Milwaukee    |Wisconsin    |credit|\n",
      "|58      |12-29-2011|4000002|194.86|Water Sports          |Windsurfing                   |Oklahoma City|Oklahoma     |credit|\n",
      "|5       |02-14-2011|4000004|193.63|Outdoor Recreation    |Camping & Backpacking & Hiking|Chicago      |Illinois     |credit|\n",
      "|35      |04-12-2011|4000008|185.26|Games                 |Board Games                   |Centennial   |Colorado     |credit|\n",
      "|10      |05-29-2011|4000007|180.28|Outdoor Recreation    |Archery                       |Reno         |Nevada       |credit|\n",
      "|57      |12-20-2011|4000003|178.2 |Outdoor Recreation    |Skating                       |San Jose     |California   |credit|\n",
      "|56      |06-21-2011|4000002|176.63|Outdoor Recreation    |Geocaching                    |Boston       |Massachusetts|credit|\n",
      "|39      |03-12-2011|4000006|174.36|Outdoor Play Equipment|Swing Sets                    |Pittsburgh   |Pennsylvania |credit|\n",
      "|40      |11-07-2011|4000005|165.1 |Team Sports           |Cheerleading                  |Reno         |Nevada       |credit|\n",
      "+--------+----------+-------+------+----------------------+------------------------------+-------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.sort('amount',ascending = False).show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|       vietnam|  cash|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|       vietnam|  cash|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |       vietnam|  cash|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "transDF.withColumn('state',when(transDF.cust_ID=='4000002','vietnam').otherwise(transDF.state)) \\\n",
    "    .withColumn('mode',when(transDF.cust_ID=='4000002','cash').otherwise(transDF.mode)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|cust_ID|count|\n",
      "+-------+-----+\n",
      "|4000001|    8|\n",
      "|4000002|    6|\n",
      "|4000003|    3|\n",
      "|4000004|    5|\n",
      "|4000005|    5|\n",
      "|4000006|    5|\n",
      "|4000007|    6|\n",
      "|4000008|   10|\n",
      "|4000009|    6|\n",
      "|4000010|    6|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').count().sort('cust_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+-----------+\n",
      "|cust_id|min(trans_id)|min(cust_ID)|min(amount)|\n",
      "+-------+-------------+------------+-----------+\n",
      "|4000009|           11|     4000009|      19.64|\n",
      "|4000001|            0|     4000001|      21.43|\n",
      "|4000006|            7|     4000006|      10.44|\n",
      "|4000005|            6|     4000005|      27.89|\n",
      "|4000008|           17|     4000008|       5.03|\n",
      "+-------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').min().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_id|min(amount)|\n",
      "+-------+-----------+\n",
      "|4000009|      19.64|\n",
      "|4000001|      21.43|\n",
      "|4000006|      10.44|\n",
      "|4000005|      27.89|\n",
      "|4000008|       5.03|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').min('amount').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|cust_ID|min_transaction_amount|\n",
      "+-------+----------------------+\n",
      "|4000009|                 19.64|\n",
      "|4000001|                 21.43|\n",
      "|4000006|                 10.44|\n",
      "|4000005|                 27.89|\n",
      "|4000008|                  5.03|\n",
      "+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "transDF.groupBy('cust_ID').agg(f.min('amount').alias('min_transaction_amount')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|cust_id|min_trans|\n",
      "+-------+---------+\n",
      "|4000009|    19.64|\n",
      "|4000001|    21.43|\n",
      "|4000006|    10.44|\n",
      "|4000005|    27.89|\n",
      "|4000008|     5.03|\n",
      "|4000004|    28.11|\n",
      "|4000003|    151.2|\n",
      "|4000010|    35.56|\n",
      "|4000007|     20.2|\n",
      "|4000002|     5.58|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').agg(f.min('amount').alias('min_trans')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_id|min(amount)|\n",
      "+-------+-----------+\n",
      "|4000001|      21.43|\n",
      "|4000002|       5.58|\n",
      "|4000003|      151.2|\n",
      "|4000004|      28.11|\n",
      "|4000005|      27.89|\n",
      "|4000006|      10.44|\n",
      "|4000007|       20.2|\n",
      "|4000008|       5.03|\n",
      "|4000009|      19.64|\n",
      "|4000010|      35.56|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').agg(f.min('amount')).sort('cust_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|cust_id|       sum(amount)|\n",
      "+-------+------------------+\n",
      "|4000009|            457.83|\n",
      "|4000001|            651.05|\n",
      "|4000006|            539.38|\n",
      "|4000005|            325.15|\n",
      "|4000008|            859.42|\n",
      "|4000004|            337.06|\n",
      "|4000003| 527.5899999999999|\n",
      "|4000010|447.09000000000003|\n",
      "|4000007| 699.5500000000001|\n",
      "|4000002|            706.97|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').sum('amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|cust_id|      total_amount|\n",
      "+-------+------------------+\n",
      "|4000009|            457.83|\n",
      "|4000001|            651.05|\n",
      "|4000006|            539.38|\n",
      "|4000005|            325.15|\n",
      "|4000008|            859.42|\n",
      "|4000004|            337.06|\n",
      "|4000003| 527.5899999999999|\n",
      "|4000010|447.09000000000003|\n",
      "|4000007| 699.5500000000001|\n",
      "|4000002|            706.97|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_id').agg(f.sum('amount').alias('total_amount')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|cust_ID|         first(game)|\n",
      "+-------+--------------------+\n",
      "|4000009|Outdoor Play Equi...|\n",
      "|4000001|  Exercise & Fitness|\n",
      "|4000006|Outdoor Play Equi...|\n",
      "|4000005|             Puzzles|\n",
      "|4000008|        Water Sports|\n",
      "|4000004|  Outdoor Recreation|\n",
      "|4000003|          Gymnastics|\n",
      "|4000010|         Team Sports|\n",
      "|4000007|  Outdoor Recreation|\n",
      "|4000002|  Exercise & Fitness|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.first('game')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------------+--------------------+-------------+-------------+------+\n",
      "|trans_id|      date|cust_ID|amount|              game|           equipment|         city|        state|  mode|\n",
      "+--------+----------+-------+------+------------------+--------------------+-------------+-------------+------+\n",
      "|       1|05-26-2011|4000002|198.44|Exercise & Fitness|Weightlifting Gloves|   Long Beach|   California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|Exercise & Fitness|Weightlifting Mac...|      Anaheim|   California|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|       Team Sports|        Field Hockey|  Nashville  |    Tennessee|credit|\n",
      "|      51|02-17-2011|4000002| 32.65|      Water Sports|        Life Jackets|     Columbus|      Georgia|  cash|\n",
      "|      56|06-21-2011|4000002|176.63|Outdoor Recreation|          Geocaching|       Boston|Massachusetts|credit|\n",
      "|      58|12-29-2011|4000002|194.86|      Water Sports|         Windsurfing|Oklahoma City|     Oklahoma|credit|\n",
      "+--------+----------+-------+------+------------------+--------------------+-------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.filter(transDF.cust_ID == 4000002).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------------------+\n",
      "|cust_id|count(cust_id)|       sum(amount)|\n",
      "+-------+--------------+------------------+\n",
      "|4000010|             6|447.09000000000003|\n",
      "|4000009|             6|            457.83|\n",
      "|4000008|            10|            859.42|\n",
      "|4000007|             6| 699.5500000000001|\n",
      "|4000006|             5|            539.38|\n",
      "|4000005|             5|            325.15|\n",
      "|4000004|             5|            337.06|\n",
      "|4000003|             3| 527.5899999999999|\n",
      "|4000002|             6|            706.97|\n",
      "|4000001|             8|            651.05|\n",
      "+-------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = transDF.groupBy('cust_id').agg(f.count('cust_id'))\n",
    "t2 = transDF.groupBy('cust_id').agg(f.sum('amount'))\n",
    "t3 = t1.join(t2,['cust_id'],\"inner\")\n",
    "t3.sort('cust_id', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|cust_ID|count(game)|\n",
      "+-------+-----------+\n",
      "|4000009|          5|\n",
      "|4000001|          6|\n",
      "|4000006|          4|\n",
      "|4000005|          5|\n",
      "|4000008|          5|\n",
      "|4000004|          3|\n",
      "|4000003|          3|\n",
      "|4000010|          5|\n",
      "|4000007|          3|\n",
      "|4000002|          4|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.countDistinct('game')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|cust_ID|collect_list(game)                                                                                                                        |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|4000009|[Outdoor Play Equipment, Indoor Games, Water Sports, Gymnastics, Indoor Games, Combat Sports]                                             |\n",
      "|4000001|[Exercise & Fitness, Combat Sports, Outdoor Recreation, Water Sports, Water Sports, Exercise & Fitness, Gymnastics, Winter Sports]        |\n",
      "|4000006|[Outdoor Play Equipment, Winter Sports, Jumping, Outdoor Play Equipment, Water Sports]                                                    |\n",
      "|4000005|[Puzzles, Exercise & Fitness, Air Sports, Team Sports, Outdoor Play Equipment]                                                            |\n",
      "|4000008|[Water Sports, Team Sports, Water Sports, Team Sports, Games, Team Sports, Outdoor Recreation, Team Sports, Games, Outdoor Play Equipment]|\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_list('game')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------+\n",
      "|cust_ID|collect_set(game)                                                                               |\n",
      "+-------+------------------------------------------------------------------------------------------------+\n",
      "|4000009|[Combat Sports, Water Sports, Indoor Games, Gymnastics, Outdoor Play Equipment]                 |\n",
      "|4000001|[Combat Sports, Water Sports, Outdoor Recreation, Gymnastics, Winter Sports, Exercise & Fitness]|\n",
      "|4000006|[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]                                  |\n",
      "|4000005|[Puzzles, Team Sports, Air Sports, Exercise & Fitness, Outdoor Play Equipment]                  |\n",
      "|4000008|[Team Sports, Water Sports, Outdoor Recreation, Games, Outdoor Play Equipment]                  |\n",
      "+-------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_set('game')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------------+\n",
      "|cust_ID|collect_set(game)                                             |\n",
      "+-------+--------------------------------------------------------------+\n",
      "|4000006|[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]|\n",
      "|4000010|[Team Sports, Jumping, Gymnastics, Games, Exercise & Fitness] |\n",
      "+-------+--------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_set('game')).filter(f.array_contains(f.col('collect_set(game)'),'Jumping')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
      "|cust_ID|collect_set(game)                                                                               |game_list_string                                                                         |\n",
      "+-------+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
      "|4000009|[Combat Sports, Water Sports, Indoor Games, Gymnastics, Outdoor Play Equipment]                 |Combat Sports,Water Sports,Indoor Games,Gymnastics,Outdoor Play Equipment                |\n",
      "|4000001|[Combat Sports, Water Sports, Outdoor Recreation, Gymnastics, Winter Sports, Exercise & Fitness]|Combat Sports,Water Sports,Outdoor Recreation,Gymnastics,Winter Sports,Exercise & Fitness|\n",
      "|4000006|[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]                                  |Water Sports,Jumping,Winter Sports,Outdoor Play Equipment                                |\n",
      "|4000005|[Puzzles, Team Sports, Air Sports, Exercise & Fitness, Outdoor Play Equipment]                  |Puzzles,Team Sports,Air Sports,Exercise & Fitness,Outdoor Play Equipment                 |\n",
      "|4000008|[Team Sports, Water Sports, Outdoor Recreation, Games, Outdoor Play Equipment]                  |Team Sports,Water Sports,Outdoor Recreation,Games,Outdoor Play Equipment                 |\n",
      "+-------+------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.groupBy('cust_ID').agg(f.collect_set('game')).withColumn('game_list_string',f.concat_ws(',',f.col('collect_set(game)'))).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "transGameStringDF =  transDF.groupBy('cust_id').agg(f.collect_set('game')).withColumn('game_string',f.concat_ws(',',f.col('collect_set(game)'))).select('cust_ID','game_string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------------------------------------+\n",
      "|cust_ID|game_string                                                                              |\n",
      "+-------+-----------------------------------------------------------------------------------------+\n",
      "|4000009|Combat Sports,Water Sports,Indoor Games,Gymnastics,Outdoor Play Equipment                |\n",
      "|4000001|Combat Sports,Water Sports,Outdoor Recreation,Gymnastics,Winter Sports,Exercise & Fitness|\n",
      "|4000006|Water Sports,Jumping,Winter Sports,Outdoor Play Equipment                                |\n",
      "|4000005|Puzzles,Team Sports,Air Sports,Exercise & Fitness,Outdoor Play Equipment                 |\n",
      "|4000008|Team Sports,Water Sports,Outdoor Recreation,Games,Outdoor Play Equipment                 |\n",
      "+-------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
      "|cust_ID|game_string                                                                              |game_array                                                                                      |\n",
      "+-------+-----------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
      "|4000009|Combat Sports,Water Sports,Indoor Games,Gymnastics,Outdoor Play Equipment                |[Combat Sports, Water Sports, Indoor Games, Gymnastics, Outdoor Play Equipment]                 |\n",
      "|4000001|Combat Sports,Water Sports,Outdoor Recreation,Gymnastics,Winter Sports,Exercise & Fitness|[Combat Sports, Water Sports, Outdoor Recreation, Gymnastics, Winter Sports, Exercise & Fitness]|\n",
      "|4000006|Water Sports,Jumping,Winter Sports,Outdoor Play Equipment                                |[Water Sports, Jumping, Winter Sports, Outdoor Play Equipment]                                  |\n",
      "|4000005|Puzzles,Team Sports,Air Sports,Exercise & Fitness,Outdoor Play Equipment                 |[Puzzles, Team Sports, Air Sports, Exercise & Fitness, Outdoor Play Equipment]                  |\n",
      "|4000008|Team Sports,Water Sports,Outdoor Recreation,Games,Outdoor Play Equipment                 |[Team Sports, Water Sports, Outdoor Recreation, Games, Outdoor Play Equipment]                  |\n",
      "+-------+-----------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array',f.split('game_string',',')).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------+\n",
      "|cust_ID|         game_string|          game_array|num_game|\n",
      "+-------+--------------------+--------------------+--------+\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|       5|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|       6|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|       4|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|       5|\n",
      "|4000008|Team Sports,Water...|[Team Sports, Wat...|       5|\n",
      "+-------+--------------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array', f.split('game_string',',')).withColumn('num_game',f.size('game_array')).show(5,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------+--------------------+\n",
      "|cust_ID|         game_string|          game_array|   first_game|           last_game|\n",
      "+-------+--------------------+--------------------+-------------+--------------------+\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|Combat Sports|Outdoor Play Equi...|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|Combat Sports|  Exercise & Fitness|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...| Water Sports|Outdoor Play Equi...|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|      Puzzles|Outdoor Play Equi...|\n",
      "|4000008|Team Sports,Water...|[Team Sports, Wat...|  Team Sports|Outdoor Play Equi...|\n",
      "+-------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array',f.split('game_string',',')) \\\n",
    ".withColumn('first_game',f.element_at('game_array',1)) \\\n",
    ".withColumn('last_game',f.element_at('game_array',-1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|cust_ID|         game_string|          game_array|         single_game|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|       Combat Sports|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|        Water Sports|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|        Indoor Games|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|          Gymnastics|\n",
      "|4000009|Combat Sports,Wat...|[Combat Sports, W...|Outdoor Play Equi...|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|       Combat Sports|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|        Water Sports|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|  Outdoor Recreation|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|          Gymnastics|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|       Winter Sports|\n",
      "|4000001|Combat Sports,Wat...|[Combat Sports, W...|  Exercise & Fitness|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|        Water Sports|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|             Jumping|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|       Winter Sports|\n",
      "|4000006|Water Sports,Jump...|[Water Sports, Ju...|Outdoor Play Equi...|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|             Puzzles|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|         Team Sports|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|          Air Sports|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|  Exercise & Fitness|\n",
      "|4000005|Puzzles,Team Spor...|[Puzzles, Team Sp...|Outdoor Play Equi...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transGameStringDF.withColumn('game_array',f.split('game_string',',')).withColumn('single_game',f.explode('game_array')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+---------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|          city|         state|  mode|day_month|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+---------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|   Clarksville|     Tennessee|credit|    06-26|\n",
      "|       1|05-26-2011|4000002|198.44|  Exercise & Fitness|Weightlifting Gloves|    Long Beach|    California|credit|    05-26|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|       Anaheim|    California|credit|    06-01|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|     Milwaukee|     Wisconsin|credit|    06-05|\n",
      "|       4|12-17-2011|4000002| 98.81|         Team Sports|        Field Hockey|   Nashville  |     Tennessee|credit|    12-17|\n",
      "|       5|02-14-2011|4000004|193.63|  Outdoor Recreation|Camping & Backpac...|       Chicago|      Illinois|credit|    02-14|\n",
      "|       6|10-28-2011|4000005| 27.89|             Puzzles|      Jigsaw Puzzles|    Charleston|South Carolina|credit|    10-28|\n",
      "|       7|07-14-2011|4000006| 96.01|Outdoor Play Equi...|           Sandboxes|      Columbus|          Ohio|credit|    07-14|\n",
      "|       8|01-17-2011|4000006| 10.44|       Winter Sports|        Snowmobiling|    Des Moines|          Iowa|credit|    01-17|\n",
      "|       9|05-17-2011|4000006|152.46|             Jumping|      Bungee Jumping|St. Petersburg|       Florida|credit|    05-17|\n",
      "|      10|05-29-2011|4000007|180.28|  Outdoor Recreation|             Archery|          Reno|        Nevada|credit|    05-29|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|      Columbus|          Ohio|credit|    06-18|\n",
      "|      12|02-08-2011|4000009| 41.52|        Indoor Games|             Bowling| San Francisco|    California|credit|    02-08|\n",
      "|      13|03-13-2011|4000010| 107.8|         Team Sports|        Field Hockey|    Honolulu  |        Hawaii|credit|    03-13|\n",
      "|      14|02-25-2011|4000010| 36.81|          Gymnastics|     Vaulting Horses|   Los Angeles|    California|credit|    02-25|\n",
      "|      15|10-20-2011|4000001|137.64|       Combat Sports|             Fencing|    Honolulu  |        Hawaii|credit|    10-20|\n",
      "|      16|05-28-2011|4000010| 35.56|  Exercise & Fitness|    Free Weight Bars|      Columbia|South Carolina|credit|    05-28|\n",
      "|      17|10-18-2011|4000008| 75.55|        Water Sports|Scuba Diving & Sn...|         Omaha|      Nebraska|credit|    10-18|\n",
      "|      18|11-18-2011|4000008| 88.65|         Team Sports|            Baseball|Salt Lake City|          Utah|credit|    11-18|\n",
      "|      19|08-28-2011|4000008| 51.81|        Water Sports|        Life Jackets|        Newark|    New Jersey|credit|    08-28|\n",
      "+--------+----------+-------+------+--------------------+--------------------+--------------+--------------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.show()\n",
    "transDF.withColumn('day_month',f.substring('date',1,5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|06-26-2011|\n",
      "|05-26-2011|\n",
      "|06-01-2011|\n",
      "|06-05-2011|\n",
      "|12-17-2011|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+\n",
      "|day_month_year|\n",
      "+--------------+\n",
      "|    06-26-2011|\n",
      "|    05-26-2011|\n",
      "|    06-01-2011|\n",
      "|    06-05-2011|\n",
      "|    12-17-2011|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.select(f.col('date')).show(5)\n",
    "transDF.select(f.col('date').alias('day_month_year')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+------------------+--------------------+-----------+----------+------+--------------+\n",
      "|trans_id|      date|cust_ID|amount|              game|           equipment|       city|     state|  mode|month_in_05_06|\n",
      "+--------+----------+-------+------+------------------+--------------------+-----------+----------+------+--------------+\n",
      "|       0|06-26-2011|4000001| 40.33|Exercise & Fitness|Cardio Machine Ac...|Clarksville| Tennessee|credit|         false|\n",
      "|       1|05-26-2011|4000002|198.44|Exercise & Fitness|Weightlifting Gloves| Long Beach|California|credit|          true|\n",
      "|       2|06-01-2011|4000002|  5.58|Exercise & Fitness|Weightlifting Mac...|    Anaheim|California|credit|         false|\n",
      "|       3|06-05-2011|4000003|198.19|        Gymnastics|    Gymnastics Rings|  Milwaukee| Wisconsin|credit|         false|\n",
      "|       4|12-17-2011|4000002| 98.81|       Team Sports|        Field Hockey|Nashville  | Tennessee|credit|          true|\n",
      "+--------+----------+-------+------+------------------+--------------------+-----------+----------+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.withColumn('month_in_05_06',f.substring('date',1,2).isin(['05','12'])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+------+--------------------+--------------------+-----------+--------------+------+\n",
      "|trans_id|      date|cust_ID|amount|                game|           equipment|       city|         state|  mode|\n",
      "+--------+----------+-------+------+--------------------+--------------------+-----------+--------------+------+\n",
      "|       0|06-26-2011|4000001| 40.33|  Exercise & Fitness|Cardio Machine Ac...|Clarksville|     Tennessee|credit|\n",
      "|       2|06-01-2011|4000002|  5.58|  Exercise & Fitness|Weightlifting Mac...|    Anaheim|    California|credit|\n",
      "|       3|06-05-2011|4000003|198.19|          Gymnastics|    Gymnastics Rings|  Milwaukee|     Wisconsin|credit|\n",
      "|      11|06-18-2011|4000009|121.39|Outdoor Play Equi...|          Swing Sets|   Columbus|          Ohio|credit|\n",
      "|      20|06-29-2011|4000005| 41.55|  Exercise & Fitness| Weightlifting Belts|New Orleans|     Louisiana|credit|\n",
      "|      24|06-10-2011|4000003| 151.2|        Water Sports|             Surfing|      Plano|         Texas|credit|\n",
      "|      29|06-03-2011|4000001| 126.9|  Outdoor Recreation|             Hunting|    Phoenix|       Arizona|credit|\n",
      "|      33|06-15-2011|4000008|154.15|  Outdoor Recreation|          Lawn Games|Nashville  |     Tennessee|credit|\n",
      "|      53|06-12-2011|4000004| 44.46|        Water Sports|Scuba Diving & Sn...| Charleston|South Carolina|  cash|\n",
      "|      56|06-21-2011|4000002|176.63|  Outdoor Recreation|          Geocaching|     Boston| Massachusetts|credit|\n",
      "+--------+----------+-------+------+--------------------+--------------------+-----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.filter(f.substring('date',0,2).isin(['06'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_ID: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- cust_ID: integer (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- game: string (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transDF.withColumn('month',f.substring('date',0,2)).printSchema()\n",
    "transDF.withColumn('month',f.substring('date',0,2).cast('INT')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-225-4cbbffdfdb64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_inner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Roll_No'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_inner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df_inner = df1.join(df2, on=['Roll_No'], how='inner')\n",
    "df_inner.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark =SparkSession.builder.appName(\"PySparktutorial\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (spark.read.csv(path= \"ratings_small.csv\",sep=\",\",header=True,quote='\"\"',schema=\"userId INT, movieId INT, rating DOUBLE, timestamp INT\",)\\\n",
    "    .withColumnRenamed(\"timestamp\",\"timestamp_unix\")\\\n",
    "    .withColumn(\"timestamp\", f.to_timestamp(f.from_unixtime(\"timestamp_unix\"))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp_unix: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2867.showString.\n: java.lang.RuntimeException: quote cannot be more than one character\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.getChar(CSVOptions.scala:68)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:106)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:58)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:108)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:130)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:121)\r\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:170)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:395)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:386)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:473)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\r\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:439)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\r\n\tat sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-7c47f30ec9ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o2867.showString.\n: java.lang.RuntimeException: quote cannot be more than one character\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.getChar(CSVOptions.scala:68)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:106)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:58)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:108)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:130)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:121)\r\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:170)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:395)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:386)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:473)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\r\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:439)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\r\n\tat sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.option(\"header\",True).csv(\"ratings_small.csv\")\n",
    "ratings.printSchema()\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp_unix: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "+------+-------+------+--------------+-------------------+\n",
      "|userId|movieId|rating|timestamp_unix|          timestamp|\n",
      "+------+-------+------+--------------+-------------------+\n",
      "|     1|      1|   4.0|     964982703|2000-07-31 01:45:03|\n",
      "|     1|      3|   4.0|     964981247|2000-07-31 01:20:47|\n",
      "|     1|      6|   4.0|     964982224|2000-07-31 01:37:04|\n",
      "|     1|     47|   5.0|     964983815|2000-07-31 02:03:35|\n",
      "|     1|     50|   5.0|     964982931|2000-07-31 01:48:51|\n",
      "|     1|     70|   3.0|     964982400|2000-07-31 01:40:00|\n",
      "|     1|    101|   5.0|     964980868|2000-07-31 01:14:28|\n",
      "|     1|    110|   4.0|     964982176|2000-07-31 01:36:16|\n",
      "|     1|    151|   5.0|     964984041|2000-07-31 02:07:21|\n",
      "|     1|    157|   5.0|     964984100|2000-07-31 02:08:20|\n",
      "|     1|    163|   5.0|     964983650|2000-07-31 02:00:50|\n",
      "|     1|    216|   5.0|     964981208|2000-07-31 01:20:08|\n",
      "|     1|    223|   3.0|     964980985|2000-07-31 01:16:25|\n",
      "|     1|    231|   5.0|     964981179|2000-07-31 01:19:39|\n",
      "|     1|    235|   4.0|     964980908|2000-07-31 01:15:08|\n",
      "|     1|    260|   5.0|     964981680|2000-07-31 01:28:00|\n",
      "|     1|    296|   3.0|     964982967|2000-07-31 01:49:27|\n",
      "|     1|    316|   3.0|     964982310|2000-07-31 01:38:30|\n",
      "|     1|    333|   5.0|     964981179|2000-07-31 01:19:39|\n",
      "|     1|    349|   4.0|     964982563|2000-07-31 01:42:43|\n",
      "+------+-------+------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.withColumnRenamed(\"timestamp\",\"timestamp_unix\").withColumn(\"timestamp\", f.to_timestamp(f.from_unixtime(\"timestamp_unix\")))\n",
    "ratings.printSchema()\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop(\"timestamp_unix\",\"foobar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      1|   4.0|2000-07-31 01:45:03|\n",
      "|     1|      3|   4.0|2000-07-31 01:20:47|\n",
      "|     1|      6|   4.0|2000-07-31 01:37:04|\n",
      "|     1|     47|   5.0|2000-07-31 02:03:35|\n",
      "|     1|     50|   5.0|2000-07-31 01:48:51|\n",
      "|     1|     70|   3.0|2000-07-31 01:40:00|\n",
      "|     1|    101|   5.0|2000-07-31 01:14:28|\n",
      "|     1|    110|   4.0|2000-07-31 01:36:16|\n",
      "|     1|    151|   5.0|2000-07-31 02:07:21|\n",
      "|     1|    157|   5.0|2000-07-31 02:08:20|\n",
      "|     1|    163|   5.0|2000-07-31 02:00:50|\n",
      "|     1|    216|   5.0|2000-07-31 01:20:08|\n",
      "|     1|    223|   3.0|2000-07-31 01:16:25|\n",
      "|     1|    231|   5.0|2000-07-31 01:19:39|\n",
      "|     1|    235|   4.0|2000-07-31 01:15:08|\n",
      "|     1|    260|   5.0|2000-07-31 01:28:00|\n",
      "|     1|    296|   3.0|2000-07-31 01:49:27|\n",
      "|     1|    316|   3.0|2000-07-31 01:38:30|\n",
      "|     1|    333|   5.0|2000-07-31 01:19:39|\n",
      "|     1|    349|   4.0|2000-07-31 01:42:43|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|userId|count_user|\n",
      "+------+----------+\n",
      "|     1|       232|\n",
      "|    10|       140|\n",
      "|   100|       148|\n",
      "|   101|        61|\n",
      "|   102|        56|\n",
      "|   103|       377|\n",
      "|   104|       273|\n",
      "|   105|       722|\n",
      "|   106|        33|\n",
      "|   107|        34|\n",
      "|   108|        76|\n",
      "|   109|       127|\n",
      "|    11|        64|\n",
      "|   110|        51|\n",
      "|   111|       646|\n",
      "|   112|        65|\n",
      "|   113|       150|\n",
      "|   114|        31|\n",
      "|   115|       112|\n",
      "|   116|        87|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.groupBy(\"userId\").agg(f.count('userId').alias('count_user')).sort(\"userId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|userId|min_rating|\n",
      "+------+----------+\n",
      "|     1|       1.0|\n",
      "|    10|       0.5|\n",
      "|   100|       1.0|\n",
      "|   101|       1.0|\n",
      "|   102|       1.0|\n",
      "|   103|       0.5|\n",
      "|   104|       0.5|\n",
      "|   105|       0.5|\n",
      "|   106|       2.5|\n",
      "|   107|       3.0|\n",
      "|   108|       1.0|\n",
      "|   109|       2.0|\n",
      "|    11|       1.0|\n",
      "|   110|       1.0|\n",
      "|   111|       0.5|\n",
      "|   112|       0.5|\n",
      "|   113|       1.0|\n",
      "|   114|       0.5|\n",
      "|   115|       1.0|\n",
      "|   116|       0.5|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.groupBy(\"userId\").agg(f.min('rating').alias(\"min_rating\")).sort(\"userId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3027.showString.\n: java.lang.RuntimeException: quote cannot be more than one character\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.getChar(CSVOptions.scala:68)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:106)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:58)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:108)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:130)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:121)\r\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:170)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:395)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:386)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:473)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\r\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:439)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\r\n\tat sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-1abac7e65c13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmovies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"movies_small.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"movieId INT, title STRING, genres STRING\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmovies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-3.0.3-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3027.showString.\n: java.lang.RuntimeException: quote cannot be more than one character\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.getChar(CSVOptions.scala:68)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:106)\r\n\tat org.apache.spark.sql.catalyst.csv.CSVOptions.<init>(CSVOptions.scala:58)\r\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:108)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:130)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:121)\r\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:170)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:395)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:386)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:473)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\r\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:47)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:439)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3627)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:767)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2697)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2904)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\r\n\tat sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "movies = (spark.read.csv(path= \"movies_small.csv\",sep=\",\",header=True,quote='\"\"',schema=\"movieId INT, title STRING, genres STRING\",))\n",
    "movies.printSchema()\n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.option(\"header\",True).csv(\"movies_small.csv\")\n",
    "movies.printSchema()\n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------+------+\n",
      "|movieId|title                                                      |genres|\n",
      "+-------+-----------------------------------------------------------+------+\n",
      "|9      |Sudden Death (1995)                                        |Action|\n",
      "|71     |Fair Game (1995)                                           |Action|\n",
      "|204    |Under Siege 2: Dark Territory (1995)                       |Action|\n",
      "|251    |Hunted, The (1995)                                         |Action|\n",
      "|667    |Bloodsport 2 (a.k.a. Bloodsport II: The Next Kumite) (1996)|Action|\n",
      "+-------+-----------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.where(f.col(\"genres\") == \"Action\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------+------+\n",
      "|movieId|title                                                      |genres|\n",
      "+-------+-----------------------------------------------------------+------+\n",
      "|9      |Sudden Death (1995)                                        |Action|\n",
      "|71     |Fair Game (1995)                                           |Action|\n",
      "|204    |Under Siege 2: Dark Territory (1995)                       |Action|\n",
      "|251    |Hunted, The (1995)                                         |Action|\n",
      "|667    |Bloodsport 2 (a.k.a. Bloodsport II: The Next Kumite) (1996)|Action|\n",
      "+-------+-----------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.filter(\"genres == 'Action'\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|        genres_array|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|[Adventure, Anima...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|[Adventure, Child...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   [Comedy, Romance]|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|[Comedy, Drama, R...|\n",
      "|      5|Father of the Bri...|              Comedy|            [Comedy]|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|[Action, Crime, T...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|   [Comedy, Romance]|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|[Adventure, Child...|\n",
      "|      9| Sudden Death (1995)|              Action|            [Action]|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|[Action, Adventur...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|[Comedy, Drama, R...|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|    [Comedy, Horror]|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|[Adventure, Anima...|\n",
      "|     14|        Nixon (1995)|               Drama|             [Drama]|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|[Action, Adventur...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|      [Crime, Drama]|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|    [Drama, Romance]|\n",
      "|     18|   Four Rooms (1995)|              Comedy|            [Comedy]|\n",
      "|     19|Ace Ventura: When...|              Comedy|            [Comedy]|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|[Action, Comedy, ...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.withColumn(\"genres_array\",f.split(f.col(\"genres\"),\"\\|\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-------------------------------------------+-------------------------------------------------+---------+\n",
      "|movieId|title                             |genres                                     |genres_array                                     |genre    |\n",
      "+-------+----------------------------------+-------------------------------------------+-------------------------------------------------+---------+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|[Adventure, Animation, Children, Comedy, Fantasy]|Adventure|\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|[Adventure, Animation, Children, Comedy, Fantasy]|Animation|\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|[Adventure, Animation, Children, Comedy, Fantasy]|Children |\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|[Adventure, Animation, Children, Comedy, Fantasy]|Comedy   |\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|[Adventure, Animation, Children, Comedy, Fantasy]|Fantasy  |\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |[Adventure, Children, Fantasy]                   |Adventure|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |[Adventure, Children, Fantasy]                   |Children |\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |[Adventure, Children, Fantasy]                   |Fantasy  |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |[Comedy, Romance]                                |Comedy   |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |[Comedy, Romance]                                |Romance  |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |[Comedy, Drama, Romance]                         |Comedy   |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |[Comedy, Drama, Romance]                         |Drama    |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |[Comedy, Drama, Romance]                         |Romance  |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |[Comedy]                                         |Comedy   |\n",
      "|6      |Heat (1995)                       |Action|Crime|Thriller                      |[Action, Crime, Thriller]                        |Action   |\n",
      "+-------+----------------------------------+-------------------------------------------+-------------------------------------------------+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.withColumn(\"genres_array\", f.split(f.col(\"genres\"),\"\\|\")).withColumn(\"genre\",f.explode(\"genres_array\")).show(15,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-------------------------------------------+-------------------------------------------------+----------+\n",
      "|movieId|title                             |genres                                     |genres_array                                     |Last_Genre|\n",
      "+-------+----------------------------------+-------------------------------------------+-------------------------------------------------+----------+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|[Adventure, Animation, Children, Comedy, Fantasy]|Fantasy   |\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |[Adventure, Children, Fantasy]                   |Fantasy   |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |[Comedy, Romance]                                |Romance   |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |[Comedy, Drama, Romance]                         |Romance   |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |[Comedy]                                         |Comedy    |\n",
      "|6      |Heat (1995)                       |Action|Crime|Thriller                      |[Action, Crime, Thriller]                        |Thriller  |\n",
      "|7      |Sabrina (1995)                    |Comedy|Romance                             |[Comedy, Romance]                                |Romance   |\n",
      "|8      |Tom and Huck (1995)               |Adventure|Children                         |[Adventure, Children]                            |Children  |\n",
      "|9      |Sudden Death (1995)               |Action                                     |[Action]                                         |Action    |\n",
      "|10     |GoldenEye (1995)                  |Action|Adventure|Thriller                  |[Action, Adventure, Thriller]                    |Thriller  |\n",
      "|11     |American President, The (1995)    |Comedy|Drama|Romance                       |[Comedy, Drama, Romance]                         |Romance   |\n",
      "|12     |Dracula: Dead and Loving It (1995)|Comedy|Horror                              |[Comedy, Horror]                                 |Horror    |\n",
      "|13     |Balto (1995)                      |Adventure|Animation|Children               |[Adventure, Animation, Children]                 |Children  |\n",
      "|14     |Nixon (1995)                      |Drama                                      |[Drama]                                          |Drama     |\n",
      "|15     |Cutthroat Island (1995)           |Action|Adventure|Romance                   |[Action, Adventure, Romance]                     |Romance   |\n",
      "+-------+----------------------------------+-------------------------------------------+-------------------------------------------------+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.withColumn(\"genres_array\",f.split(\"genres\",\"\\|\")).withColumn(\"Last_Genre\",f.element_at(f.col(\"genres_array\"),-1)).show(15,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- imdbId: string (nullable = true)\n",
      " |-- tmdbId: string (nullable = true)\n",
      "\n",
      "+-------+-------+------+\n",
      "|movieId| imdbId|tmdbId|\n",
      "+-------+-------+------+\n",
      "|      1|0114709|   862|\n",
      "|      2|0113497|  8844|\n",
      "|      3|0113228| 15602|\n",
      "|      4|0114885| 31357|\n",
      "|      5|0113041| 11862|\n",
      "|      6|0113277|   949|\n",
      "|      7|0114319| 11860|\n",
      "|      8|0112302| 45325|\n",
      "|      9|0114576|  9091|\n",
      "|     10|0113189|   710|\n",
      "|     11|0112346|  9087|\n",
      "|     12|0112896| 12110|\n",
      "|     13|0112453| 21032|\n",
      "|     14|0113987| 10858|\n",
      "|     15|0112760|  1408|\n",
      "|     16|0112641|   524|\n",
      "|     17|0114388|  4584|\n",
      "|     18|0113101|     5|\n",
      "|     19|0112281|  9273|\n",
      "|     20|0113845| 11517|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "+------+-------+-----------------+-------------------+\n",
      "|userId|movieId|              tag|          timestamp|\n",
      "+------+-------+-----------------+-------------------+\n",
      "|     2|  60756|            funny|2015-10-25 02:29:54|\n",
      "|     2|  60756|  Highly quotable|2015-10-25 02:29:56|\n",
      "|     2|  60756|     will ferrell|2015-10-25 02:29:52|\n",
      "|     2|  89774|     Boxing story|2015-10-25 02:33:27|\n",
      "|     2|  89774|              MMA|2015-10-25 02:33:20|\n",
      "|     2|  89774|        Tom Hardy|2015-10-25 02:33:25|\n",
      "|     2| 106782|            drugs|2015-10-25 02:30:54|\n",
      "|     2| 106782|Leonardo DiCaprio|2015-10-25 02:30:51|\n",
      "|     2| 106782|  Martin Scorsese|2015-10-25 02:30:56|\n",
      "|     7|  48516|     way too long|2007-01-25 08:08:45|\n",
      "|    18|    431|        Al Pacino|2016-05-02 04:39:25|\n",
      "|    18|    431|         gangster|2016-05-02 04:39:09|\n",
      "|    18|    431|            mafia|2016-05-02 04:39:15|\n",
      "|    18|   1221|        Al Pacino|2016-04-27 02:35:06|\n",
      "|    18|   1221|            Mafia|2016-04-27 02:35:03|\n",
      "|    18|   5995|        holocaust|2016-02-18 01:57:52|\n",
      "|    18|   5995|       true story|2016-02-18 01:57:59|\n",
      "|    18|  44665|     twist ending|2016-03-03 02:51:23|\n",
      "|    18|  52604|  Anthony Hopkins|2016-03-11 05:58:16|\n",
      "|    18|  52604|  courtroom drama|2016-03-11 05:58:31|\n",
      "+------+-------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links = spark.read.option(\"header\",True).csv(\"links_small.csv\")\n",
    "links.printSchema()\n",
    "links.show()\n",
    "tags = spark.read.option(\"header\",True).csv(\"tags_small.csv\").withColumn(\"timestamp\",f.to_timestamp(f.from_unixtime(\"timestamp\")))\n",
    "tags.printSchema()\n",
    "tags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+-------+----------------+-------------------+\n",
      "|movieId|               title|              genres|userId|movieId|             tag|          timestamp|\n",
      "+-------+--------------------+--------------------+------+-------+----------------+-------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|   567|      1|             fun|2018-05-03 01:33:33|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|   474|      1|           pixar|2006-01-14 09:47:05|\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|   336|      1|           pixar|2006-02-04 16:36:04|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|   474|      2|            game|2006-01-16 08:39:12|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|    62|      2|  Robin Williams|2018-06-13 05:51:47|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|    62|      2|magic board game|2018-06-13 05:52:12|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|    62|      2|         fantasy|2018-06-13 05:52:09|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   289|      3|             old|2006-03-27 09:01:00|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   289|      3|           moldy|2006-03-27 09:01:00|\n",
      "|      5|Father of the Bri...|              Comedy|   474|      5|          remake|2006-01-16 08:11:43|\n",
      "|      5|Father of the Bri...|              Comedy|   474|      5|       pregnancy|2006-01-16 08:11:43|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|   474|      7|          remake|2006-01-16 08:40:42|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|   474|     11|       president|2006-01-16 08:28:24|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|   474|     11|        politics|2006-01-16 08:28:24|\n",
      "|     14|        Nixon (1995)|               Drama|   474|     14|       president|2006-01-16 08:40:23|\n",
      "|     14|        Nixon (1995)|               Drama|   474|     14|        politics|2006-01-16 08:40:23|\n",
      "|     16|       Casino (1995)|         Crime|Drama|   474|     16|           Mafia|2006-01-14 02:47:20|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|   474|     17|     Jane Austen|2006-01-14 02:39:13|\n",
      "|     21|   Get Shorty (1995)|Comedy|Crime|Thri...|   474|     21|       Hollywood|2006-01-14 09:36:18|\n",
      "|     22|      Copycat (1995)|Crime|Drama|Horro...|   474|     22|   serial killer|2006-01-16 08:38:16|\n",
      "+-------+--------------------+--------------------+------+-------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opinions = movies.join(tags,movies[\"movieId\"] == tags[\"movieId\"])\n",
    "opinions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+------+----------+-------------------+\n",
      "|movieId|           title|              genres|userId|       tag|          timestamp|\n",
      "+-------+----------------+--------------------+------+----------+-------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   474|     pixar|2006-01-14 09:47:05|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   567|       fun|2018-05-03 01:33:33|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   336|     pixar|2006-02-04 16:36:04|\n",
      "| 100083| Movie 43 (2013)|              Comedy|   125|   sarcasm|2016-09-20 20:10:15|\n",
      "| 100083| Movie 43 (2013)|              Comedy|   125|R language|2016-09-20 20:10:35|\n",
      "+-------+----------------+--------------------+------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------------+--------------------+------+-----+-------------------+\n",
      "|movieId|           title|              genres|userId|  tag|          timestamp|\n",
      "+-------+----------------+--------------------+------+-----+-------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   336|pixar|2006-02-04 16:36:04|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   567|  fun|2018-05-03 01:33:33|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   474|pixar|2006-01-14 09:47:05|\n",
      "|     10|GoldenEye (1995)|Action|Adventure|...|  null| null|               null|\n",
      "|    100|City Hall (1996)|      Drama|Thriller|  null| null|               null|\n",
      "+-------+----------------+--------------------+------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------------+--------------------+------+-----+-------------------+\n",
      "|movieId|           title|              genres|userId|  tag|          timestamp|\n",
      "+-------+----------------+--------------------+------+-----+-------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   474|pixar|2006-01-14 09:47:05|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   567|  fun|2018-05-03 01:33:33|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   336|pixar|2006-02-04 16:36:04|\n",
      "|     10|GoldenEye (1995)|Action|Adventure|...|  null| null|               null|\n",
      "|    100|City Hall (1996)|      Drama|Thriller|  null| null|               null|\n",
      "+-------+----------------+--------------------+------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------------+--------------------+------+------------------+-------------------+\n",
      "|movieId|           title|              genres|userId|               tag|          timestamp|\n",
      "+-------+----------------+--------------------+------+------------------+-------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   474|             pixar|2006-01-14 09:47:05|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   336|             pixar|2006-02-04 16:36:04|\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|   567|               fun|2018-05-03 01:33:33|\n",
      "| 100083| Movie 43 (2013)|              Comedy|   125|embarassing scenes|2016-09-20 20:11:15|\n",
      "| 100083| Movie 43 (2013)|              Comedy|   125|           sarcasm|2016-09-20 20:10:15|\n",
      "+-------+----------------+--------------------+------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.join(tags,[\"movieId\"],\"inner\").sort('movieID').show(5)\n",
    "movies.join(tags,[\"movieId\"],\"outer\").sort('movieID').show(5)\n",
    "movies.join(tags,[\"movieId\"],\"left\").sort('movieID').show(5)\n",
    "movies.join(tags,[\"movieId\"],\"right\").sort('movieID').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      1|   4.0|2000-07-31 01:45:03|\n",
      "|     1|      3|   4.0|2000-07-31 01:20:47|\n",
      "|     1|      6|   4.0|2000-07-31 01:37:04|\n",
      "|     1|     47|   5.0|2000-07-31 02:03:35|\n",
      "|     1|     50|   5.0|2000-07-31 01:48:51|\n",
      "|     1|     70|   3.0|2000-07-31 01:40:00|\n",
      "|     1|    101|   5.0|2000-07-31 01:14:28|\n",
      "|     1|    110|   4.0|2000-07-31 01:36:16|\n",
      "|     1|    151|   5.0|2000-07-31 02:07:21|\n",
      "|     1|    157|   5.0|2000-07-31 02:08:20|\n",
      "|     1|    163|   5.0|2000-07-31 02:00:50|\n",
      "|     1|    216|   5.0|2000-07-31 01:20:08|\n",
      "|     1|    223|   3.0|2000-07-31 01:16:25|\n",
      "|     1|    231|   5.0|2000-07-31 01:19:39|\n",
      "|     1|    235|   4.0|2000-07-31 01:15:08|\n",
      "|     1|    260|   5.0|2000-07-31 01:28:00|\n",
      "|     1|    296|   3.0|2000-07-31 01:49:27|\n",
      "|     1|    316|   3.0|2000-07-31 01:38:30|\n",
      "|     1|    333|   5.0|2000-07-31 01:19:39|\n",
      "|     1|    349|   4.0|2000-07-31 01:42:43|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------+--------------------+--------------------+----------------+-------------------+------+-------------------+\n",
      "|userId|movieId|               title|              genres|             tag|          timestamp|rating|          timestamp|\n",
      "+------+-------+--------------------+--------------------+----------------+-------------------+------+-------------------+\n",
      "|   567|      1|    Toy Story (1995)|Adventure|Animati...|             fun|2018-05-03 01:33:33|   3.5|2018-05-03 01:33:21|\n",
      "|   474|      1|    Toy Story (1995)|Adventure|Animati...|           pixar|2006-01-14 09:47:05|   4.0|2001-01-04 09:36:00|\n",
      "|   336|      1|    Toy Story (1995)|Adventure|Animati...|           pixar|2006-02-04 16:36:04|   4.0|2005-07-25 00:48:49|\n",
      "|   474|      2|      Jumanji (1995)|Adventure|Childre...|            game|2006-01-16 08:39:12|   3.0|2003-03-06 00:53:34|\n",
      "|    62|      2|      Jumanji (1995)|Adventure|Childre...|  Robin Williams|2018-06-13 05:51:47|   4.0|2018-06-13 05:51:30|\n",
      "|    62|      2|      Jumanji (1995)|Adventure|Childre...|magic board game|2018-06-13 05:52:12|   4.0|2018-06-13 05:51:30|\n",
      "|    62|      2|      Jumanji (1995)|Adventure|Childre...|         fantasy|2018-06-13 05:52:09|   4.0|2018-06-13 05:51:30|\n",
      "|   289|      3|Grumpier Old Men ...|      Comedy|Romance|             old|2006-03-27 09:01:00|   2.5|2006-03-27 08:57:37|\n",
      "|   289|      3|Grumpier Old Men ...|      Comedy|Romance|           moldy|2006-03-27 09:01:00|   2.5|2006-03-27 08:57:37|\n",
      "|   474|      5|Father of the Bri...|              Comedy|          remake|2006-01-16 08:11:43|   1.5|2003-05-16 01:06:22|\n",
      "+------+-------+--------------------+--------------------+----------------+-------------------+------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()\n",
    "movies.join(tags,[\"movieId\"],\"inner\").join(ratings,[\"userId\",\"movieId\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------------+--------------------+----------------+-------------------+------+-------------------+\n",
      "|movieId|userId|               title|              genres|             tag|      tag_timestamp|rating|          timestamp|\n",
      "+-------+------+--------------------+--------------------+----------------+-------------------+------+-------------------+\n",
      "|      1|   567|    Toy Story (1995)|Adventure|Animati...|             fun|2018-05-03 01:33:33|   3.5|2018-05-03 01:33:21|\n",
      "|      1|   474|    Toy Story (1995)|Adventure|Animati...|           pixar|2006-01-14 09:47:05|   4.0|2001-01-04 09:36:00|\n",
      "|      1|   336|    Toy Story (1995)|Adventure|Animati...|           pixar|2006-02-04 16:36:04|   4.0|2005-07-25 00:48:49|\n",
      "|      2|   474|      Jumanji (1995)|Adventure|Childre...|            game|2006-01-16 08:39:12|   3.0|2003-03-06 00:53:34|\n",
      "|      2|    62|      Jumanji (1995)|Adventure|Childre...|  Robin Williams|2018-06-13 05:51:47|   4.0|2018-06-13 05:51:30|\n",
      "|      2|    62|      Jumanji (1995)|Adventure|Childre...|magic board game|2018-06-13 05:52:12|   4.0|2018-06-13 05:51:30|\n",
      "|      2|    62|      Jumanji (1995)|Adventure|Childre...|         fantasy|2018-06-13 05:52:09|   4.0|2018-06-13 05:51:30|\n",
      "|      3|   289|Grumpier Old Men ...|      Comedy|Romance|             old|2006-03-27 09:01:00|   2.5|2006-03-27 08:57:37|\n",
      "|      3|   289|Grumpier Old Men ...|      Comedy|Romance|           moldy|2006-03-27 09:01:00|   2.5|2006-03-27 08:57:37|\n",
      "|      5|   474|Father of the Bri...|              Comedy|          remake|2006-01-16 08:11:43|   1.5|2003-05-16 01:06:22|\n",
      "|      5|   474|Father of the Bri...|              Comedy|       pregnancy|2006-01-16 08:11:43|   1.5|2003-05-16 01:06:22|\n",
      "|      7|   474|      Sabrina (1995)|      Comedy|Romance|          remake|2006-01-16 08:40:42|   3.0|2001-01-04 09:46:21|\n",
      "|     11|   474|American Presiden...|Comedy|Drama|Romance|       president|2006-01-16 08:28:24|   2.5|2003-05-16 00:57:17|\n",
      "|     11|   474|American Presiden...|Comedy|Drama|Romance|        politics|2006-01-16 08:28:24|   2.5|2003-05-16 00:57:17|\n",
      "|     14|   474|        Nixon (1995)|               Drama|       president|2006-01-16 08:40:23|   3.0|2005-07-08 19:54:07|\n",
      "|     14|   474|        Nixon (1995)|               Drama|        politics|2006-01-16 08:40:23|   3.0|2005-07-08 19:54:07|\n",
      "|     16|   474|       Casino (1995)|         Crime|Drama|           Mafia|2006-01-14 02:47:20|   4.0|2004-06-28 19:45:31|\n",
      "|     17|   474|Sense and Sensibi...|       Drama|Romance|     Jane Austen|2006-01-14 02:39:13|   5.0|2000-11-20 04:17:46|\n",
      "|     21|   474|   Get Shorty (1995)|Comedy|Crime|Thri...|       Hollywood|2006-01-14 09:36:18|   4.0|2005-06-20 08:59:44|\n",
      "|     22|   474|      Copycat (1995)|Crime|Drama|Horro...|   serial killer|2006-01-16 08:38:16|   3.0|2003-03-06 03:26:46|\n",
      "+-------+------+--------------------+--------------------+----------------+-------------------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.join(tags,[\"movieId\"],\"inner\").withColumnRenamed(\"timestamp\",\"tag_timestamp\").join(ratings,[\"movieId\",\"userId\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------+-----------+------------------+-------------------+-------------------+\n",
      "|movieId|count|min(rating)|max(rating)|       avg(rating)|     min(timestamp)|     max(timestamp)|\n",
      "+-------+-----+-----------+-----------+------------------+-------------------+-------------------+\n",
      "| 100553|    2|        4.5|        4.5|               4.5|2015-03-15 00:14:07|2015-11-04 00:39:58|\n",
      "| 102684|    2|        3.5|        4.0|              3.75|2013-08-16 19:02:32|2017-05-14 03:59:59|\n",
      "|   1090|   63|        1.0|        5.0| 3.984126984126984|1997-03-19 18:50:39|2018-08-11 07:54:18|\n",
      "| 112911|    4|        0.5|        4.0|               2.0|2015-12-18 19:26:23|2018-05-03 02:22:29|\n",
      "| 115713|   28|        0.5|        5.0|3.9107142857142856|2015-05-22 20:18:30|2018-09-17 11:20:30|\n",
      "| 117630|    1|        1.0|        1.0|               1.0|2018-02-23 15:03:51|2018-02-23 15:03:51|\n",
      "| 119655|    2|        1.0|        3.5|              2.25|2016-03-29 00:38:32|2016-04-05 01:10:44|\n",
      "| 120478|    3|        3.5|        5.0| 4.333333333333333|2016-08-09 07:31:31|2018-08-23 22:20:21|\n",
      "| 121007|    1|        4.0|        4.0|               4.0|2018-03-07 14:49:28|2018-03-07 14:49:28|\n",
      "|   1572|    2|        2.5|        3.5|               3.0|2005-09-05 01:09:05|2007-07-30 13:38:04|\n",
      "| 158813|    4|        1.0|        3.0|               2.0|2016-05-27 00:11:12|2018-02-12 03:28:03|\n",
      "| 173535|    1|        4.5|        4.5|               4.5|2018-05-13 17:23:13|2018-05-13 17:23:13|\n",
      "|   2069|    2|        3.5|        5.0|              4.25|2003-03-31 09:02:30|2005-12-19 04:49:09|\n",
      "|   2088|   18|        1.0|        4.0|               2.5|1999-11-03 22:04:32|2018-08-13 05:51:42|\n",
      "|   2136|   14|        0.5|        5.0|2.4642857142857144|1999-10-13 17:37:12|2012-02-02 08:19:04|\n",
      "|   2162|    8|        1.0|        3.5|               2.5|2000-10-15 21:22:34|2018-02-22 00:29:27|\n",
      "|   2294|   45|        1.5|        5.0|3.2444444444444445|1999-02-28 18:27:31|2018-09-02 03:30:29|\n",
      "|  26082|    3|        4.0|        5.0|               4.5|2006-10-26 14:56:24|2015-11-04 00:52:09|\n",
      "|  27317|    6|        3.0|        4.5|              3.75|2005-04-05 21:57:39|2017-06-30 12:23:18|\n",
      "|    296|  307|        0.5|        5.0| 4.197068403908795|1996-04-18 00:08:18|2018-09-17 11:12:07|\n",
      "+-------+-----+-----------+-----------+------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.groupBy(\"movieId\").agg(\n",
    "    f.count(\"*\").alias(\"count\"),\n",
    "    f.min(\"rating\"),\n",
    "    f.max(\"rating\"),\n",
    "    f.avg(\"rating\"),\n",
    "    f.min(\"timestamp\"),\n",
    "    f.max(\"timestamp\"),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+-------------+-------------------+-------------------+\n",
      "|movieId|    collect_set(tag)|count(tag)| collect_set(userId)|count(userId)|     min(timestamp)|     max(timestamp)|\n",
      "+-------+--------------------+----------+--------------------+-------------+-------------------+-------------------+\n",
      "|   1090|           [Vietnam]|         1|               [474]|            1|2006-01-25 04:26:30|2006-01-25 04:26:30|\n",
      "|    296|[foul language, r...|       181|[474, 103, 424, 599]|          181|2006-01-14 09:16:41|2017-06-26 12:58:14|\n",
      "|   3210|       [high school]|         1|               [474]|            1|2006-01-16 08:19:41|2006-01-16 08:19:41|\n",
      "|   1372|          [Klingons]|         1|               [474]|            1|2006-01-14 08:44:24|2006-01-14 08:44:24|\n",
      "|   1394|     [Coen Brothers]|         1|               [474]|            1|2006-01-14 02:43:35|2006-01-14 02:43:35|\n",
      "|   2393|[space opera, Sta...|         3|               [477]|            3|2009-05-14 12:21:03|2009-05-14 12:21:13|\n",
      "|   3281|         [sexuality]|         1|               [474]|            1|2006-01-16 08:18:50|2006-01-16 08:18:50|\n",
      "|  58559|[gritty, psycholo...|         4|          [435, 567]|            4|2013-04-23 07:14:00|2018-05-03 01:26:41|\n",
      "|    800|  [In Netflix queue]|         1|               [474]|            1|2006-01-14 08:26:14|2006-01-14 08:26:14|\n",
      "|  90439|[Kevin Spacey, Wa...|         9|               [537]|            9|2015-02-17 09:03:55|2015-02-17 09:44:19|\n",
      "+-------+--------------------+----------+--------------------+-------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.groupBy(\"movieId\").agg(\n",
    "    f.collect_set(\"tag\"),\n",
    "    f.count(\"tag\"),\n",
    "    f.collect_set(\"userId\"),\n",
    "    f.count(\"userId\"),\n",
    "    f.min(\"timestamp\"),\n",
    "    f.max(\"timestamp\")\n",
    ").show(10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
